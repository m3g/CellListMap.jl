<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Parallelization · CellListMap.jl</title><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.039/juliamono-regular.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.11/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img src="../assets/logo.svg" alt="CellListMap.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../">CellListMap.jl</a></span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Overview</a></li><li><a class="tocitem" href="../examples/">Examples</a></li><li><a class="tocitem" href="../units_etc/">Units, autodiff, etc.</a></li><li><a class="tocitem" href="../pbc/">Periodic conditions</a></li><li class="is-active"><a class="tocitem" href>Parallelization</a><ul class="internal"><li><a class="tocitem" href="#Custom-reduction-functions"><span>Custom reduction functions</span></a></li><li><a class="tocitem" href="#Preallocating-auxiliary-arrays:-threaded-output-and-cell-lists"><span>Preallocating auxiliary arrays: threaded output and cell lists</span></a></li><li><a class="tocitem" href="#Number-of-batches"><span>Number of batches</span></a></li></ul></li><li><a class="tocitem" href="../performance/">Performance</a></li><li><a class="tocitem" href="../options/">Options</a></li><li><a class="tocitem" href="../help/">Help entries</a></li><li><a class="tocitem" href="../reference/">Reference</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Parallelization</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Parallelization</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/m3g/CellListMap.jl/blob/master/docs/src/parallelization.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Parallelization-splitting-and-reduction"><a class="docs-heading-anchor" href="#Parallelization-splitting-and-reduction">Parallelization splitting and reduction</a><a id="Parallelization-splitting-and-reduction-1"></a><a class="docs-heading-anchor-permalink" href="#Parallelization-splitting-and-reduction" title="Permalink"></a></h1><p>The parallel execution requires the splitting of the computation among threads, obviously. Thus, the output variable must be split and then reduced to avoid concurrency. To control these steps, set manually the <code>output_threaded</code> and <code>reduce</code> optional input parameters of the <code>map_pairwise!</code> function. </p><p>By default, we define:</p><pre><code class="language-julia hljs">output_threaded = [ deepcopy(output) for i in 1:CellListMap.batches(cl) ]</code></pre><p>where <code>CellListMap.batches(cl)</code> is the number of batches into which the computation will be divided, as defined for the cell list <code>cl</code> (this parameter is usually equal to the number of threads available, except for very small system, but it can be tunned for performance, as explained <a href="voltar">here</a>),  and, for scalars and vectors, the reduction is just the sum of the output per thread:</p><pre><code class="language-julia hljs">reduce(output::Number,output_threaded) = sum(output_threaded)
function reduce(output::Vector,output_threaded) 
    @. output = output_threaded[1]
    for i in 2:length(output_threaded)
         @. output += output_threaded[i] 
    end
    return output
end</code></pre><h2 id="Custom-reduction-functions"><a class="docs-heading-anchor" href="#Custom-reduction-functions">Custom reduction functions</a><a id="Custom-reduction-functions-1"></a><a class="docs-heading-anchor-permalink" href="#Custom-reduction-functions" title="Permalink"></a></h2><p>In some cases, as in the <a href="#nearest-neighbour">Nearest neighbour</a> example, the output is a tuple and reduction consists in keeping the output from each thread having the minimum value for the distance. Thus, the reduction operation is not a simple sum over the elements of each threaded output. We can, therefore, overwrite the default reduction method, by passing the reduction function as the <code>reduce</code> parameter of <code>map_pairwise!</code>:</p><pre><code class="language-julia hljs">mind = map_pairwise!( 
    (x,y,i,j,d2,mind) -&gt; f(i,j,d2,mind), mind,box,cl;
    reduce=reduce_mind
)</code></pre><p>where here the <code>reduce</code> function is set to be the custom function that keeps the tuple associated to the minimum distance obtained between threads:</p><pre><code class="language-julia hljs">function reduce_mind(output,output_threaded)
    mind = output_threaded[1]
    for i in 2:length(output_threaded)
        if output_threaded[i][3] &lt; mind[3]
            mind = output_threaded[i]
        end
    end
    return mind
end</code></pre><p>This function <em>must</em> return the updated <code>output</code> variable, being it mutable or not, to be compatible with the interface.  </p><h2 id="Preallocating-auxiliary-arrays:-threaded-output-and-cell-lists"><a class="docs-heading-anchor" href="#Preallocating-auxiliary-arrays:-threaded-output-and-cell-lists">Preallocating auxiliary arrays: threaded output and cell lists</a><a id="Preallocating-auxiliary-arrays:-threaded-output-and-cell-lists-1"></a><a class="docs-heading-anchor-permalink" href="#Preallocating-auxiliary-arrays:-threaded-output-and-cell-lists" title="Permalink"></a></h2><h3 id="Preallocating-the-cell-lists-and-cell-list-auxiliary-arrays"><a class="docs-heading-anchor" href="#Preallocating-the-cell-lists-and-cell-list-auxiliary-arrays">Preallocating the cell lists and cell list auxiliary arrays</a><a id="Preallocating-the-cell-lists-and-cell-list-auxiliary-arrays-1"></a><a class="docs-heading-anchor-permalink" href="#Preallocating-the-cell-lists-and-cell-list-auxiliary-arrays" title="Permalink"></a></h3><p>The arrays containing the cell lists can be initialized only once, and then updated. This is useful for iterative runs. Note that, since the list size depends on the box size and cutoff, if the box properties changes some arrays might be increased (never shrink) on this update. </p><pre><code class="language-julia hljs"># Initialize cell lists with initial coordinates
cl = CellList(x,box)
# Allocate auxiliary arrays for threaded cell list construction
aux = CellListMap.AuxThreaded(cl)
for i in 1:nsteps
    x = ... # new coordinates
    box = Box(sides,cutoff) # perhaps the box has changed
    cl = UpdateCellList!(x,box,cl,aux) 
end</code></pre><p>The procedure is identical if using two sets of coordinates, in which case, one would do:</p><pre><code class="language-julia hljs">cl = CellList(x,y,box)
aux = CellListMap.AuxThreaded(cl)
for i in 1:nsteps
    x = ... # new coordinates
    box = Box(sides,cutoff) # perhaps the box has changed
    cl = UpdateCellList!(x,y,box,cl,aux)
end</code></pre><p>By passing the <code>aux</code> auxiliary structure, the <code>UpdateCellList!</code> functions will only allocate some minor variables associated to the launching of multiple threads and, possibly, to the expansion of the cell lists if the box or the number of particles became greater. </p><h3 id="Preallocating-threaded-output-auxiliary-arrays"><a class="docs-heading-anchor" href="#Preallocating-threaded-output-auxiliary-arrays">Preallocating threaded output auxiliary arrays</a><a id="Preallocating-threaded-output-auxiliary-arrays-1"></a><a class="docs-heading-anchor-permalink" href="#Preallocating-threaded-output-auxiliary-arrays" title="Permalink"></a></h3><p>On parallel runs, note that <code>output_threaded</code> is, by default, initialized on the call to <code>map_pairwise!</code>. Thus, if the calculation must be run multiple times (for example, for several steps of a trajectory), it is probably a good idea to preallocate the threaded output, particularly if it is a large array. For example, the arrays of forces should be created only once, and reset to zero after each use:</p><pre><code class="language-julia hljs">forces = zeros(SVector{3,Float64},N)
forces_threaded = [ deepcopy(forces) for i in 1:cl.nbatches ]
for i in 1:nsteps
    map_pairwise!(f, forces, box, cl, output_threaded=forces_threaded)
    # work with the final forces vector
    ...
    # Reset forces_threaded
    for i in 1:cl.nbatches
        @. forces_threaded[i] = zero(SVector{3,Float64}) 
    end
end</code></pre><p>In this case, the <code>forces</code> vector will be updated by the default reduction method. <code>cl.nbatches</code> is the number of batches of the parallel calculation, which is defined on the construction of the cell list (usually equal to the number of threads available).</p><h2 id="Number-of-batches"><a class="docs-heading-anchor" href="#Number-of-batches">Number of batches</a><a id="Number-of-batches-1"></a><a class="docs-heading-anchor-permalink" href="#Number-of-batches" title="Permalink"></a></h2><p>Every calculation with cell lists has two steps: the construction of the lists, and the mapping of the computation among the pairs of particles that satisfy the cutoff criterion. </p><p>The construction of the cell list is harder to parallelize, because assigning each particle to a cell is fast, such that the cost of merging a set of lists generated in parallel can be as costly as building the lists themselves. Therefore, it is frequent that it is not worthwhile (actually it is detrimental for performance) to split the construction of the cell lists in to many threads. This is particularly relevant for smaller systems, for which the cost of constructing the lists can be comparable to the cost of actually computing the mapped function. </p><p>At the same time, the homogeneity of the computation of the mapped function may be fast or not, homogeneous or not. These characteristics affect the optimal workload splitting strategy. For very large systems, or systems for which the function to be computed is not homogeneous in time, it may be interesting to split the workload in many tasks as possible, such that slow tasks do not dominate the final computational time.   </p><p>Both the above considerations can be taken into consideration by tunning the <code>nbatches</code> parameter in the construction of the cell lists. This parameter assumes a value of type <code>NumberOfBatches</code>, which is basically a tuple of two integers, defining the number of batches that will be used for constructing the cell lists and for the mapping of the computations. By default, these assume values which are at most <code>nthreads()</code>, but in particular for very small systems the number of batches for the construction of the cell lists can be smaller.</p><p>For example:</p><pre><code class="language-julia-repl hljs">julia&gt; Threads.nthreads()
8

julia&gt; x = [ rand(3) for _ in 1:1000 ]; box = Box([1,1,1],0.1);

julia&gt; cl = CellList(x,box); # default

julia&gt; cl.nbatches
CellListMap.NumberOfBatches
  Number of batches for cell list construction: 1
  Number of batches for function mapping: 8</code></pre><p>Note that we have 8 threads  available, but by default, for this small system (1000 particles), we will use only one batch for the construction of the cell lists.  This is effectively faster than if we force the computation to use all threads:</p><pre><code class="nohighlight hljs">julia&gt; @btime CellList($x,$box); # default
  262.040 μs (2224 allocations: 627.38 KiB)

julia&gt; @btime CellList($x,$box,nbatches=CellListMap.NumberOfBatches(8,8));
  2.740 ms (18883 allocations: 2.86 MiB)</code></pre><p>For larger systems this may change. For example, for <code>1_000_000</code> points, we have:</p><pre><code class="nohighlight hljs">julia&gt; @btime CellList($x,$box,nbatches=CellListMap.NumberOfBatches(1,8));
  207.017 ms (5227 allocations: 77.14 MiB)

julia&gt; @btime CellList($x,$box,nbatches=CellListMap.NumberOfBatches(8,8));
  78.663 ms (40540 allocations: 351.79 MiB)</code></pre><p>The default numbers of batches, in these cases, correspond to the optimal choices. But what is implemented is a very simple heuristic based on the number of particles per cell, thus the optimal choice is available for exploration by the user by adjusting the <code>nbatches</code> parameter as shown above. </p><p>The number of batches for the mapping of the pairwise computation generally is close to optimal if equal to the number of threads.  Most times it doesn&#39;t really makes sense to start a number of batches that is not a multiple of the number of threads available. For example, if the number of batches is <code>nthreads()+1</code>, most likely <code>ntreads()</code> batches will finish almost simultaneously and then the remaining batch will start running. Let us see the effect  of the number of batches in one specific example. The computer in which these tests are performed has 4 physical cores, which with multi-threading can span 8 independent threads.</p><pre><code class="language-julia-repl hljs">julia&gt; Threads.nthreads()
8</code></pre><p>The test will be the computation of pairwise velocities of a set of <code>100_000</code> particles. We will keep the first parameter fixed (the number of batches of the cell list construction):</p><pre><code class="language-julia-repl hljs">julia&gt; @btime CellListMap.Examples.pairwise_velocities(N=100_000,nbatches=CellListMap.NumberOfBatches(4,1));
  159.174 ms (178841 allocations: 51.94 MiB)

julia&gt; @btime CellListMap.Examples.pairwise_velocities(N=100_000,nbatches=CellListMap.NumberOfBatches(4,4));
  56.735 ms (178872 allocations: 51.95 MiB)

julia&gt; @btime CellListMap.Examples.pairwise_velocities(N=100_000,nbatches=CellListMap.NumberOfBatches(4,8));
  46.302 ms (178914 allocations: 51.95 MiB)

julia&gt; @btime CellListMap.Examples.pairwise_velocities(N=100_000,nbatches=CellListMap.NumberOfBatches(4,16));
  46.211 ms (178998 allocations: 51.97 MiB)

julia&gt; @btime CellListMap.Examples.pairwise_velocities(N=100_000);
  48.192 ms (88325 allocations: 36.04 MiB)
</code></pre><p>As shown above, the optimal number o batches is close to the number of threads available, and increasing it further does not improve performance. It may degrade performance for larger number of batches. However, if the computations where heterogeneous and the cost of each batch is much larger than the cost of spawning the threads, splitting into more batches than threads may be worthwhile. Gains in performance for very large systems are expected with this strategy. </p><p>For example, for a system with 5 million particles, this computation is faster with more batches than with the number of threads:</p><pre><code class="nohighlight hljs">julia&gt; @time CellListMap.Examples.pairwise_velocities(N=5_000_000,nbatches=CellListMap.NumberOfBatches(4,16));
  3.707087 seconds (8.36 M allocations: 2.066 GiB, 4.86% gc time)

julia&gt; @time CellListMap.Examples.pairwise_velocities(N=5_000_000,nbatches=CellListMap.NumberOfBatches(4,8));
  4.450609 seconds (8.36 M allocations: 2.066 GiB, 20.86% gc time)</code></pre><p>this occurs because the random splitting of the workload into batches can lead to fluctuations in the amount of work per batch, and this effect is minimized if a greater number of batches is present. Also, this alleviates the problem of one batch being assigned to a thread that for some reason became slower (for competing with other process, or being associated to a virtual processor, etc.)</p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../pbc/">« Periodic conditions</a><a class="docs-footer-nextpage" href="../performance/">Performance »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.10 on <span class="colophon-date" title="Tuesday 23 November 2021 13:53">Tuesday 23 November 2021</span>. Using Julia version 1.6.4.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
