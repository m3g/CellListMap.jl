var documenterSearchIndex = {"docs":
[{"location":"neighborlists/#Neighbor-lists","page":"Neighbor lists","title":"Neighbor lists","text":"Neighbor lists can be computed, returning all pairs of particles that are found within the cutoff, and the corresponding distances.  \n\nNon-periodic systems\nPeriodic systems\nIn-place computation of neighbor lists\nOptions\n\nnote: Note\nWhen computing neighbor lists with cell-lists, it is possible for pairs of particles that are at a distance equal to the cutoff to either be included or excluded due to numerical rounding. As a result, these neighbor lists should only be utilized for calculating properties that vanish at the cutoff distance.","category":"section"},{"location":"neighborlists/#Non-periodic-systems","page":"Neighbor lists","title":"Non-periodic systems","text":"Without periodic boundary conditions, just provide the coordinates and the cutoff:\n\njulia> using CellListMap\n\njulia> x = [ rand(2) for _ in 1:10_000 ];\n\njulia> neighborlist(x,0.05)\n376457-element Vector{Tuple{Int64, Int64, Float64}}:\n (1, 363, 0.04855594810064624)\n (1, 513, 0.03356381123125866)\n (1, 1209, 0.005159666709130686)\n â‹®\n (6575, 7378, 0.03791567990447959)\n (7378, 3450, 0.01748757015908321)\n\nnote: Note\nThe order of the pairs in the output list is not guaranteed and may change, in particular, for parallel executions.\n\nIf the neighbor lists between two sets of points are required, use the following notation,  in this case using coordinates as arrays of static arrays:\n\njulia> using StaticArrays\n\njulia> x = rand(SVector{3,Float64},10^4);\n\njulia> y = rand(SVector{3,Float64},10^3);\n\njulia> list = neighborlist(x,y,0.1)\n37309-element Vector{Tuple{Int64, Int64, Float64}}:\n (1, 971, 0.09867846773727411)\n (1, 567, 0.06630101425431004)\n (1, 3, 0.04103170149300593)\n â‹®\n (10000, 156, 0.08549899843141298)\n (10000, 444, 0.0737386384422871)\n\nwhere, similarly, the third parameter is the cutoff. The returning array contains tuples with the index of the particle in the first vector, the index of the particle in the second vector, and their distance.","category":"section"},{"location":"neighborlists/#Periodic-systems","page":"Neighbor lists","title":"Periodic systems","text":"If periodic boundary conditions are used, the unitcell can be provided explicitly as keyword parameters:\n\njulia> x = [ rand(2) for _ in 1:10_000 ]; \n\njulia> neighborlist(x, 0.05; unitcell=[1,1])\n392100-element Vector{Tuple{Int64, Int64, Float64}}:\n (1, 5, 0.03445098850037766)\n (1, 393, 0.039448810592487206)\n (1, 1632, 0.02276457565643465)\n â‹®\n (9501, 9781, 0.03351665194098955)\n (9501, 5429, 0.04199258248973222)\n\nIn the example above, an Orthorhombic cell was assumed, and thus a vector of sides was provided. For general periodic boundary conditions, a unit cell matrix can be provided, for example:\n\njulia> neighborlist(x, 0.05; unitcell=[1.0 0.5; 0.5 1.0])\n580693-element Vector{Tuple{Int64, Int64, Float64}}:\n (1, 457, 0.03935441952786555)\n (1, 1467, 0.033407692174569875)\n (1, 1767, 0.04490555313598093)\n â‹®\n (3652, 8475, 0.04721628783510375)\n (6260, 8475, 0.04946130971686825)\n\nnote: Note\nPositions and unit cells can be 2 or 3-dimensional.","category":"section"},{"location":"neighborlists/#In-place-computation-of-neighbor-lists","page":"Neighbor lists","title":"In-place computation of neighbor lists","text":"If neighbor lists are computed within a interactive scenario, it is interesting preallocate all the necessary data and just update the lists at every iteration. This can be achieved by constructing the InPlaceNeighborList  object in advance. The performance gain of performing the operations in place might vary and may not be  important for single runs, as the allocations do not dominate the computing time. \n\nWe will first illustrate the interface for a non-parallel run:\n\njulia> using CellListMap, StaticArrays\n\njulia> x = rand(SVector{3,Float64}, 10^4);\n\njulia> system = InPlaceNeighborList(x=x, cutoff=0.1, unitcell=[1,1,1], parallel=false)\nInPlaceNeighborList with types: \nCellList{3, Float64}\nBox{OrthorhombicCell, 3, Float64, Float64, 9}\nCurrent list buffer size: 0\n\nNote that the buffer size has size 0. The first time the neighbor lists are computed, the list will be allocated. We will use the neighborlist! (with the bang) function, because it will effectively  mutate the system, by allocating all necessary data:\n\njulia> @time list = neighborlist!(system)\n  0.017765 seconds (12 allocations: 7.445 MiB)\n209190-element Vector{Tuple{Int64, Int64, Float64}}:\n (1, 1375, 0.09425551992016712)\n (1, 3076, 0.045320021406080775)\n (1, 3666, 0.07780146666634076)\n â‹®\n (9962, 6983, 0.07355578793348823)\n (9962, 7457, 0.07597724209140656)\n\nNow, if we modify the coordinates, we can update the system and recompute the neighbor lists:\n\njulia> x_new = rand(SVector{3,Float64}, 10^4);\n\njulia> @time update!(system, x_new)\n  0.003562 seconds\nInPlaceNeighborList with types: \nCellList{3, Float64}\nBox{OrthorhombicCell, 3, Float64, Float64, 9}\nCurrent list buffer size: 209190\n\njulia> @time list = neighborlist!(system);\n  0.012338 seconds\n\nnote: Note\nHere we illustrate the behavior of the functions in their second calls, to remove the  effects of compilation on the allocation results.\nThe cutoff and unitcell  can be modified by providing additional keyword parameters to the update! function (for example update!(system, x; cutoff=0.1)).\nAllocations can occur if the cutoff, unit cell, or number of particles change such that greater buffers are required. The number of allocations tend to diminish as  the buffers become large enough to accommodate the possible variations of the computation.\n\nFor parallel runs, the allocations are minimal, but some small auxiliary data is required for the launching of multiple threads. We illustrate here the convergence of the allocations to the  minimum required for multi-threaded calculations:\n\njulia> system = InPlaceNeighborList(x=x, cutoff=0.1, unitcell=[1,1,1], parallel=true);\n\njulia> @time list = neighborlist!(system);\n  0.007762 seconds (230 allocations: 18.142 MiB)\n\njulia> x_new = rand(SVector{3,Float64},10^4);\n\njulia> @time update!(system, x_new)\n  0.005283 seconds (20.30 k allocations: 6.200 MiB)\nInPlaceNeighborList with types: \nCellList{3, Float64}\nBox{OrthorhombicCell, 3, Float64, Float64, 9}\nCurrent list buffer size: 209190\n\njulia> @time neighborlist!(system);\n  0.008190 seconds (166 allocations: 6.461 MiB)\n\njulia> x_new = rand(SVector{3,Float64},10^4);\n\njulia> @time update!(system, x_new);\n  0.002723 seconds (221 allocations: 208.922 KiB)\n\njulia> @time neighborlist!(system);\n  0.006227 seconds (165 allocations: 2.863 MiB)\n\njulia> x_new = rand(SVector{3,Float64},10^4);\n\njulia> @time update!(system, x_new);\n  0.002396 seconds (275 allocations: 144.078 KiB)\n\njulia> @time neighborlist!(system);\n  0.004996 seconds (161 allocations: 15.141 KiB)","category":"section"},{"location":"neighborlists/#Options","page":"Neighbor lists","title":"Options","text":"Additional optional parameters can be used in a neighborlist call:\n\nKeyword Values types Default About\nparallel Bool true turns on and off parallelization\nshow_progress Bool false turns on and off progress bar\nnbatches Tuple{Int,Int} (0,0) Number of batches used in parallelization (see here)\nautoswap Bool true (advanced) automatically choose set to construct the cell lists","category":"section"},{"location":"neighborlists/#Docstrings","page":"Neighbor lists","title":"Docstrings","text":"","category":"section"},{"location":"neighborlists/#CellListMap.neighborlist-Tuple{Any, Any, Any}","page":"Neighbor lists","title":"CellListMap.neighborlist","text":"neighborlist(\n    x, y, cutoff; \n    unitcell=nothing, \n    parallel=true, \n    show_progress=false, \n    autoswap=true,\n    nbatches=(0,0)\n)\n\nComputes the list of pairs of particles of x which are closer than r to the particles of y. The autoswap option will swap x and y to try to optimize the cost of the construction of the cell list. \n\nnote: Note\nThe order of the pairs in the output of neighborlist! is not guaranteed, and may change, in particular, in parallel runs.\n\nExamples\n\nCompute the neighborlist between two sets of Argon atoms, considering the system non-periodic (do not provide a unitcell):\n\njulia> using CellListMap, PDBTools\n\njulia> x = coor(readPDB(CellListMap.argon_pdb_file, \"index <= 50\"));\n\njulia> y = coor(readPDB(CellListMap.argon_pdb_file, \"index > 50\"));\n\njulia> CellListMap.neighborlist(x, y, 8.0; parallel=false)\n439-element Vector{Tuple{Int64, Int64, Float64}}:\n (1, 13, 7.0177629626541265)\n (1, 24, 7.976895636774999)\n (1, 29, 3.1770283284856)\n (1, 11, 4.0886518560523095)\n (1, 17, 5.939772807102978)\n (1, 30, 2.457228927063981)\n (1, 44, 5.394713986857875)\n (1, 45, 5.424876588458028)\n (2, 2, 3.9973374888793174)\n (2, 6, 5.355242104704511)\n â‹®\n (50, 27, 6.257296620746054)\n (50, 32, 3.109966559305742)\n (50, 33, 2.9192916949150525)\n (50, 35, 5.043227240567294)\n (50, 10, 3.9736202636890208)\n (50, 20, 6.995405134800989)\n (50, 39, 3.9001540995196584)\n (50, 37, 7.5464903100713)\n (50, 3, 7.232267901564487)\n\nNow, considering the system periodic:\n\njulia> using CellListMap, PDBTools\n\njulia> x = coor(readPDB(CellListMap.argon_pdb_file, \"index <= 50\"));\n\njulia> y = coor(readPDB(CellListMap.argon_pdb_file, \"index > 50\"));\n\njulia> CellListMap.neighborlist(x, y, 8.0; unitcell = [21.0, 21.0, 21.0], parallel=false)\n584-element Vector{Tuple{Int64, Int64, Float64}}:\n (1, 12, 7.360804915224965)\n (1, 13, 7.017762962654125)\n (1, 24, 7.976895636774997)\n (1, 29, 3.177028328485598)\n (1, 44, 5.394713986857875)\n (1, 45, 5.4248765884580274)\n (1, 11, 4.088651856052312)\n (1, 17, 5.93977280710298)\n (1, 30, 2.457228927063981)\n (1, 28, 6.853834401267658)\n â‹®\n (50, 3, 7.232267901564487)\n (50, 10, 3.9736202636890203)\n (50, 27, 6.257296620746054)\n (50, 32, 3.1099665593057426)\n (50, 33, 2.919291694915052)\n (50, 35, 5.043227240567294)\n (50, 20, 6.995405134800987)\n (50, 37, 7.546490310071297)\n (50, 39, 3.900154099519657)\n\n\n\n\n\n","category":"method"},{"location":"neighborlists/#CellListMap.neighborlist-Tuple{Any, Any}","page":"Neighbor lists","title":"CellListMap.neighborlist","text":"neighborlist(x, cutoff; unitcell=nothing, parallel=true, show_progress=false)\n\nComputes the list of pairs of particles in x which are closer to each other than cutoff. If the keyword parameter unitcell is provided (as a vector of sides or a general unit cell matrix, periodic boundary conditions are considered). \n\nnote: Note\nThe order of the pairs in the output of neighborlist is not guaranteed, and may change, in particular, in parallel runs.\n\nExample\n\nCompute the neighborlist between within a set Argon atoms, considering the system non-periodic (do not provide a unitcell):\n\njulia> using CellListMap, PDBTools\n\njulia> x = coor(readPDB(CellListMap.argon_pdb_file));\n\njulia> neighborlist(x, 8.0; parallel=false)\n857-element Vector{Tuple{Int64, Int64, Float64}}:\n (1, 20, 3.163779543520692)\n (1, 61, 4.0886518560523095)\n (1, 67, 5.939772807102978)\n (1, 80, 2.457228927063981)\n (1, 94, 5.394713986857875)\n (13, 15, 2.678764267344178)\n (13, 41, 4.408015539900014)\n (13, 44, 6.960112211739117)\n (13, 61, 5.939197673086828)\n (13, 64, 4.560755858407684)\n â‹®\n (46, 18, 6.114385414741209)\n (46, 51, 7.999472795128439)\n (51, 68, 2.200357470957844)\n (51, 22, 6.638020940009152)\n (54, 45, 4.423308377221737)\n (73, 78, 2.853611220891874)\n (73, 88, 6.078711047582372)\n (78, 88, 7.006116541993863)\n (88, 54, 7.933654076149277)\n\nAnd now, considering the system periodic:\n\njulia> using CellListMap, PDBTools\n\njulia> x = coor(readPDB(CellListMap.argon_pdb_file));\n\njulia> neighborlist(x, 8.0; unitcell = [21.0, 21.0, 21.0], parallel=false)\n1143-element Vector{Tuple{Int64, Int64, Float64}}:\n (1, 7, 3.36387559222989)\n (1, 20, 3.163779543520693)\n (1, 47, 6.243868272153088)\n (1, 63, 7.017762962654125)\n (1, 74, 7.976895636774997)\n (1, 79, 3.177028328485598)\n (1, 94, 5.394713986857875)\n (1, 95, 5.4248765884580274)\n (7, 20, 3.3995637955478935)\n (7, 26, 7.96292025578556)\n â‹®\n (57, 34, 6.536566147450816)\n (57, 84, 7.225401442134547)\n (57, 88, 7.971591246420004)\n (68, 14, 5.2021891545771375)\n (68, 34, 3.955899012866733)\n (68, 84, 5.650943284089833)\n (68, 88, 7.254140403934848)\n (68, 38, 7.4092885623384905)\n (68, 90, 7.875801229081395)\n\n\n\n\n\n","category":"method"},{"location":"neighborlists/#CellListMap.update!-Union{Tuple{C}, Tuple{UnitCellType}, Tuple{InPlaceNeighborList{<:Box{UnitCellType}, C}, AbstractVecOrMat}} where {UnitCellType, C<:CellList}","page":"Neighbor lists","title":"CellListMap.update!","text":"update!(system::InPlaceNeighborList, x::AbstractVecOrMat; cutoff=nothing, unitcell=nothing)\nupdate!(system::InPlaceNeighborList, x::AbstractVecOrMat, y::AbstractVecOrMat; cutoff=nothing, unitcell=nothing)\n\nUpdates a InPlaceNeighborList system, by updating the coordinates, cutoff, and unitcell.\n\nExamples\n\nFor self-pairs computations\n\njulia> x = rand(SVector{3,Float64}, 10^3);\n\njulia> system = InPlaceNeighborList(x=x; cutoff=0.1)\nInPlaceNeighborList with types: \nCellList{3, Float64}\nBox{NonPeriodicCell, 3, Float64, Float64, 9}\nCurrent list buffer size: 0\n\njulia> neighborlist!(system);\n\njulia> new_x = rand(SVector{3,Float64}, 10^3);\n\njulia> update!(system, new_x; cutoff = 0.05)\nInPlaceNeighborList with types: \nCellList{3, Float64}\nBox{NonPeriodicCell, 3, Float64, Float64, 9}\nCurrent list buffer size: 1826\n\njulia> neighborlist!(system)\n224-element Vector{Tuple{Int64, Int64, Float64}}:\n (25, 486, 0.03897345036790646)\n â‹®\n (723, 533, 0.04795768478723409)\n (868, 920, 0.042087156715720137)\n\n\n\n\n\n","category":"method"},{"location":"neighborlists/#CellListMap.InPlaceNeighborList-Tuple{}","page":"Neighbor lists","title":"CellListMap.InPlaceNeighborList","text":"InPlaceNeighborList(;\n    x::AbstractVecOrMat,\n    y::Union{AbstractVecOrMat,Nothing}=nothing,\n    cutoff::T,\n    unitcell::Union{AbstractVecOrMat,Nothing}=nothing,\n    parallel::Bool=true,\n    show_progress::Bool=false,\n) where {T}\n\nFunction that initializes the InPlaceNeighborList structure, to be used for in-place computation of neighbor lists.\n\nIf only x is provided, the neighbor list of the set is computed. \nIf x and y are provided, the neighbor list between the sets is computed.\nIf unitcell is provided, periodic boundary conditions will be used. The unitcell can be a vector of Orthorhombic box sides, or an actual unitcell matrix for general cells. \nIf unicell is not provide (value nothing), no periodic boundary conditions will be considered. \n\nExamples\n\nHere the neighborlist structure is constructed for the first time, and used to compute the neighbor lists with the mutating neighborlist! function:\n\njulia> using CellListMap, StaticArrays\n\njulia> x = rand(SVector{3,Float64}, 10^4);\n\njulia> system = InPlaceNeighborList(x=x, cutoff=0.1, unitcell=[1,1,1]) \nInPlaceNeighborList with types: \nCellList{3, Float64}\nBox{OrthorhombicCell, 3, Float64, Float64, 9}\nCurrent list buffer size: 0\n\njulia> neighborlist!(system)\n210034-element Vector{Tuple{Int64, Int64, Float64}}:\n (1, 357, 0.09922225615002134)\n (1, 488, 0.043487074695938925)\n (1, 2209, 0.017779967072139684)\n â‹®\n (9596, 1653, 0.0897570322108541)\n (9596, 7927, 0.0898266280344037)\n\nThe coordinates of the system, its unitcell, or the cutoff can be changed with the update! function. If the number of pairs of the list does not change  significantly, the new calculation is minimally allocating, or non-allocating  at all, in particular if the computation is run without parallelization:\n\nnote: Note\nThe order of the pairs in the output of neighborlist! is not guaranteed, and may change, in particular, in parallel runs.\n\nIf the structure is used repeatedly for similar systems, the allocations will vanish, except for minor allocations used in the threading computation (if a  non-parallel computation is executed, the allocations will vanish completely):\n\njulia> x = rand(SVector{3,Float64}, 10^4);\n\njulia> system = InPlaceNeighborList(x=x, cutoff=0.1, unitcell=[1,1,1]);\n\njulia> @time neighborlist!(system);\n  0.008004 seconds (228 allocations: 16.728 MiB)\n\njulia> update!(system, rand(SVector{3,Float64}, 10^4); cutoff = 0.1, unitcell = [1,1,1]);\n\njulia> @time neighborlist!(system);\n  0.024811 seconds (167 allocations: 7.887 MiB)\n\njulia> update!(system, rand(SVector{3,Float64}, 10^4); cutoff = 0.1, unitcell = [1,1,1]);\n\njulia> @time neighborlist!(system);\n  0.005213 seconds (164 allocations: 1.439 MiB)\n\njulia> update!(system, rand(SVector{3,Float64}, 10^4); cutoff = 0.1, unitcell = [1,1,1]);\n\njulia> @time neighborlist!(system);\n  0.005276 seconds (162 allocations: 15.359 KiB)\n\n\n\n\n\n\n","category":"method"},{"location":"unitcell/#Unitcell-requirements","page":"Unitcell requirements","title":"Unitcell requirements","text":"The unitcell provided by the user must satisfy certain conditionsfor the cell list algorithm to work correctly. If the conditions are not satisfied, the computation will throw an early error. These conditions guarantee that the box is not too small for the given required cutoff, considering the perodic conditions. In the  simple case of orthorhombic boxes, the conditions imply that each side must be greater than twice the cutoff. These conditions are usually met except for very small systems, which are not within the current scope of this package.","category":"section"},{"location":"unitcell/#In-3D","page":"Unitcell requirements","title":"In 3D","text":"Given an unitcell matrix of the form leftvecavecbveccright, where veca, vecb, and  vecc are the lattice vectors, the following conditions must be met:\n\nveca cdot fracvecb times veccvecb times vecc gt 2r_cut\n\nvecb cdot fracvecc times vecavecc times veca gt 2r_cut\n\nvecc cdot fracveca times vecbveca times vecb gt 2r_cut\n\nwhere r_cut is the cutoff. ","category":"section"},{"location":"unitcell/#In-2D","page":"Unitcell requirements","title":"In 2D","text":"Given an unitcell matrix of the form leftvecavecbright, where veca and vecb  are the lattice vectors, the following conditions must be met:\n\nsqrtveca^2 - left(vecacdot fracvecbvecbright)^2 gt 2r_cut \n\nsqrtvecb^2 - left(vecbcdot fracvecavecaright)^2 gt 2r_cut \n\nwhere r_cut is the cutoff. ","category":"section"},{"location":"citation/#Citation","page":"Citation","title":"Citation","text":"If you use this software, please be kind to cite the following article in relevant publications, to keep us motivated in developing  new features and enhancements:\n\nL. MartÃ­nez, CellListMap.jl: Efficient and customizable cell list implementation for calculation of pairwise particle properties within a cutoff. Computer Physics Communications, 279, 108452, (2022). DOI: 10.1016/j.cpc.2022.108452","category":"section"},{"location":"ecosystem/#Ecosystem-integration","page":"Ecosystem integration","title":"Ecosystem integration","text":"Agents.jl\nUnitful and units\nAutomatic differentiation\nMeasurements","category":"section"},{"location":"ecosystem/#Agents.jl","page":"Ecosystem integration","title":"Agents.jl","text":"Agents.jl provides a comprehensive framework for simulation, analysis and visualization of agent-based systems. CellListMap can be used to accelerate these simulations, and the integration of the packages is rather simple, particularly using the ParticleSystem interface. A complete integration example can be obtained in the Agents documentation (currently at the development branch). \n\nThe example will produce the following animation:\n\n<video width=\"auto\" controls autoplay loop>\n<source src=\"https://juliadynamics.github.io/Agents.jl/stable/examples/celllistmap.mp4\" type=\"video/mp4\">\n</video>","category":"section"},{"location":"ecosystem/#Unitful-and-units","page":"Ecosystem integration","title":"Unitful and units","text":"The functions of CellListMap.jl support the propagation of generic (isbits) types, and thus units and thus automatic differentiation and the use of Unitful. A set of working examples can be found in the generic_types.jl file.\n\nWe start illustrating the support for unit propagation. We need to define all involved quantities in the same units:","category":"section"},{"location":"ecosystem/#Using-the-ParticleSystem-interface","page":"Ecosystem integration","title":"Using the ParticleSystem interface","text":"The only requirement is to attach proper units to all quantities (positions, cutoff, unitcell, and output variables). Here we compute the square of the distances of the particles within the cutoff, where the particle coordinates are in Angstroms, while the box size and cutoff are defined in nanometers:\n\njulia> using CellListMap, Unitful, PDBTools\n\njulia> positions = coor(readPDB(CellListMap.argon_pdb_file))u\"Ã…\";\n\njulia> system = ParticleSystem(\n           positions = positions,\n           cutoff = 0.8u\"nm\",\n           unitcell = [2.1,2.1,2.1]u\"nm\",\n           output = 0.0u\"nm^2\",\n           output_name = :sum_sqr\n       );\n\njulia> map_pairwise((x,y,i,j,d2,out) -> out += d2, system)\n437.74543675999995 nm^2","category":"section"},{"location":"ecosystem/#Units-in-neighbor-lists","page":"Ecosystem integration","title":"Units in neighbor lists","text":"CellListMap.neighborlist also propagates units correctly:\n\njulia> using CellListMap, Unitful, PDBTools\n\njulia> positions = coor(readPDB(CellListMap.argon_pdb_file))u\"Ã…\";\n\njulia> cutoff = 0.8u\"nm\";\n\njulia> neighborlist(positions, cutoff)\n857-element Vector{Tuple{Int64, Int64, Quantity{Float64, ð‹, Unitful.FreeUnits{(nm,), ð‹, nothing}}}}:\n (1, 20, 0.3163779543520692 nm)\n (1, 61, 0.408865185605231 nm)\n (1, 67, 0.5939772807102979 nm)\n (1, 80, 0.24572289270639777 nm)\n (1, 94, 0.5394713986857874 nm)\n (13, 15, 0.2678764267344179 nm)\n (13, 41, 0.4408015539900013 nm)\n (13, 44, 0.6960112211739119 nm)\n (13, 61, 0.5939197673086826 nm)\n (13, 64, 0.45607558584076857 nm)\n â‹®\n (46, 18, 0.6114385414741209 nm)\n (46, 51, 0.799947279512844 nm)\n (51, 68, 0.22003574709578452 nm)\n (51, 22, 0.663802094000915 nm)\n (54, 45, 0.44233083772217385 nm)\n (73, 78, 0.2853611220891873 nm)\n (73, 88, 0.6078711047582371 nm)\n (78, 88, 0.7006116541993859 nm)\n (88, 54, 0.7933654076149276 nm)","category":"section"},{"location":"ecosystem/#Automatic-differentiation","page":"Ecosystem integration","title":"Automatic differentiation","text":"Allowing automatic differentiation follows the same principles, meaning that we only need to allow the propagation of dual types through the computation by proper initialization of the input data. However, it is easier to work with the low level interface, which accepts matrices as the input for positions and a more fine control of the types of the variables. Matrices are easier input types for auto diff packages.\n\nThe variables are each component of each vector, thus the easiest way to represent the points to interface with differentiation packages is providing the coordinates as a matrix:\n\njulia> x = rand(3,1000)\n3Ã—1000 Matrix{Float64}:\n 0.186744  0.328719  0.874102  0.503535   â€¦  0.328161  0.0895699  0.917338\n 0.176157  0.972954  0.80729   0.624724      0.655268  0.470754   0.327578\n 0.648482  0.537362  0.599624  0.0688776     0.92333   0.497984   0.208924\n\nThe key here is allow all the types of the parameters to follow the type propagation of the elements of x inside the differentiation routine. The function we define to compute the derivative is, then:\n\njulia> function sum_sqr(x, sides, cutoff)\n           sys = ParticleSystem(\n               positions=x,\n               unitcell=eltype(x).(sides),\n               cutoff=eltype(x).(cutoff),\n               output=zero(eltype(x))\n           )\n           return  map_pairwise((_, _, _, _, d2, sum_sqr) -> sum_sqr += d2, sys)\n       end\n\nNote that we convert cutoff and sides  to the same type of the input x  of the function, and set the type of the output variable accordingly. For a simple call to the function this is inconsequential:\n\njulia> cutoff = 0.1; sides = [1,1,1];\n\njulia> sum_sqr(x,sides,cutoff)\n12.897650398753228\n\nbut the conversion is required to allow the differentiation to take place:\n\njulia> ForwardDiff.gradient(x -> sum_sqr(x,sides,cutoff),x)\n3Ã—1000 Matrix{Float64}:\n -0.132567   0.029865  -0.101301  â€¦   0.249267    0.0486424  -0.0400487\n  0.122421   0.207495  -0.184366     -0.201648   -0.105031    0.218342\n  0.0856502  0.288924   0.122445     -0.0147022  -0.103314   -0.0862264","category":"section"},{"location":"ecosystem/#Measurements","page":"Ecosystem integration","title":"Measurements","text":"Propagating uncertainties through the Measurements  and other similar packages requires a different strategy, because within CellListMap only isbits types can be used, which is not the case of the type Measurement type. \n\nIn cases like this, it is better to bypass all the internals of CellListMap  and provide the data to the function that computes pairwise properties directly as a closure. For example:\n\nA vector of particles with uncertainties in their coordinates can be created with: \n\njulia> using StaticArrays \n\njulia> x_input = [ SVector{3}(measurement(rand(),0.01*rand()) for i in 1:3) for j in 1:1000 ]\n1000-element Vector{SVector{3, Measurement{Float64}}}:\n [0.1658 Â± 0.003, 0.9951 Â± 0.0054, 0.5067 Â± 0.0035]\n [0.2295 Â± 0.0074, 0.2987 Â± 0.0021, 0.42828 Â± 0.00099]\n â‹®\n [0.1362 Â± 0.0034, 0.2219 Â± 0.0048, 0.2119 Â± 0.0072]\n [0.2521 Â± 0.0038, 0.4988 Â± 0.00013, 0.856046 Â± 4.3e-5]\n\nThe variables within the CellListMap functions will be stripped from the uncertainties. We do:\n\njulia> unitcell = [1,1,1]\n\njulia> cutoff = 0.1; box = Box(unitcell,cutoff);\n\njulia> x_strip = [ getproperty.(v,:val) for v in x_input ]\n1000-element Vector{SVector{3, Float64}}:\n [0.08441931492362276, 0.9911530546181084, 0.07408559584648788]\n [0.12084764467339837, 0.8284551316333133, 0.9021906852432111]\n â‹®\n [0.2418752113326077, 0.4429225751775432, 0.13576355747772784]\n [0.24440380524702654, 0.07148275176890073, 0.26722687487212315]\n\nThe cell list is built with the stripped values:\n\njulia> cl = CellList(x_strip,box)\nCellList{3, Float64}\n  1000 real particles.\n  637 cells with real particles.\n  1695 particles in computing box, including images.\n\nThe result is initialized with the proper type,\n\njulia> result = measurement(0.,0.)\n0.0 Â± 0.0\n\nand the mapping is performed with the stripped coordinates, but passing the values with uncertainties to the mapped function, which will perform the computation on the pairs with those values:\n\njulia> using LinearAlgebra: norm_sqr\n\njulia> result = map_pairwise!(\n           (xáµ¢,xâ±¼,i,j,d2,sum_sqr) -> begin\n               x1 = x_input[i]\n               x2 = CellListMap.wrap_relative_to(x_input[j],x1,unitcell)\n               sum_sqr += norm_sqr(x2-x1)\n               return sum_sqr\n           end, \n           result, box, cl\n       )\n13.14 Â± 0.061\n\nIn the function above, the xáµ¢ and xâ±¼ coordinates, which correspond to the coordinates in x_input[i] and x_input[j], but already wrapped relative to each other, are ignored, because they don't carry the uncertainties. We use only the indexes i and j to recompute the relative position of the particles according to the periodic boundary conditions (using the CellListMap.wrap_relative_to function) and their (squared) distance. Since the x_input  array carries the uncertainties, the computation of sum_sqr will propagate them.   \n\nnote: Note\nAll these computations should be performed inside the scope of a function for optimal performance. The examples here can be followed by copying and pasting the code into the REPL, but this is not the recommended practice for critical code. The strategy of bypassing the internal computations of CellListMap may be useful for improving performance even if the previous and simpler method is possible. ","category":"section"},{"location":"ParticleSystem/#ParticleSystem-interface","page":"ParticleSystem interface","title":"ParticleSystem interface","text":"The ParticleSystem interface facilitates the use of CellListMap for the majority of cases. \n\nnote: Note\nThis interface requires CellListMap.jl version 0.8.30 or greater.\nThe complete codes of the examples are at the end of this page, with examples of:\nSimple energy computation\nForce computation\nEnergy and forces\nTwo sets of particles\nParticle simulation\n\ncompat: Compat\nThe ParticleSystem interface is available since version 0.9.0 of CellListMap.jl. It replaces the PeriodicSystems interface available in previous versions.","category":"section"},{"location":"ParticleSystem/#The-mapped-function","page":"ParticleSystem interface","title":"The mapped function","text":"The purpose of CellListMap is to compute a pairwise-dependent function for all pairs of particles that are closer to each other than a defined cutoff. This pairwise function must be implemented by the user and adhere to the following  interface:  \n\nfunction f(x, y, i, j, d2, output)\n    # update output variable\n    return output\nend\n\nwhere x and y are the positions of the particles, already wrapped relative to each other according to the periodic boundary conditions (a minimum-image set of positions), i and j are the indexes of the particles in the arrays of coordinates, d2 is the squared distance between the particles, and output is the variable to be computed. \n\ninfo: Info\nDetails of the mapped function interfaceThe input parameters x, y, i, j, and d2 must not be modified by the user. They are the the input data that the user may use to update the output variable.  Input Parameter Type Meaning\nx SVector The coordinates of particle i of the pair.\ny SVector The coordinates of particle j of the pair (minimum-image relative to x).\ni Int Index of first particle in the original array of coordinates.\nj Int Index of second particle in the original array of coordinates.\nd2 <:Real Squared distance between the particles.\noutput user defined the value to be updatedNotes: x and y may be 2D or 3D vectors, depending on the dimension of the system. The type of  the coordinates of x, y, and of d2 are dependent on the input arrays and cutoff, and can be Float64, Float32, unitful quantities, etc. Return value Type Meaning\noutput user defined the updated value of output.The output variable must be returned by the function, being it mutable or immutable. ","category":"section"},{"location":"ParticleSystem/#Basic-examples","page":"ParticleSystem interface","title":"Basic examples","text":"For example, computing the energy, as the sum of the inverse of the distance between particles, can be done with a function like:\n\nfunction energy(d2,u)\n    u += 1 / sqrt(d2)\n    return u\nend\n\nand the additional parameters required by the interface can be eliminated by the use of an anonymous function, directly on the call to the map_pairwise function:\n\nu = map_pairwise(\n    (x,y,i,j,d2,u) -> energy(d2,u), \n    system\n)\n\n(what system is will be explained in the examples below). Note that the energy function does not use the x, y, i, and j input parameters, such  that the anonymous function managing the interface could also be written as (_, _, _, _, d2, u) -> energy(d2, u), making explicit the dummy character of these variables in the example.\n\nAlternatively, the function might require additional parameters, such as the masses of the particles. In this case, we can use a closure to provide such data:\n\nfunction energy(i,j,d2,u,masses)\n    u += masses[i]*masses[j] / sqrt(d2)\n    return u\nend\nconst masses = # ... some masses\nu = map_pairwise((x,y,i,j,d2,u) -> energy(d2,u,masses), system)\n\nHere we reinforce the fact that the energy functions defined above compute the contribution to the energy of the interaction of a single pair of particles. This function will be called for every pair of particles within the cutoff, automatically, in the map_pairwise call. \n\nnote: Note\nThe output of the CellListMap computation may be of any kind. Most commonly, it is an energy, a set of forces, or other data type that can be represented either as a number, an array of numbers, or an array of vectors (SVectors in particular), such as an arrays of forces.  Additionally, the properties are frequently additive (the energy is the sum of the energy of the particles, or the forces are added by summation). For these types of output data the usage does not require the implementation of any data-type dependent function. ","category":"section"},{"location":"ParticleSystem/#The-ParticleSystem-constructor","page":"ParticleSystem interface","title":"The ParticleSystem constructor","text":"","category":"section"},{"location":"ParticleSystem/#Potential-energy-example","page":"ParticleSystem interface","title":"Potential energy example","text":"For example, here we read the coordinates of Argon atoms from a PDB file. The coordinates are given as  vector of SVectors. We then compute an \"energy\", which in this case is simply the sum of 1/d over all pair of particles, within a cutoff.\n\nThe ParticleSystem constructor receives the properties of the system and sets up automatically the most commonly used data structures necessary. \n\njulia> using CellListMap, PDBTools\n\njulia> argon_coordinates = coor(readPDB(CellListMap.argon_pdb_file))\n\njulia> system = ParticleSystem(\n           xpositions=argon_coordinates,\n           unitcell=[21.0,21.0,21.0], \n           cutoff = 8.0, \n           output = 0.0,\n           output_name = :energy\n       );\n\nnote: Note\nSystems can be 2 or 3-dimensional. \nThe unitcell parameter may be:\na vector, in which case the system periodic boundaries are Orthorhombic, this is faster.\na matrix, in which case the system periodic boundaries are Triclinic (general). The lattice vectors correspond to the columns of the matrix.\nnothing (by default), in which case no periodic boundary conditions will be used.\nUnitful quantities can be provided, given appropriate types for all input parameters. \n\nNow, let us compute the energy of the particles, assuming a simple formula which depends on the inverse of the distance between pairs:\n\njulia> function energy(x, y, i, j, d2, energy)\n           energy += 1 / sqrt(d2)\n           return energy\n       end\n\njulia> map_pairwise!(energy, system)\n207.37593043370865\n\nNote that the first four parameters of energy are not used here but are needed to adhere to the interface. The function  input could be written as (_, _, _, _, d2, energy) to make that explicit. \n\nBecause output_name was set to :energy, the system.energy field accesses the resulting value of the computation:\n\njulia> system.energy\n207.37593043370865\n\nIf the output_name field is not provided, the output value from the system.output field.","category":"section"},{"location":"ParticleSystem/#Computing-forces","page":"ParticleSystem interface","title":"Computing forces","text":"Following the example above, let us compute the forces between the particles. We have to define the function that computes the force between a pair of particles and updates the array of forces:\n\nfunction update_forces!(x,y,i,j,d2,forces)\n    d = sqrt(d2)\n    df = (1/d2)*(1/d)*(y - x)\n    forces[i] += df\n    forces[j] -= df\n    return forces\nend\n\nImportantly, the function must return the forces array to follow the API. \n\nNow, let us setup the system with the new type of output variable, which will be now an array of forces with the same type as the positions:\n\njulia> using CellListMap, PDBTools\n\njulia> argon_coordinates = coor(readPDB(CellListMap.argon_pdb_file))\n\njulia> system = ParticleSystem(\n           xpositions=argon_coordinates,\n           unitcell=[21.0, 21.0, 21.0], \n           cutoff = 8.0, \n           output = similar(argon_coordinates),\n           output_name = :forces\n       );\n\nLet us note that the forces where reset upon the construction of the system:\n\njulia> system.forces\n1000-element Vector{SVector{3, Float64}}:\n [0.0, 0.0, 0.0]\n [0.0, 0.0, 0.0]\n â‹®\n [0.0, 0.0, 0.0]\n\nA call to map_pairwise! with the appropriate function definition will update the forces:\n\njulia> map_pairwise!((x,y,i,j,d2,forces) -> update_forces!(x,y,i,j,d2,forces), system)\n100-element Vector{SVector{3, Float64}}:\n [0.026493833307357332, 0.18454277989323772, -0.012253902366284965]\n [0.07782602581235695, 0.2791082233740261, 0.21926615329195248]\n â‹®\n [0.11307234751448932, 0.006353545239676281, -0.05955687310348302]\n [-0.03101200918307673, 0.03543655648545697, 0.031849121630976335]","category":"section"},{"location":"ParticleSystem/#Computing-both-energy-and-forces","page":"ParticleSystem interface","title":"Computing both energy and forces","text":"In this example we define a general type of output variable, for which custom copy, reset, and reduction functions must be defined. It can be followed for the computation of other general properties from the particle positions.\n\nnote: Note\nInterface to be implemented:Method Return What it does\ncopy_output(x::T) new instance of type T Copies an element of the output type T.\nreset_output!(x::T) mutated x Resets (usually zero) the value of x to the initial value it must assume before mapping.  If x is immutable, the function can return a new instance of T.\nreducer(x::T,y::T) mutated x Reduces x and y into x (for example x = x + y). If x is immutable, returns a new instance of type T.Remark: if the output is an array of an immutable type T, the methods above can be defined for single instances of T, which is simpler than for the arrays.\n\nusing CellListMap, StaticArrays, PDBTools\n\nThe computation of energies and forces in a single call is an interesting example for the definition of a custom output type and the required interface functions.  Let us first define an output variable containing both quantities:\n\nmutable struct EnergyAndForces\n    energy::Float64\n    forces::Vector{SVector{3,Float64}}\nend\n\nNow we need to define what it means to copy, reset, and reduce this new type of output. We overload the default corresponding functions, for our new output type:\n\nThe copy method creates a new instance of the EnergyAndForces type, with copied data:\n\nfunction CellListMap.copy_output(x::EnergyAndForces) \n    return EnergyAndForces(copy(x.energy), copy(x.forces))\nend\n\nThe reset method will zero both the energy and all forces:\n\nfunction CellListMap.reset_output!(output::EnergyAndForces)\n    output.energy = 0.0\n    for i in eachindex(output.forces)\n        output.forces[i] = SVector(0.0, 0.0, 0.0)\n    end\n    return output\nend\n\nThe reducer function defines what it means to combine two output variables obtained on independent threads. In this case, we sum the energies and forces. Different reduction functions might be necessary for other custom types (for example if computing minimum distances).\n\nfunction CellListMap.reducer(x::EnergyAndForces, y::EnergyAndForces)\n    e_tot = x.energy + y.energy\n    x.forces .+= y.forces\n    return EnergyAndForces(e_tot, x.forces)\nend\n\nNote that in the above example, we reuse the x.forces array in the return instance of EnergyAndForces. You must always reduce from right to left, and reuse the possible buffers of the first argument of the reducer (in this case, x).\n\nwarning: Warning\nAll these functions must return the modified output variable, to adhere to the interface.\nThe proper definition of a reduction function is crucial for correctness. Please verify your results if using the default reducer function, which sums the elements.\n\nNow we can proceed as before, defining a function that updates the output variable appropriately:\n\nfunction energy_and_forces!(x,y,i,j,d2,output::EnergyAndForces)\n    d = sqrt(d2)\n    output.energy += 1/d\n    df = (1/d2)*(1/d)*(y - x)\n    output.forces[i] += df\n    output.forces[j] -= df\n    return output\nend\n\nTo finally define the system and compute the properties:\n\nargon_coordinates = coor(readPDB(CellListMap.argon_pdb_file))\n\nsystem = ParticleSystem(\n    xpositions = argon_coordinates,\n    unitcell = [21.0, 21.0, 21.0], \n    cutoff = 8.0, \n    output = EnergyAndForces(0.0, similar(argon_coordinates)),\n    output_name = :energy_and_forces\n);\n\nmap_pairwise((x,y,i,j,d2,output) -> energy_and_forces!(x,y,i,j,d2,output), system);\n\nThe output can be seen with the aliases of the system.output variable:\n\njulia> system.energy_and_forces.energy\n207.37593043370862\n\njulia> system.energy_and_forces.forces\n100-element Vector{SVector{3, Float64}}:\n [0.02649383330735732, 0.18454277989323772, -0.012253902366284958]\n [0.07782602581235692, 0.27910822337402613, 0.21926615329195248]\n â‹®\n [0.11307234751448932, 0.006353545239676281, -0.05955687310348303]\n [-0.031012009183076745, 0.03543655648545698, 0.03184912163097636]","category":"section"},{"location":"ParticleSystem/#Updating-coordinates,-unit-cell,-and-cutoff","page":"ParticleSystem interface","title":"Updating coordinates, unit cell, and cutoff","text":"If the map_pairwise! function will compute energy and/or forces in a iterative procedure (a simulation, for instance), we need to update the coordinates, and perhaps the unit cell and the cutoff.\n\nUpdating coordinates\nUpdating the unit cell\nUpdating the cutoff","category":"section"},{"location":"ParticleSystem/#Updating-coordinates","page":"ParticleSystem interface","title":"Updating coordinates","text":"The coordinates can be updated (mutated, or the array of coordinates can change in size by pushing or deleting particles), simply by directly accessing the xpositions field of the system. The xpositions array is a Vector of SVector (from StaticArrays), with coordinates copied from the input array provided. Thus, the coordinates in the ParticleSystem structure must be updated independently of updates in the original array of coordinates. \n\nLet us exemplify the interface with the computation of forces:\n\njulia> using CellListMap, StaticArrays\n\njulia> positions = rand(SVector{3,Float64}, 1000);\n\njulia> system = ParticleSystem(\n           xpositions = positions,\n           unitcell=[1,1,1], \n           cutoff = 0.1, \n           output = similar(positions),\n           output_name = :forces\n       );\n\njulia> system.xpositions[1]\n3-element SVector{3, Float64} with indices SOneTo(3):\n 0.6391290709055079\n 0.43679325975360894\n 0.8231829019768698\n\njulia> system.xpositions[1] = zeros(SVector{3,Float64})\n3-element SVector{3, Float64} with indices SOneTo(3):\n 0.0\n 0.0\n 0.0\n\njulia> push!(system.xpositions, SVector(0.5, 0.5, 0.5))\n1001-element Vector{SVector{3, Float64}}:\n [0.0, 0.0, 0.0]\n [0.5491373098208292, 0.23899915605319244, 0.49058287555218516]\n â‹®\n [0.4700394061063937, 0.5440026379397457, 0.7411235688716618]\n [0.5, 0.5, 0.5]\n\nwarning: Warning\nThe output variable may have to be resized accordingly, depending on the calculation being performed. Use the resize_output! function  (do not use Base.resize! on your output array directly).\n\nIf the output array has to be resized, that has to be done with the  resize_output! function, which will keep the consistency of the auxiliary multi-threading buffers. This is, for instance, the case  in the example of computation of forces, as the forces array must be of the same length as the array of positions:\n\njulia> resize_output!(system, length(system.xpositions));\n\njulia> map_pairwise!((x,y,i,j,d2,forces) -> update_forces!(x,y,i,j,d2,forces), system)\n1001-element Vector{SVector{3, Float64}}:\n [756.2076075886971, -335.1637545330828, 541.8627090466914]\n [-173.02442398784672, -178.782819965489, 4.570607952876692]\n â‹®\n [-722.5400961501635, 182.65287417718935, 380.0394926753039]\n [20.27985502389337, -193.77607810950286, -155.28968519541544]\n\nIn this case, if the output is not resized, a BoundsError: is be obtained, because updates of forces at unavailable positions will be attempted. ","category":"section"},{"location":"ParticleSystem/#Updating-the-unit-cell","page":"ParticleSystem interface","title":"Updating the unit cell","text":"The unit cell can be updated to new dimensions at any moment, with the update_unitcell! function:\n\njulia> update_unitcell!(system, SVector(1.2, 1.2, 1.2))\nParticleSystem1 of dimension 3, composed of:\n    Box{OrthorhombicCell, 3}\n      unit cell matrix = [ 1.2, 0.0, 0.0; 0.0, 1.2, 0.0; 0.0, 0.0, 1.2 ]\n      cutoff = 0.1\n      number of computing cells on each dimension = [13, 13, 13]\n      computing cell sizes = [0.11, 0.11, 0.11] (lcell: 1)\n      Total number of cells = 2197\n    CellListMap.CellList{3, Float64}\n      1000 real particles.\n      623 cells with real particles.\n      1719 particles in computing box, including images.\n    Parallelization auxiliary data set for: \n      Number of batches for cell list construction: 8\n      Number of batches for function mapping: 12\n    Type of output variable (forces): Vector{SVector{3, Float64}}\n\nnote: Note\nThe unit cell can be set initially using a vector or a unit cell matrix. If a vector is provided the system is considered Orthorhombic, if a matrix is provided, a Triclinic system is built.  Unit cells updates must preserve the system type. \nThe unit cell of non-periodic systems (initialized with nothing) cannot be updated manually.\nIt is recommended (but not mandatory) to use static arrays (or Tuples) to update the unitcell,  as in this case the update will be non-allocating. ","category":"section"},{"location":"ParticleSystem/#Updating-the-cutoff","page":"ParticleSystem interface","title":"Updating the cutoff","text":"The cutoff can also be updated, using the update_cutoff! function:\n\njulia> update_cutoff!(system, 0.2)\nParticleSystem1 of dimension 3, composed of:\n    Box{OrthorhombicCell, 3}\n      unit cell matrix = [ 1.0, 0.0, 0.0; 0.0, 1.0, 0.0; 0.0, 0.0, 1.0 ]\n      cutoff = 0.2\n      number of computing cells on each dimension = [7, 7, 7]\n      computing cell sizes = [0.2, 0.2, 0.2] (lcell: 1)\n      Total number of cells = 343\n    CellListMap.CellList{3, Float64}\n      1000 real particles.\n      125 cells with real particles.\n      2792 particles in computing box, including images.\n    Parallelization auxiliary data set for: \n      Number of batches for cell list construction: 8\n      Number of batches for function mapping: 8\n    Type of output variable (forces): Vector{SVector{3, Float64}}\n\njulia> map_pairwise!((x,y,i,j,d2,forces) -> update_forces!(x,y,i,j,d2,forces), system)\n1000-element Vector{SVector{3, Float64}}:\n [306.9612911344924, -618.7375562535321, -607.1449767066479]\n [224.0803003775478, -241.05319348787023, 67.53780411933884]\n â‹®\n [2114.4873184508524, -3186.265279868732, -6777.748445712408]\n [-25.306486853608945, 119.69319481834582, 104.1501577339471]","category":"section"},{"location":"ParticleSystem/#Computations-for-two-sets-of-particles","page":"ParticleSystem interface","title":"Computations for two sets of particles","text":"If the computation involves two sets of particle, a similar interface is available.  The only difference is that the coordinates of the two sets must be provided to the ParticleSystem constructor as the xpositions and ypositions arrays.\n\nWe will illustrate this interface by computing the minimum distance between two sets of particles, which allows us to showcase further the definition of custom type interfaces:\n\nFirst, we define a variable type that will carry the indexes and  the distance of the closest pair of particles:\n\njulia> struct MinimumDistance\n           i::Int\n           j::Int\n           d::Float64\n       end\n\nThe function that, given two particles, retains the minimum distance, is:\n\njulia> function minimum_distance(i, j, d2, md)\n           d = sqrt(d2)\n           if d < md.d\n               md = MinimumDistance(i, j, d)\n           end\n           return md\n       end\nminimum_distance (generic function with 1 method)\n\nWe overload copy, reset, and reduce functions, accordingly:\n\njulia> import CellListMap: copy_output, reset_output!, reducer!\n\njulia> copy_output(md::MinimumDistance) = md\ncopy_output (generic function with 5 methods)\n\njulia> reset_output!(md::MinimumDistance) = MinimumDistance(0, 0, +Inf)\nreset_output! (generic function with 5 methods)\n\njulia> reducer!(md1::MinimumDistance, md2::MinimumDistance) = md1.d < md2.d ? md1 : md2\nreducer! (generic function with 2 methods)\n\nNote that since MinimumDistance is immutable, copying it is the same as returning the value.  Also, resetting the minimum distance consists of setting its d field to +Inf. And, finally, reducing the threaded distances consists of keeping the pair with the shortest distance. \n\nNext, we build the system\n\njulia> xpositions = rand(SVector{3,Float64},1000);\n\njulia> ypositions = rand(SVector{3,Float64},1000);\n\njulia> system = ParticleSystem(\n           xpositions = xpositions,\n           ypositions = ypositions, \n           unitcell=[1.0,1.0,1.0], \n           cutoff = 0.1, \n           output = MinimumDistance(0,0,+Inf),\n           output_name = :minimum_distance,\n        )\n\nAnd finally we can obtain the minimum distance between the sets: \n\njulia> map_pairwise((x,y,i,j,d2,md) -> minimum_distance(i,j,d2,md), system)\nMinimumDistance(276, 617, 0.006009804808785543)","category":"section"},{"location":"ParticleSystem/#Additional-options","page":"ParticleSystem interface","title":"Additional options","text":"Turn parallelization on and off\nDisplaying a progress bar\nFine control of the parallelization\nAvoid cell list updating\nControl CellList cell size\nCoordinates as matrices","category":"section"},{"location":"ParticleSystem/#Turn-parallelization-on-and-off","page":"ParticleSystem interface","title":"Turn parallelization on and off","text":"The use of parallel computations can be tunned on and of by the system.parallel boolean flag. For example, using 6 cores (12 threads) for the calculation of the minimum-distance example: \n\njulia> f(system) = map_pairwise((x,y,i,j,d2,md) -> minimum_distance(i,j,d2,md), system)\nf (generic function with 1 method)\n\njulia> Threads.nthreads()\n8\n\njulia> system.parallel = true\ntrue\n\njulia> @btime f($system)\n  268.265 Î¼s (144 allocations: 16.91 KiB)\nMinimumDistance(783, 497, 0.007213710914619913)\n\njulia> system.parallel = false\nfalse\n\njulia> @btime f($system)\n  720.304 Î¼s (0 allocations: 0 bytes)\nMinimumDistance(783, 497, 0.007213710914619913)","category":"section"},{"location":"ParticleSystem/#Displaying-a-progress-bar","page":"ParticleSystem interface","title":"Displaying a progress bar","text":"Displaying a progress bar: for very long runs, the user might want to see the progress of the computation. Use the show_progress keyword parameter of the map_pairwise!  function for that.\n\nFor example, we execute the computation above, but with much more particles:\n\njulia> xpositions = rand(SVector{3,Float64},10^6);\n\njulia> ypositions = rand(SVector{3,Float64},10^6);\n\njulia> system = ParticleSystem(\n                  xpositions = xpositions,\n                  ypositions = ypositions, \n                  unitcell=[1.0,1.0,1.0], \n                  cutoff = 0.1, \n                  output = MinimumDistance(0,0,+Inf),\n                  output_name = :minimum_distance,\n               );\n\njulia> map_pairwise(\n           (x,y,i,j,d2,md) -> minimum_distance(i,j,d2,md), system; \n           show_progress = true\n       )\nProgress:  24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                               |  ETA: 0:00:29\n\nBy activating the show_progress flag, a nice progress bar is shown. ","category":"section"},{"location":"ParticleSystem/#Fine-control-of-the-parallelization","page":"ParticleSystem interface","title":"Fine control of the parallelization","text":"The number of batches launched in parallel runs can be tunned by the  nbatches keyword parameter of the ParticleSystem constructor.  By default, the number of batches is defined as heuristic function  dependent on the number of particles, and possibly returns optimal values in most cases. For a detailed discussion about this parameter,  see Number of batches.\n\nFor example, to set the number of batches for cell list calculation to 4 and the number of batches for mapping to 8, we can do:\n\njulia> system = ParticleSystem(\n           xpositions = rand(SVector{3,Float64},1000), \n           unitcell=[1,1,1], \n           cutoff = 0.1, \n           output = 0.0,\n           output_name = :energy,\n           nbatches=(4,8), # use this keyword \n       );\n\nMost times it is expected that the default parameters are optimal. But particularly for  inhomogeneous systems increasing the number of batches of the mapping phase (second parameter of the tuple) may improve the performance by reducing the idle time of  threads.","category":"section"},{"location":"ParticleSystem/#Avoid-cell-list-updating","page":"ParticleSystem interface","title":"Avoid cell list updating","text":"To compute different properties without recomputing cell lists, use update_lists=false in  the call of map_pairwise methods, for example,\n\nusing CellListMap, StaticArrays\nsystem = ParticleSystem(xpositions=rand(SVector{3,Float64},1000), output=0.0, cutoff=0.1, unitcell=[1,1,1])\n# First call, will compute the cell lists\nmap_pairwise((x,y,i,j,d2,u) -> u += d2, system)\n# Second run: do not update the cell lists but compute a different property\nmap_pairwise((x,y,i,j,d2,u) -> u += sqrt(d2), system; update_lists = false)\n\nin which case we are computing the sum of distances from the same cell lists used to compute the energy in the previous example (requires version 0.8.9). Specifically, this will skip the updating of the cell lists, thus be careful to not use this option if the cutoff, unitcell, or any other property of the system changed. \n\nFor systems with two sets of particles, the  coordinates of the xpositions set can be updated, preserving the cell lists computed for the ypositions, but this requires setting autoswap=false in the construction of the ParticleSystem: \n\nusing CellListMap, StaticArrays\nsystem = ParticleSystem(\n    xpositions=rand(SVector{3,Float64},1000), \n    ypositions=rand(SVector{3,Float64},2000),\n    output=0.0, cutoff=0.1, unitcell=[1,1,1],\n    autoswap=false # Cell lists are constructed for ypositions\n)\nmap_pairwise((x,y,i,j,d2,u) -> u += d2, system)\n# Second run: preserve the cell lists but compute a different property\nmap_pairwise((x,y,i,j,d2,u) -> u += sqrt(d2), system; update_lists = false)","category":"section"},{"location":"ParticleSystem/#Control-CellList-cell-size","page":"ParticleSystem interface","title":"Control CellList cell size","text":"The cell sizes of the construction of the cell lists can be controled with the keyword lcell of the ParticleSystem constructor. For example:\n\njulia> system = ParticleSystem(\n           xpositions = rand(SVector{3,Float64},1000), \n           unitcell=[1,1,1], \n           cutoff = 0.1, \n           output = 0.0,\n           output_name = :energy,\n           lcell=2,\n       );\n\nMost times using lcell=1 (default) or lcell=2 will provide the optimal performance. For very dense systems, or systems for which the number of particles within the cutoff is very large, larger values of lcell may improve the performance. To be tested by the user.\n\nnote: Note\nThe number of cells in which the particles will be classified is, for each dimension lcell*length/cutoff.  Thus if the length of the box is too large relative to the cutoff, many cells will be created, and this imposes a perhaps large memory requirement. Usually, it is a good practice to limit the number of cells to be not greater than the number of particles, and for that the cutoff may have to be increased, if there is a memory bottleneck. A reasonable choice is to use cutoff = max(real_cutoff, length/n^(1/D)) where n is the  number of particles and D is the dimension (2 or 3). With that the number of cells will be close to n in the worst case.  ","category":"section"},{"location":"ParticleSystem/#Coordinates-as-matrices","page":"ParticleSystem interface","title":"Coordinates as matrices","text":"Coordinates can also be provided as matrices of size (D,N) where D is the dimension (2 or 3) and N is the number of particles. For example:\n\njulia> using CellListMap\n\njulia> system = ParticleSystem(\n           xpositions=rand(2,100),\n           ypositions=rand(2,200),\n           cutoff=0.1,\n           unitcell=[1,1],\n           output=0.0,\n       )\nParticleSystem2{output} of dimension 2, composed of:\n    Box{OrthorhombicCell, 2}\n      unit cell matrix = [ 1.0 0.0; 0.0 1.0 ]\n      cutoff = 0.1\n      number of computing cells on each dimension = [13, 13]\n      computing cell sizes = [0.1, 0.1] (lcell: 1)\n      Total number of cells = 169\n    CellListMap.CellListPair{Vector{StaticArraysCore.SVector{2, Float64}}, 2, Float64, CellListMap.Swapped}\n       200 particles in the reference vector.\n       61 cells with real particles of target vector.\n    Parallelization auxiliary data set for:\n      Number of batches for cell list construction: 1\n      Number of batches for function mapping: 1\n    Type of output variable (output): Float64\n\nwarning: Warning\nThis interface less flexible than when the coordinates are input as vectors of vectors, because the number of particles cannot be changed, because matrices cannot be resized. Otherwise, matrices can be used as input.","category":"section"},{"location":"ParticleSystem/#Complete-example-codes","page":"ParticleSystem interface","title":"Complete example codes","text":"Simple energy computation\nForce computation\nEnergy and forces\nTwo sets of particles\nParticle simulation","category":"section"},{"location":"ParticleSystem/#Simple-energy-computation","page":"ParticleSystem interface","title":"Simple energy computation","text":"In this example, a simple potential energy defined as the sum of the  inverse of the distance between the particles is computed.\n\nusing CellListMap\nusing StaticArrays\nsystem = ParticleSystem(\n    xpositions = rand(SVector{3,Float64},1000), \n    unitcell=[1.0,1.0,1.0], \n    cutoff = 0.1, \n    output = 0.0,\n    output_name = :energy\n)\nmap_pairwise!((x,y,i,j,d2,energy) -> energy += 1 / sqrt(d2), system)","category":"section"},{"location":"ParticleSystem/#Force-computation","page":"ParticleSystem interface","title":"Force computation","text":"Here we compute the force vector associated to the potential energy function of the previous example.\n\nusing CellListMap\nusing StaticArrays\npositions = rand(SVector{3,Float64},1000) \nsystem = ParticleSystem(\n    xpositions = positions, \n    unitcell=[1.0,1.0,1.0], \n    cutoff = 0.1, \n    output = similar(positions),\n    output_name = :forces\n)\nfunction update_forces!(x,y,i,j,d2,forces)\n    d = sqrt(d2)\n    df = (1/d2)*(1/d)*(y - x)\n    forces[i] += df\n    forces[j] -= df\n    return forces\nend\nmap_pairwise!((x,y,i,j,d2,forces) -> update_forces!(x,y,i,j,d2,forces), system)","category":"section"},{"location":"ParticleSystem/#Energy-and-forces","page":"ParticleSystem interface","title":"Energy and forces","text":"In this example, the potential energy and the forces are computed in a single run, and a custom data structure is defined to store both values.\n\nusing CellListMap\nusing StaticArrays\n# Define custom type\nmutable struct EnergyAndForces\n    energy::Float64\n    forces::Vector{SVector{3,Float64}}\nend\n# Custom copy, reset and reducer functions\nimport CellListMap: copy_output, reset_output!, reducer\ncopy_output(x::EnergyAndForces) = EnergyAndForces(copy(x.energy), copy(x.forces))\nfunction reset_output!(output::EnergyAndForces)\n    output.energy = 0.0\n    for i in eachindex(output.forces)\n        output.forces[i] = SVector(0.0, 0.0, 0.0)\n    end\n    return output\nend\nfunction reducer(x::EnergyAndForces, y::EnergyAndForces)\n    e_tot = x.energy + y.energy\n    x.forces .+= y.forces\n    return EnergyAndForces(e_tot, x.forces)\nend\n# Function that updates energy and forces for each pair\nfunction energy_and_forces!(x,y,i,j,d2,output::EnergyAndForces)\n    d = sqrt(d2)\n    output.energy += 1/d\n    df = (1/d2)*(1/d)*(y - x)\n    output.forces[i] += df\n    output.forces[j] -= df\n    return output\nend\n# Initialize system\npositions = rand(SVector{3,Float64},1000);\nsystem = ParticleSystem(\n    xpositions = positions,\n    unitcell=[1.0,1.0,1.0], \n    cutoff = 0.1, \n    output = EnergyAndForces(0.0, similar(positions)),\n    output_name = :energy_and_forces\n)\n# Compute energy and forces\nmap_pairwise((x,y,i,j,d2,output) -> energy_and_forces!(x,y,i,j,d2,output), system)","category":"section"},{"location":"ParticleSystem/#Two-sets-of-particles","page":"ParticleSystem interface","title":"Two sets of particles","text":"In this example we illustrate the interface for the computation of properties of two sets of particles, by computing the minimum distance between the two sets.\n\nusing CellListMap\nusing StaticArrays\n# Custom structure to store the minimum distance pair\nstruct MinimumDistance\n    i::Int\n    j::Int\n    d::Float64\nend\n# Function that updates the minimum distance found\nfunction minimum_distance(i, j, d2, md)\n    d = sqrt(d2)\n    if d < md.d\n        md = MinimumDistance(i, j, d)\n    end\n    return md\nend\n# Define appropriate methods for copy, reset and reduce \nimport CellListMap: copy_output, reset_output!, reducer!\ncopy_output(md::MinimumDistance) = md\nreset_output!(md::MinimumDistance) = MinimumDistance(0, 0, +Inf)\nreducer!(md1::MinimumDistance, md2::MinimumDistance) = md1.d < md2.d ? md1 : md2\n# Build system \nxpositions = rand(SVector{3,Float64},1000);\nypositions = rand(SVector{3,Float64},1000);\nsystem = ParticleSystem(\n       xpositions = xpositions,\n       ypositions = ypositions, \n       unitcell=[1.0,1.0,1.0], \n       cutoff = 0.1, \n       output = MinimumDistance(0,0,+Inf),\n       output_name = :minimum_distance,\n)\n# Compute the minimum distance\nmap_pairwise((x,y,i,j,d2,md) -> minimum_distance(i,j,d2,md), system)","category":"section"},{"location":"ParticleSystem/#Particle-simulation","page":"ParticleSystem interface","title":"Particle simulation","text":"In this example, a complete particle simulation is illustrated, with a simple potential.  This example can illustrate how particle positions and forces can be updated. Run this simulation with:\n\njulia> system = init_system(N=200); # number of particles\n\njulia> trajectory = simulate(system);\n\njulia> animate(trajectory)\n\nOne important characteristic of this example is that the system is built outside the function that performs the simulation. This is done because the construction of the system is type-unstable (it is dimension, geometry and output-type dependent). Adding a function barrier avoids type-instabilities to propagate to the simulation causing possible performance problems. \n\nusing StaticArrays\nusing CellListMap\nimport CellListMap.wrap_relative_to\n# Function that updates the forces, for potential of the form:\n# if d < cutoff k*(d^2-cutoff^2)^2 else 0.0 with k = 10^6\nfunction update_forces!(x, y, i, j, d2, forces, cutoff)\n    r = y - x\n    dudr = 10^6 * 4 * r * (d2 - cutoff^2)\n    forces[i] += dudr\n    forces[j] -= dudr\n    return forces\nend\n# Function that initializes the system: it is preferable to initialize\n# the system outside the function that performs the simulation, because\n# the system (data)type is defined on initialization. Initializing it outside\n# the simulation function avoids possible type-instabilities. \nfunction init_system(;N::Int=200)\n    Vec2D = SVector{2,Float64}\n    positions = rand(Vec2D, N)\n    unitcell = [1.0, 1.0]\n    cutoff = 0.1\n    system = ParticleSystem(\n        positions=positions,\n        cutoff=cutoff,\n        unitcell=unitcell,\n        output=similar(positions),\n        output_name=:forces,\n    )\n    return system\nend\nfunction simulate(system=init_system(); nsteps::Int=100, isave=1)\n    # initial velocities\n    velocities = [ randn(eltype(system.positions)) for _ in 1:length(system.positions) ]\n    dt = 1e-3\n    trajectory = typeof(system.positions)[]\n    for step in 1:nsteps\n        # compute forces at this step\n        map_pairwise!(\n            (x,y,i,j,d2,forces) -> update_forces!(x,y,i,j,d2,forces,system.cutoff),\n            system\n        )\n        # Update positions and velocities\n        for i in eachindex(system.positions, system.forces)\n            f = system.forces[i]\n            x = system.positions[i]\n            v = velocities[i]\n            x = x + v * dt + (f / 2) * dt^2\n            v = v + f * dt\n            # wrapping to origin for obtaining a pretty animation\n            x = wrap_relative_to(x, SVector(0.0, 0.0), system.unitcell)\n            # !!! IMPORTANT: Update arrays of positions and velocities\n            system.positions[i] = x\n            velocities[i] = v\n        end\n        # Save step for printing\n        if step % isave == 0\n            push!(trajectory, copy(system.positions))\n        end\n    end\n    return trajectory\nend\n\nusing Plots\nfunction animate(trajectory)\n    anim = @animate for step in trajectory\n        scatter(\n            Tuple.(step),\n            label=nothing,\n            lims=(-0.5, 0.5),\n            aspect_ratio=1,\n            framestyle=:box,\n        )\n    end\n    gif(anim, \"simulation.gif\", fps=10)\nend","category":"section"},{"location":"ParticleSystem/#Docstrings","page":"ParticleSystem interface","title":"Docstrings","text":"","category":"section"},{"location":"ParticleSystem/#CellListMap.ParticleSystem-Tuple{}","page":"ParticleSystem interface","title":"CellListMap.ParticleSystem","text":"ParticleSystem(;\n    xpositions::Union{AbstractVector{<:AbstractVector},AbstractMatrix},\n    #or\n    xpositions::Union{AbstractVector{<:AbstractVector},AbstractMatrix},\n    ypositions::Union{AbstractVector{<:AbstractVector},AbstractMatrix},\n    # and\n    unitcell::Union{Nothing,AbstractVecOrMat} = nothing,\n    cutoff::Number,\n    output::Any;\n    output_name::Symbol,\n    parallel::Bool=true,\n    nbatches::Tuple{Int,Int}=(0, 0),\n    autoswap::Bool = true,\n    validate_coordinates::Union{Nothing,Function}=_validate_coordinates\n)\n\nConstructor of the ParticleSystem type given the positions of the particles.\n\nPositions can be provided as vectors of 2D or 3D vectors  (preferentially static vectors from StaticArrays), or as  (2,N) or (3,N) matrices (v0.8.28 is required for matrices).\nIf only the xpositions array is provided, a single set of coordinates  is considered, and the computation will be mapped for the N(N-1)  pairs of this set. \nIf the xpositions and ypositions arrays of coordinates are provided,  the computation will be mapped to the NÃ—M pairs of particles,  being N and M the number of particles of each set of coordinates.\n\nThe unit cell (either a vector for Orthorhombic cells or a  full unit cell matrix for Triclinic cells - where columns contain the lattice vectors), the cutoff used for the construction of the cell lists and the output variable of the calculations. If unitcell == nothing, the system is considered not-periodic, in which case artificial periodic boundaries will be built such that images  are farther from each other than the cutoff.\n\noutput_name can be set to a symbol that best identifies the output variable. For instance, if output_name=:forces, the forces can be retrieved from the structure using the system.forces notation.\n\nThe parallel and nbatches flags control the parallelization scheme of computations (see https://m3g.github.io/CellListMap.jl/stable/parallelization/#Number-of-batches)). By default the parallelization is turned on and nbatches is set with heuristics that may provide good efficiency in most cases. autoswap = false will guarantee that the cell lists will be buitl for the ypositions (by default they are constructed for the smallest set, which is faster).\n\nThe validate_coordinates function can be used to validate the coordinates before the construction of the system. If nothing, no validation is performed. By default the validation checks if the coordinates are not missing or NaN. \n\nExample\n\nIn these examples, we compute the sum of the squared distances between the particles that are within the cutoff:\n\nSingle set of particles\n\njulia> using CellListMap\n\njulia> using PDBTools: readPDB, coor\n\njulia> positions = coor(readPDB(CellListMap.argon_pdb_file));\n\njulia> sys = ParticleSystem(\n           xpositions = positions, \n           unitcell = [21.0, 21.0, 21.0],\n           cutoff = 8.0, \n           output = 0.0, \n        );\n\njulia> map_pairwise!((x,y,i,j,d2,output) -> output += d2, sys)\n43774.54367600001\n\nTwo sets of particles\n\njulia> using CellListMap, PDBTools\n\njulia> xpositions = coor(readPDB(CellListMap.argon_pdb_file))[1:50];\n\njulia> ypositions = coor(readPDB(CellListMap.argon_pdb_file))[51:100];\n\njulia> sys = ParticleSystem(\n           xpositions = xpositions, \n           ypositions = ypositions, \n           unitcell = [21.0, 21.0, 21.0],\n           cutoff = 8.0, \n           output = 0.0, \n           parallel = false, # use true for parallelization\n        );\n\njulia> map_pairwise!((x,y,i,j,d2,output) -> output += d2, sys)\n21886.196785000004\n\n\n\n\n\n","category":"method"},{"location":"ParticleSystem/#CellListMap.copy_output-Tuple{Any}","page":"ParticleSystem interface","title":"CellListMap.copy_output","text":"copy_output(x)\n\nDefines how the output variable is copied. Identical to Base.copy(x) and implemented for the types in Union{Number, StaticArraysCore.FieldVector, StaticArraysCore.SVector}.\n\nOther custom output types must have their copy_output method implemented.\n\nExample\n\nusing CellListMap\n# Custom data type\nstruct A x::Int end\n# Custom output type (array of A)\noutput = [ A(0) for _ in 1:100 ]\n# How to copy an array of `A`\nCellListMap.copy_output(v::Vector{A}) = [ x for x in v ]\n\n# Alternativelly, in this case, one could have defined:\nBase.copy(a::A) = a\nCellListMap.copy_output(v::Vector{A}) = copy(v)\n\nThe user must guarantee that the copy is independent of the original array. For many custom types it is possible to define \n\nCellListMap.copy_output(v::Vector{T}) where {T<:CustomType} = deepcopy(v)\n\n\n\n\n\n","category":"method"},{"location":"ParticleSystem/#CellListMap.map_pairwise!-Union{Tuple{F}, Tuple{F, CellListMap.AbstractParticleSystem}} where F<:Function","page":"ParticleSystem interface","title":"CellListMap.map_pairwise!","text":"map_pairwise!(\n    f::Function, system::AbstractParticleSystem; \n    show_progress = true, update_lists = true\n)\n\nFunction that maps the f function into all pairs of particles of system that are found to be within the cutoff. \n\nThe function f must be of the general form:\n\nfunction f(x,y,i,j,d2,output)\n    # operate on particle coordinates, distance and indexes\n    # update output\n    return output\nend\n\nwhere x and y are the coordinates (adjusted for the minimum image) of the two particles involved, i and j their indices in the original arrays of positions, d2 their squared Euclidean distance, and output the current value of the output variable. The output variable must be updated within this function with the contribution of the two particles involved. \n\nThread-safety is taken care automatically in parallel executions.\n\nmap_pairwise is an alias to map_pairwise! for syntax consistency when the output variable is immutable.\n\nIf update_lists is false, the cell lists will not be recomputed, this may be useful for computing a different function from the same coordinates.\n\nExample\n\nIn this example we compute the sum of 1/(1+d) where d is the distance between particles of a set, for d < cutoff. \n\njulia> sys = ParticleSystem(\n           xpositions = rand(SVector{3,Float64},1000), \n           unitcell=[1,1,1], \n           cutoff = 0.1, \n           output = 0.0\n           );\n\njulia> map_pairwise((x,y,i,j,d2,output) -> output += 1 / (1 + sqrt(d2)), sys)\n1870.0274887950268\n\n\n\n\n\n","category":"method"},{"location":"ParticleSystem/#CellListMap.reducer!-Tuple{Any, Any}","page":"ParticleSystem interface","title":"CellListMap.reducer!","text":"reducer(x,y)\nreducer!(x,y)\n\nDefines how to reduce (combine, or merge) to variables computed in parallel to obtain a single instance of the variable with the reduced result. \n\nreducer and reducer! are aliases, and reducer! is preferred, by convention for mutating functions.\n\nThe most commont reducer is the sum, and this is how it is implemented for Union{Number, StaticArraysCore.FieldVector, StaticArraysCore.SVector}. For example, when computin energies, or forces, the total energy is the sum of the energies. The force on one particle is the sum of the forces between the particle and every other particle. Thus, the implemented reducer is the sum: \n\nreducer(x,y) = +(x,y)\n\nHowever, in  many cases, reduction must be done differently. For instance, if the minimum distance between particles is to be computed, it is interesting to define a custom type and associated reducer. For example:\n\nstruct MinimumDistance d::Float64 end\nreducer(x::MinimumDistance, y::MinimumDistance) = MinimumDistance(min(x.d, y.d))\n\nThe overloading of reducer allows the use of parallel computations for custom,  complex data types, containing different types of variables, fields, or sizes.\n\nThe appropriate behavior of the reducer should be carefuly inspected by the user to avoid spurious results. \n\nExample\n\nIn this example we show how to obtain the minimum distance among argon atoms in a simulation box.\n\njulia> using CellListMap, PDBTools\n\njulia> positions = coor(readPDB(CellListMap.argon_pdb_file));\n\njulia> struct MinimumDistance d::Float64 end # Custom output type\n\njulia> CellListMap.copy_output(d::MinimumDistance) = MinimumDistance(d.d) # Custom copy function for `Out`\n\njulia> CellListMap.reset_output(d::MinimumDistance) = MinimumDistance(+Inf) # How to reset an array with elements of type `MinimumDistance`\n\njulia> CellListMap.reducer(md1::MinimumDistance, md2::MinimumDistance) = MinimumDistance(min(md1.d, md2.d)) # Custom reduction function\n\njulia> # Construct the system\n       sys = ParticleSystem(;\n           positions = positions,\n           unitcell = [21,21,21],\n           cutoff = 8.0,\n           output = MinimumDistance(+Inf),\n       );\n\njulia> # Obtain the minimum distance between atoms:\n       map_pairwise!((x,y,i,j,d2,output) -> sqrt(d2) < output.d ? MinimumDistance(sqrt(d2)) : output, sys)\nMinimumDistance(2.1991993997816563)\n\n\n\n\n\n","category":"method"},{"location":"ParticleSystem/#CellListMap.reset_output!-Tuple{Any}","page":"ParticleSystem interface","title":"CellListMap.reset_output!","text":"reset_output(x)\nreset_output!(x)\n\nFunction that defines how to reset (or zero) the output variable. For Union{Number, StaticArraysCore.FieldVector, StaticArraysCore.SVector} it is  implemented as zero(x).\n\nOther custom output types must have their reset_output! method implemented. \n\nThe function must return the variable itself. If it is immutable, a new instante of the variable must be created, with the reset value. \n\nnote: Note\nBy default, if reset_output! is defined for one element type, reset_output! is defined for arrays of that type by calling reset_output! for each element of the array.  The user must overload the reset_output!  function for the custom type array if that is not the desired behavior.\n\nreset_output and reset_output! are aliases, and by convention reset_output! is preferred for mutable types.\n\nExample\n\nIn this example, we define a reset_output function that will set to +Inf the minimum distance between particles (not always resetting means zeroing).\n\njulia> using CellListMap\n\njulia> struct MinimumDistance d::Float64 end\n\njulia> CellListMap.reset_output(x::MinimumDistance) = MinimumDistance(+Inf)\n\njulia> x = MinimumDistance(1.0)\nMinimumDistance(1.0)\n\njulia> CellListMap.reset_output(x)\nMinimumDistance(Inf)\n\nSee the reducer help entry for a complete example of how to use reset_output.\n\n\n\n\n\n","category":"method"},{"location":"ParticleSystem/#CellListMap.resize_output!-Tuple{CellListMap.AbstractParticleSystem, Int64}","page":"ParticleSystem interface","title":"CellListMap.resize_output!","text":"resize_output!(sys::AbstractParticleSystem, n::Int)\n\nResizes the output array and the auxiliary output arrays used for multithreading, if the number of particles of the system changed.\n\nThis function must be implemented by the user if the output variable is a  vector whose length is dependent on the number of particles. For example, if the output is a vector of forces acting on each particle, the output vector must be resized if the number of particles changes. \n\nThis function must be used in that case, to guarantee that the  auxiliary arrays used for multi-threading are resized accordingly. \n\n\n\n\n\n","category":"method"},{"location":"ParticleSystem/#CellListMap.unitcelltype-Tuple{CellListMap.AbstractParticleSystem}","page":"ParticleSystem interface","title":"CellListMap.unitcelltype","text":"unitcelltype(sys::AbstractParticleSystem)\n\nReturns the type of a unitcell from the ParticleSystem structure.\n\n\n\n\n\n","category":"method"},{"location":"ParticleSystem/#CellListMap.update_cutoff!-Tuple{CellListMap.ParticleSystem1, Any}","page":"ParticleSystem interface","title":"CellListMap.update_cutoff!","text":"update_cutoff!(system, cutoff)\n\nFunction to update the cutoff` of the system. \n\nThis function can be used to update the system geometry in iterative schemes.\n\nExample\n\nHere we initialize a particle system with a cutoff of 8.0 and then update the cutoff to 10.0. \n\njulia> using CellListMap, PDBTools\n\njulia> x = coor(readPDB(CellListMap.argon_pdb_file));\n\njulia> sys = ParticleSystem(\n           xpositions = x, \n           unitcell=[21.0,21.0,21.0], \n           cutoff = 8.0, \n           output = 0.0\n       );\n\njulia> update_cutoff!(sys, 10.0)\nParticleSystem1{output} of dimension 3, composed of:\n    Box{OrthorhombicCell, 3}\n      unit cell matrix = [ 21.0 0.0 0.0; 0.0 21.0 0.0; 0.0 0.0 21.0 ]\n      cutoff = 10.0\n      number of computing cells on each dimension = [5, 5, 5]\n      computing cell sizes = [10.5, 10.5, 10.5] (lcell: 1)\n      Total number of cells = 125\n    CellList{3, Float64}\n      100 real particles.\n      8 cells with real particles.\n      800 particles in computing box, including images.\n    Parallelization auxiliary data set for:\n      Number of batches for cell list construction: 8\n      Number of batches for function mapping: 8\n    Type of output variable (output): Float64\n\n\n\n\n\n","category":"method"},{"location":"ParticleSystem/#CellListMap.update_unitcell!-Tuple{Any, Any}","page":"ParticleSystem interface","title":"CellListMap.update_unitcell!","text":"update_unitcell!(system, unitcell)\n\nFunction to update the unit cell of the system. The unicell must be of the  same type (OrthorhombicCell, TriclinicCell) of the original system  (changing the type of unit cell requires reconstructing the system).\n\nThe unitcell can be a NÃ—N matrix or a vector of dimension N, where N is the dimension of the sytem (2D or 3D).\n\nThis function can be used to update the system geometry in iterative schemes, where the size of the simulation box changes during the simulation.\n\nnote: Note\nManual updating of the unit cell of non-periodic systems is not allowed.\n\nExample\n\njulia> using CellListMap, StaticArrays, PDBTools\n\njulia> xpositions = coor(readPDB(CellListMap.argon_pdb_file));\n\njulia> sys = ParticleSystem(\n           xpositions = xpositions,\n           unitcell=[21,21,21], \n           cutoff = 8.0, \n           output = 0.0\n       );\n\njulia> update_unitcell!(sys, [30.0, 30.0, 30.0])\nParticleSystem1{output} of dimension 3, composed of:\n    Box{OrthorhombicCell, 3}\n      unit cell matrix = [ 30.0 0.0 0.0; 0.0 30.0 0.0; 0.0 0.0 30.0 ]\n      cutoff = 8.0\n      number of computing cells on each dimension = [6, 6, 6]\n      computing cell sizes = [10.0, 10.0, 10.0] (lcell: 1)\n      Total number of cells = 216\n    CellList{3, Float64}\n      100 real particles.\n      8 cells with real particles.\n      800 particles in computing box, including images.\n    Parallelization auxiliary data set for:\n      Number of batches for cell list construction: 1\n      Number of batches for function mapping: 1\n    Type of output variable (output): Float64\n\n\n\n\n\n\n","category":"method"},{"location":"ParticleSystem/#CellListMap.ParticleSystem1","page":"ParticleSystem interface","title":"CellListMap.ParticleSystem1","text":"mutable struct ParticleSystem1{OutputName, V, O, B, C, A, VC} <: CellListMap.AbstractParticleSystem{OutputName}\n\nxpositions::Any\noutput::Any\n_box::Any\n_cell_list::Any\n_output_threaded::Vector\n_aux::Any\nparallel::Bool\nvalidate_coordinates::Any\n\nStructure that carries the information necessary for map_pairwise! computations, for systems with one set of positions (thus, replacing the loops over N(N-1)  pairs of particles of the set). \n\nThe xpositions, output, and parallel fields are considered part of the API, and you can retrive or mutate xpositions, retrieve the output or its elements, and set the computation to use or not parallelization by directly accessing these elements.\n\nThe other fileds of the structure (starting with _) are internal and must not  be modified or accessed directly. The construction of the ParticleSystem1 structure is done through the ParticleSystem(;xpositions, unitcell, cutoff, output)  auxiliary function.\n\n\n\n\n\n","category":"type"},{"location":"ParticleSystem/#CellListMap.ParticleSystem2","page":"ParticleSystem interface","title":"CellListMap.ParticleSystem2","text":"mutable struct ParticleSystem2{OutputName, V, O, B, C, A, VC} <: CellListMap.AbstractParticleSystem{OutputName}\n\nxpositions::Any\nypositions::Any\noutput::Any\n_box::Any\n_cell_list::Any\n_output_threaded::Vector\n_aux::Any\nparallel::Bool\nvalidate_coordinates::Any\n\nStructure that carries the information necessary for map_pairwise! computations, for systems with two set of positions (thus, replacing the loops over NÃ—M  pairs of particles, being N and M the number of particles of each set).\n\nThe xpositions, ypositions, output, and parallel fields are considered part of the API, and you can retrive or mutate positions, retrieve the output or its elements, and set the computation to use or not parallelization by directly accessing these elements.\n\nThe other fileds of the structure (starting with _) are internal and must not  be modified or accessed directly. The construction of the ParticleSystem1 structure is done through the ParticleSystem(;xpositions, ypositions, unitcell, cutoff, output)  auxiliary function.\n\n\n\n\n\n","category":"type"},{"location":"python/#Calling-from-Python","page":"From Python","title":"Calling from Python","text":"Callling CellListMap from python can be useful if lists of neighbors or other properties have to be computed many times, making the overhead of initializing Julia negligible. As the example and benchmark below demonstrates, the current implementation of cell lists in this package is faster than common alternatives available in the python ecosystem. ","category":"section"},{"location":"python/#Installing","page":"From Python","title":"Installing","text":"First, install juliacall using the pip package manager, with\n\n% pip install juliacall\n\nUsing ipython3 (only Python geq 3 is supported), do:\n\nIn [1]: from juliacall import Main as jl\n\nwhich, on the first use only, will install the latest stable version of Julia. \n\nThen, install CellListMap, with:\n\nIn [2]: jl.Pkg.add(\"CellListMap\")","category":"section"},{"location":"python/#A-Python-module","page":"From Python","title":"A Python module","text":"The CellListMap.py  provides a complete small python module that interfaces the neighborlist function of CellListMap  with python, returning numpy arrays of indices and distances: \n\nBy saving the file above in a CellListMap.py file, within python we just need to do:\n\nIn [1]: import CellListMap as cl\n\nIn [2]: import numpy as np\n\nIn [3]: coords = np.random.random((50_000,3))\n\nIn [4]: i_inds, j_inds, d = cl.neighborlist(coords, 0.05)\n\nThe output i_inds, j_inds and d variables are numpy arrays with the indexes of the particles and their distances.\n\nFor periodic systems, the unitcell must be provided, as uni-dimensional np.array (for orthorhombic systems) or a np.matrix (for general periodic boundary conditions). For example: \n\nIn [5]: i_inds, j_inds, d = cl.neighborlist(coords, 0.05, unitcell=np.array([1, 1, 1]))\n\nIn [6]: i_inds, j_inds, d = cl.neighborlist(coords, 0.05, unitcell=np.matrix('1 0 0; 0 1 0; 0 0 1'))\n\nThe neighborlist_cross function provided above has a similar syntax, but to compute the neighboring particles of two independent sets:\n\nIn [7]: x = np.random.random((50_000,3))\n\nIn [8]: y = np.random.random((50_000,3))\n\nIn [9]: i_inds, j_inds, d = cl.neighborlist_cross(x, y, 0.05, unitcell=np.array([1, 1, 1]))\n\nnote: Note\nThe indexes of the particles the i_inds and j_inds arrays are 0-based, to conform the numpy array standard. \n\ntip: Tip\nTo run the code multi-threaded, set the JULIA_NUM_THREADS environment variable before launching python:% export JULIA_NUM_THREADS=8","category":"section"},{"location":"python/#Under-the-hood:-interfacing-with-the-Julia-package","page":"From Python","title":"Under the hood: interfacing with the Julia package","text":"note: Note\nThe details of the above module are explained below, for a more in depth understanding of the interface between Julia and Python through the PythonCall.jl library.We highly recommend using the CellListMap.py module provided above.\n\nThe typical input coordinates, in python, are a numpy array with shape (N,dim) where N is the number of particles and dim is the dimension of the space (2 or 3 for CellListMap). Here, we generate a set of 50,000 particles in three dimensions:\n\nIn [1]: import numpy as np\n\nIn [2]: coords = np.random.random((50_000,3))\n\nJulia is column-major, and python is row-major, thus if we want to use the functions from CellListMap we need to transpose the coordinates:\n\nIn [3]: coords_t = coords.transpose()\n\nThese transposed coordinates can be used in the CellListMap.neighborlist function. For example:\n\nIn [4]: jl.seval(\"using CellListMap\")\n\nIn [6]: neighbor_list = jl.neighborlist(coords_t,0.05)\n\nwhich will return a list of tuples, containing all pairs of coordinates withing the cutoff (remember that the first call to a Julia function will always take longer than subsequent calls, because the function is JIT compiled):\n\nIn [12]: neighbor_list.shape\nOut[12]: (618774,)\n\nIn [13]: neighbor_list[1]\nOut[13]: (1, 37197, 0.047189685889846615)\n\nNote that the third element of the tuple is the distance between the points.","category":"section"},{"location":"python/#Converting-the-list-to-numpy-arrays","page":"From Python","title":"Converting the list to numpy arrays","text":"The output of CellListMap.neighborlist is a Julia Vector{Tuple{Int,Int,Float64}} array (or Float32, if the coordinates and cutoff were given in 32-bit precision). This Julia list can be accessed from within python normally:\n\nIn [36]: neighbor_list = jl.neighborlist(coords_t, 0.05);\n\nIn [37]: neighbor_list[0:2]\nOut[37]: \n2-element view(::Vector{Tuple{Int64, Int64, Float64}}, 1:1:2) with eltype Tuple{Int64, Int64, Float64}:\n (1, 6717, 0.020052121336342873)\n (1, 7208, 0.03880915662838867)\n\nIn [38]: neighbor_list[0][0]\nOut[38]: 1\n\nIn [40]: neighbor_list[0][2]\nOut[40]: 0.020052121336342873\n\nYet, this list may not be interoperable with many other python packages, particularly with numpy standard  operations. Thus, it may be interesting to convert the list to numpy  arrays. This can be done with a simple helper function, which uses a Julia function to copy the list values to the numpy arrays:\n\njl.seval(\"\"\"\nfunction copy_to_numpy_arrays(nb_list, i_inds, j_inds, d)\n    for i in eachindex(nb_list)\n        i_inds[i], j_inds[i], d[i] = nb_list[i]\n    end\n    return nothing\nend\n\"\"\")\ndef neighborlist(x, cutoff) :\n    x_t = x.transpose()\n    nb_list = jl.neighborlist(x_t, cutoff)\n    i_inds = np.full((len(nb_list),), 0, dtype=np.int64)\n    j_inds = np.full((len(nb_list),), 0, dtype=np.int64)\n    d = np.full((len(nb_list),), 0.0, dtype=np.float64)\n    jl.copy_to_numpy_arrays(nb_list, i_inds, j_inds, d)\n    i_inds -= 1 # make indexes 0-based\n    j_inds -= 1 # make indexes 0-based\n    return i_inds, j_inds, d\n\nNow, the output of the python neighborlist contains the numpy arrays for the indexes of the two particles involved in each pair, and their distances:\n\nIn [61]: neighborlist(coords,0.05)\nOut[61]: \n(array([    0,     0,     0, ..., 49802, 49802, 49885]),\n array([ 6717,  7208,  9303, ..., 11542, 27777, 43853]),\n array([0.02005212, 0.03880916, 0.04543936, ..., 0.04671987, 0.02671908,\n        0.02772025]))\n\nThe overhead of these conversions, array creation and copies is not very large, and the benchmarks below are still valid considering this auxiliary python function.","category":"section"},{"location":"python/#Benchmarking-vs.-Scipy","page":"From Python","title":"Benchmarking vs. Scipy","text":"To properly benchmark the neighborlist function from CellListMap, let us first define a simple wrapper that will include the transposition of the coordinates in the time:\n\nIn [14]: def neighborlist_simple(x,cutoff):\n    ...:     y = x.transpose()\n    ...:     nn = jl.CellListMap.neighborlist(y,cutoff)\n    ...:     return nn\n    ...:\n\nIn [15]: %timeit neighborlist_simple(coords,0.05)\n61.7 ms Â± 707 Âµs per loop (mean Â± std. dev. of 7 runs, 10 loops each)\n\nLet us compare this with the performance of a inrange neighborlist algorithm from scipy:\n\nIn [29]: from scipy.spatial import cKDTree\n\nIn [30]: def neighborlist_scipy(x,cutoff) : \n    ...:     kd_tree = cKDTree(x)  \n    ...:     pairs = kd_tree.query_pairs(r=0.05)  \n    ...:     return pairs \n    ...:\n\nIn [31]: %timeit neighborlist_scipy(coords,0.05)\n312 ms Â± 2.85 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n\nJust to confirm, this is the number of pairs that is being output in this test\n\nIn [32]: len(neighborlist_scipy(coords,0.05)) # using Scipy\nOut[32]: 618475\n\nIn [20]: len(neighborlist_smple(coords,0.05)) # using CellListMap\nOut[20]: 618475\n\nIf we use the neighborlist function from Converting the list to numpy arrays, the result is similar, thus copying the output to numpy arrays does not create a large overhead:\n\nIn [30]: %timeit neighborlist(coords, 0.05)\n67.4 ms Â± 4.04 ms per loop (mean Â± std. dev. of 7 runs, 10 loops each)","category":"section"},{"location":"python/#Overhead","page":"From Python","title":"Overhead","text":"The overhead of calling the function through juliacall  is small. From within Julia, the timings of a similar execution would be:\n\njulia> using BenchmarkTools\n\njulia> using CellListMap\n\njulia> x = rand(3,50_000);\n\njulia> @btime CellListMap.neighborlist($x,0.05,parallel=false);\n  51.299 ms (17687 allocations: 37.43 MiB)","category":"section"},{"location":"python/#Multi-threading","page":"From Python","title":"Multi-threading","text":"These examples were run single-threaded. To run multi-threaded, an environment variable for Julia needs to be set. For example, in bash, do:\n\n% export JULIA_NUM_THREADS=12\n\nwarning: Warning\nThere is a conflict between garbage collectors that may cause segmentation faults in multi-threaded runs  (see this issue). The workaround appears to be to  disable the Julia garbage collector during the execution of multi-threaded code. Here we provide the necessary syntax as an auxiliary Python function.\n\nConsider the following python file, let us call it neighborlist.py, that provides the neighborlist python function with the conversion of the output to numpy arrays:\n\nfrom juliacall import Main as jl\njl.seval(\"using CellListMap\")\nimport numpy as np\njl.seval(\"\"\"\nfunction copy_to_numpy_arrays(nb_list, i_inds, j_inds, d)\n    for i in eachindex(nb_list)\n        i_inds[i], j_inds[i], d[i] = nb_list[i]\n    end\n    return nothing\nend\n\"\"\")\ndef neighborlist(x, cutoff) :\n    x_t = x.transpose()\n    jl.GC.enable(False)\n    nb_list = jl.neighborlist(x_t, cutoff)\n    jl.GC.enable(True)\n    i_inds = np.full((len(nb_list),), 0, dtype=np.int64)\n    j_inds = np.full((len(nb_list),), 0, dtype=np.int64)\n    d = np.full((len(nb_list),), 0.0, dtype=np.float64)\n    jl.copy_to_numpy_arrays(nb_list, i_inds, j_inds, d)\n    return i_inds, j_inds, d\n\nThen, in Python, do:\n\nIn [1]: import neighborlist as nb\n\nIn [2]: import numpy as np\n\nIn [3]: coords = np.random.random((50_000,3))\n\nIn [4]: i_inds, j_inds, d = nb.neighborlist(coords, 0.05)\n\nIn a notebook with 6 cores (12 threads) this led to the following performance:\n\nIn [5]: %timeit i_inds, j_inds, d = nb.neighborlist(coords, 0.05)\n23.7 ms Â± 910 Âµs per loop (mean Â± std. dev. of 7 runs, 10 loops each)\n\nWhich, is about 3x faster than the serial execution:\n\nIn [4]: %timeit i_inds, j_inds, d = nb.neighborlist(coords, 0.05)\n59.2 ms Â± 959 Âµs per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n\nand thus about 10x faster than scipy.spatial:\n\nIn [7]: %timeit neighborlist_scipy(coords,0.05)\n204 ms Â± 2.86 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)","category":"section"},{"location":"python/#General-mappings","page":"From Python","title":"General mappings","text":"A greater flexibility on the use of CellListMap from python can be obtained by defining custom Julia functions. This feature must be used with the low level interface of CellListMap, and is somewhat limited in scope.\n\nIn [36]: jl.seval(\"using CellListMap\")\n\nIn [37]: x = np.random.random((50_000,3));\n\nIn [38]: x_t = x.transpose()\n\nIn [39]: box = jl.Box(np.array([1,1,1]), 0.05)\n\nIn [40]: box\nOut[41]: \nBox{OrthorhombicCell, 3}\n  unit cell matrix = [ 1.0, 0.0, 0.0; 0.0, 1.0, 0.0; 0.0, 0.0, 1.0 ]\n  cutoff = 0.05\n  number of computing cells on each dimension = [22, 22, 22]\n  computing cell sizes = [0.05, 0.05, 0.05] (lcell: 1)\n  Total number of cells = 10648\n\nIn [41]: cl = jl.CellList(x_t,box)\n\nIn [42]: cl\nOut[42]: \nCellList{3, Float64}\n  50000 real particles.\n  7985 cells with real particles.\n  66594 particles in computing box, including images.\n\nThe function to be mapped, however, has to be defined in Julia, using seval. For example, here we define a function that computes the histogram of the distances within the cutoff. \n\nIn [43]: jl.seval(\"\"\"  \n    ...: function histogram(x,y,i,j,d2,hist) \n    ...:     cutoff = 0.05 \n    ...:     dc = sqrt(d2)/cutoff # in [0,1] \n    ...:     ibin = floor(Int,dc*10) + 1 # in [0,10] \n    ...:     hist[ibin] += 1 \n    ...:     return hist \n    ...: end \n    ...: \"\"\")\nOut[44]: histogram (generic function with 1 method)\n\nWe can initialize the output variable (the histogram) using a regular numpy array: \n\nIn [45]: hist = np.zeros(10)\n\nand call the map_pairwise function to obtain the histogram of the distances within the cutoff:\n\nIn [46]: jl.map_pairwise(jl.histogram, hist, box, cl)\nOut[46]: \n10-element PythonCall.PyArray{Float64, 1, true, true, Float64}:\n 153344.0\n      1.151744e6\n      3.066624e6\n      5.787392e6\n      9.220608e6\n      1.3175552e7\n      1.7414912e7\n      2.1817088e7\n      2.6189312e7\n      3.0583808e7\n\nWith this interface, however, it is not possible to pass additional parameters to the mapped function, and thus the additional parameters have to defined inside the called function (as the cutoff in the current example). This is not ideal, for example, for computing accelerations, which depend on the masses of the particles. In this case, currently, either just use Julia from start and closures, or use the neighborlist  function to obtain the list of neighbors to then compute whatever property is desired from the list of pairs, although this is suboptimal in terms of performance.  ","category":"section"},{"location":"LowLevel/#Low-level-interface","page":"Low level interface","title":"Low level interface","text":"Since version 0.8.30 we strongly encourage the use of the ParticleSystem interface. Yet,  the low level interface is still available. To use it, load the package as usual:\n\nusing CellListMap","category":"section"},{"location":"LowLevel/#Examples","page":"Low level interface","title":"Examples","text":"The full code of the examples described here is available at the examples directory. \n\nMean difference of coordinates\nHistogram of distances\nGravitational potential\nGravitational force\nNearest neighbor\nImplementing Neighbor lists","category":"section"},{"location":"LowLevel/#Mean-difference-of-coordinates","page":"Low level interface","title":"Mean difference of coordinates","text":"Computing the mean difference in x position between random particles. The closure is used to remove the indexes and the distance of the particles from the parameters of the input function, as they are not needed in this case.\n\nusing CellListMap\n\n# System properties\nN = 100_000\nsides = [250,250,250]\ncutoff = 10\n\n# Particle positions\nx = [ sides .* rand(3) for i in 1:N ]\n\n# Initialize linked lists and box structures\nbox = Box(sides,cutoff)\ncl = CellList(x,box)\n\n# Function to be evaluated from positions \nf(x,y,sum_dx) = sum_dx + abs(x[1] - y[1])\nnormalization = N / (N*(N-1)/2) # (number of particles) / (number of pairs)\n\n# Run calculation (0.0 is the initial value)\navg_dx = normalization * map_pairwise(\n    (x,y,i,j,d2,sum_dx) -> f(x,y,sum_dx), 0.0, box, cl \n)\n\nThe example above can be run with CellListMap.Examples.average_displacement() and is available in the average_displacement.jl file.","category":"section"},{"location":"LowLevel/#Histogram-of-distances","page":"Low level interface","title":"Histogram of distances","text":"Computing the histogram of the distances between particles (considering the same particles as in the above example). Again, we use a closure to remove the positions and indexes of the particles from the function arguments, because they are not needed. The distance, on the other side, is needed in this example:\n\n# Function that accumulates the histogram of distances\nfunction build_histogram!(d2,hist)\n    d = sqrt(d2)\n    ibin = floor(Int,d) + 1\n    hist[ibin] += 1\n    return hist\nend;\n\n# Initialize (and preallocate) the histogram\nhist = zeros(Int,10);\n\n# Run calculation\nmap_pairwise!(\n    (x,y,i,j,d2,hist) -> build_histogram!(d2,hist),\n    hist,box,cl\n)\n\nNote that, since hist is mutable, there is no need to assign the output of map_pairwise! to it. \n\nThe example above can be run with CellListMap.Examples.distance_histogram() and is available in the distance_histogram.jl file.","category":"section"},{"location":"LowLevel/#Gravitational-potential","page":"Low level interface","title":"Gravitational potential","text":"In this test we compute the \"gravitational potential\", assigning to each particle a different mass. In this case, the closure is used to pass the masses to the function that computes the potential.\n\n# masses\nconst mass = rand(N)\n\n# Function to be evaluated for each pair \nfunction potential(i,j,d2,mass,u)\n    d = sqrt(d2)\n    u = u - 9.8*mass[i]*mass[j]/d\n    return u\nend\n\n# Run pairwise computation\nu = map_pairwise((x,y,i,j,d2,u) -> potential(i,j,d2,mass,u),0.0,box,cl)\n\nThe example above can be run with CellListMap.Examples.gravitational_potential() and is available in the gravitational_potential.jl file.","category":"section"},{"location":"LowLevel/#Gravitational-force","page":"Low level interface","title":"Gravitational force","text":"In the following example, we update a force vector of for all particles.\n\n# masses\nconst mass = rand(N)\n\n# Function to be evaluated for each pair: update force vector\nfunction calc_forces!(x,y,i,j,d2,mass,forces)\n    G = 9.8*mass[i]*mass[j]/d2\n    d = sqrt(d2)\n    df = (G/d)*(x - y)\n    forces[i] = forces[i] - df\n    forces[j] = forces[j] + df\n    return forces\nend\n\n# Initialize and preallocate forces\nforces = [ zeros(SVector{3,Float64}) for i in 1:N ]\n\n# Run pairwise computation\nmap_pairwise!(\n    (x,y,i,j,d2,forces) -> calc_forces!(x,y,i,j,d2,mass,forces),\n    forces,box,cl\n)\n\n\nThe example above can be run with CellListMap.Examples.gravitational_force() and is available in the gravitational_force.jl file.\n\nnote: Note\nThe parallelization works by splitting the forces vector in as many tasks as necessary, and each task will update an independent forces array, which will be reduced at the end. Therefore, there is no need to deal with atomic operations or blocks in the calc_forces! function above for the update of forces, which is implemented as if the code was running serially. The same applies to other examples in this section.","category":"section"},{"location":"LowLevel/#Nearest-neighbor","page":"Low level interface","title":"Nearest neighbor","text":"Here we compute the indexes of the particles that satisfy the minimum distance between two sets of points, using the linked lists. The distance and the indexes are stored in a tuple, and a reducing method has to be defined for that tuple to run the calculation.  The function does not need the coordinates of the points, only their distance and indexes.\n\n# Number of particles, sides and cutoff\nN1=1_500\nN2=1_500_000\nsides = [250,250,250]\ncutoff = 10.\nbox = Box(sides,cutoff)\n\n# Particle positions\nx = [ SVector{3,Float64}(sides .* rand(3)) for i in 1:N1 ]\ny = [ SVector{3,Float64}(sides .* rand(3)) for i in 1:N2 ]\n\n# Initialize auxiliary linked lists\ncl = CellList(x,y,box)\n\n# Function that keeps the minimum distance\nf(i,j,d2,mind) = d2 < mind[3] ? (i,j,d2) : mind\n\n# We have to define our own reduce function here\nfunction reduce_mind(output,output_threaded)\n    mind = output_threaded[1]\n    for i in 2:length(output_threaded)\n        if output_threaded[i][3] < mind[3]\n            mind = output_threaded[i]\n        end\n    end\n    return mind\nend\n\n# Initial value\nmind = ( 0, 0, +Inf )\n\n# Run pairwise computation\nmind = map_pairwise( \n    (x,y,i,j,d2,mind) -> f(i,j,d2,mind),\n    mind,box,cl;reduce=reduce_mind\n)\n\nThe example above can be run with CellListMap.Examples.nearest_neighbor() and is available in the nearest_neighbor.jl file.\n\nThe example CellListMap.Examples.nearest_neighbor_nopbc() of nearest_neighbor_nopbc.jl describes a similar problem but without periodic boundary conditions. Depending on the distribution of points and size it is a faster method than usual ball-tree methods. ","category":"section"},{"location":"LowLevel/#Implementing-Neighbor-lists","page":"Low level interface","title":"Implementing Neighbor lists","text":"The implementation of the CellLIstMap.neighborlist (see Neighbor lists) is as follows: The empty pairs output array will be split in one vector for each thread, and reduced with a custom reduction function. \n\n# Function to be evaluated for each pair: push pair\nfunction push_pair!(i,j,d2,pairs)\n    d = sqrt(d2)\n    push!(pairs,(i,j,d))\n    return pairs\nend\n\n# Reduction function\nfunction reduce_pairs(pairs,pairs_threaded)\n    for i in eachindex(pairs_threaded)\n        append!(pairs,pairs_threaded[i])\n    end\n    return pairs\nend\n\n# Initialize output\npairs = Tuple{Int,Int,Float64}[]\n\n# Run pairwise computation\nmap_pairwise!(\n    (x,y,i,j,d2,pairs) -> push_pair!(i,j,d2,pairs),\n    pairs,box,cl,\n    reduce=reduce_pairs\n)\n\nThe full example can be run with CellListMap.Examples.neighborlist(), available in the file  neighborlist.jl.","category":"section"},{"location":"LowLevel/#Periodic-boundary-conditions","page":"Low level interface","title":"Periodic boundary conditions","text":"Orthorhombic periodic boundary conditions\nTriclinic periodic boundary conditions\nWithout periodic boundary conditions","category":"section"},{"location":"LowLevel/#Orthorhombic-periodic-boundary-conditions","page":"Low level interface","title":"Orthorhombic periodic boundary conditions","text":"Orthorhombic periodic boundary conditions allow some special methods that are faster than those for general cells. To initialize an Orthorhombic cell, just provide the length of the cell on each side, and the cutoff. For example:\n\njulia> box = Box([100,70,130],12)\nBox{OrthorhombicCell, 3, Float64, 9}\n  unit cell matrix: [100.0 0.0 0.0; 0.0 70.0 0.0; 0.0 0.0 130.0]\n  cutoff: 12.0\n  number of computing cells on each dimension: [10, 7, 12]\n  computing cell sizes: [12.5, 14.0, 13.0] (lcell: 1)\n  Total number of cells: 840","category":"section"},{"location":"LowLevel/#Triclinic-periodic-boundary-conditions","page":"Low level interface","title":"Triclinic periodic boundary conditions","text":"Triclinic periodic boundary conditions of any kind can be used. However, the input has some limitations for the moment. The lattice vectors must have strictly positive coordinates, and the smallest distance within the cell cannot be smaller than twice the size of the cutoff. An error will be produced if the cell does not satisfy these conditions. \n\nLet us illustrate building a two-dimensional cell, for easier visualization. A matrix of column-wise lattice vectors is provided in the construction of the box, and that is all. \n\nHere, the lattice vectors are [1,0] and [0.5,1] (and we illustrate with cutoff=0.1): \n\njulia> box = Box([ 1.0  0.5\n                   0.0  1.0 ], 0.1);\n\njulia> x = 10*rand(SVector{2,Float64},1000);\n\nWe have created random coordinates for 1000 particles, that are not necessarily wrapped according to the periodic boundary conditions. We can see the coordinates in the minimum image cell with:\n\njulia> using Plots\n\njulia> CellListMap.draw_computing_cell(x,box)\n\n<img src=../assets/lattice.png>\n\nThe construction of the cell list is, as always, done with:\n\njulia> cl = CellList(x,box)\nCellList{2, Float64}\n  109 cells with real particles.\n  2041 particles in computing box, including images.\n\n\nUpon construction of the cell lists, the cell is rotated such that the longest axis becomes oriented along the x-axis, and the particles are replicated to fill a rectangular box (or orthorhombic box, in three-dimensions), with boundaries that exceed the actual system size. This improves the performance of the pairwise computations by avoiding the necessity of wrapping coordinates on the main loop (these is an implementation detail only). \n\nIn summary, to use arbitrary periodic boundary conditions, just initialize the box with the matrix of lattice vectors as columns. In three dimensions, for example, one could use:\n\njulia> unitcell = [ 50.  0. 00. \n                     0. 30. 30.          \n                     0. 00. 50. ]\n\njulia> box = Box(unitcell,  2.)\n\njulia> x = 100*rand(SVector{3,Float64},10000);\n\njulia> p = [ CellListMap.wrap_to_first(x,unitcell) for x in x ];\n\njulia> using Plots\n\njulia> scatter(Tuple.(p),aspect_ratio=1,framestyle=:box,label=:none)\n\nto work with an arbitrary 3D lattice, Which in this case looks like:\n\n<img src=../assets/3Dlattice.png>","category":"section"},{"location":"LowLevel/#Without-periodic-boundary-conditions","page":"Low level interface","title":"Without periodic boundary conditions","text":"To avoid the use of periodic boundary conditions it is enough to define an Orthorhombic box with lengths in each direction that are larger than the limits of the coordinates of the particles plus the cutoff. This can be done automatically with the limits function. The box must be constructed with:\n\njulia> x = [ [100,100,100] .* rand(3) for i in 1:100_000 ];\n\njulia> box = Box(limits(x),12)\nBox{NonPeriodicCell, 3}\n  unit cell matrix = [ 112.0, 0.0, 0.0; 0.0, 112.0, 0.0; 0.0, 0.0, 112.0 ]\n  cutoff = 12.0\n  number of computing cells on each dimension = [11, 11, 11]\n  computing cell sizes = [12.44, 12.44, 12.44] (lcell: 1)\n  Total number of cells = 1331\n\nor, for computing the interaction between two disjoint sets of particles, call the limits function with two arguments:\n\njulia> x = [ [100,100,100] .* rand(3) for i in 1:100_000 ];\n\njulia> y = [ [120,180,100] .* rand(3) for i in 1:100_000 ];\n\njulia> box = Box(limits(x,y),12)\nBox{NonPeriodicCell, 3}\n  unit cell matrix = [ 132.0, 0.0, 0.0; 0.0, 192.0, 0.0; 0.0, 0.0, 112.0 ]\n  cutoff = 12.0\n  number of computing cells on each dimension = [12, 17, 11]\n  computing cell sizes = [13.2, 12.8, 12.44] (lcell: 1)\n  Total number of cells = 2244\n\nNote that the unit cell length is, on each direction, the maximum coordinates of all particles plus the cutoff. This will avoid the computation of pairs of periodic images. The algorithms used for computing interactions in Orthorhombic cells will then be used.","category":"section"},{"location":"LowLevel/#Parallelization-splitting-and-reduction","page":"Low level interface","title":"Parallelization splitting and reduction","text":"How output is updated thread-safely\nCustom reduction functions\nNumber of batches\n\nThe parallel execution requires the splitting of the computation among tasks. ","category":"section"},{"location":"LowLevel/#How-output-is-updated-thread-safely","page":"Low level interface","title":"How output is updated thread-safely","text":"To allow general output types, the approach of CellListMap is to copy the output variable the number of times necessary for each parallel task to update an independent output variables, which are reduced at the end. This, of course, requires some additional memory, particularly if the output being updated is formed by arrays. These copies can be preallocated, and custom reduction functions can be defined. \n\nTo control these steps, set manually the output_threaded and reduce optional input parameters of the map_pairwise! function. \n\nBy default, we define:\n\noutput_threaded = [ deepcopy(output) for i in 1:nbatches(cl) ]\n\nwhere nbatches(cl) is the number of batches into which the computation will be divided. The number of batches is not necessarily equal to the number of threads available (an heuristic is used to optimize performance, as a function of the workload per batch), but can be manually set, as described in the Number of batches section below. \n\nThe default reduction function just assumes the additivity of the results obtained by each batch:\n\nreduce(output::Number,output_threaded) = sum(output_threaded)\nfunction reduce(output::Vector,output_threaded) \n    @. output = output_threaded[1]\n    for i in 2:length(output_threaded)\n         @. output += output_threaded[i] \n    end\n    return output\nend","category":"section"},{"location":"LowLevel/#Custom-reduction-functions","page":"Low level interface","title":"Custom reduction functions","text":"In some cases, as in the Nearest neighbor example, the output is a tuple and reduction consists in keeping the output from each thread having the minimum value for the distance. Thus, the reduction operation is not a simple sum over the elements of each threaded output. We can, therefore, overwrite the default reduction method, by passing the reduction function as the reduce parameter of map_pairwise!:\n\nmind = map_pairwise!( \n    (x,y,i,j,d2,mind) -> f(i,j,d2,mind), mind,box,cl;\n    reduce=reduce_mind\n)\n\nwhere here the reduce function is set to be the custom function that keeps the tuple associated to the minimum distance obtained between threads:\n\nfunction reduce_mind(output,output_threaded)\n    mind = output_threaded[1]\n    for i in 2:length(output_threaded)\n        if output_threaded[i][3] < mind[3]\n            mind = output_threaded[i]\n        end\n    end\n    return mind\nend\n\nThis function must return the updated output variable, being it mutable or not, to be compatible with the interface.  \n\nUsing the length of the output_threaded vector as the measure of how many copies of the array is available is convenient because it will be insensitive in changes in the number of batches that may be set.","category":"section"},{"location":"LowLevel/#Number-of-batches","page":"Low level interface","title":"Number of batches","text":"Every calculation with cell lists has two steps: the construction of the lists, and the mapping of the computation among the pairs of particles that satisfy the cutoff criterion. \n\nThe construction of the cell list is harder to parallelize, because assigning each particle to a cell is fast, such that the cost of merging a set of lists generated in parallel can be as costly as building the lists themselves. Therefore, it is frequent that it is not worthwhile (actually it is detrimental for performance) to split the construction of the cell lists in too many threads. This is particularly relevant for smaller systems, for which the cost of constructing the lists can be comparable to the cost of actually computing the mapped function. \n\nAt the same time, the homogeneity of the computation of the mapped function may be fast or not, homogeneous or not. These characteristics affect the optimal workload splitting strategy. For very large systems, or systems for which the function to be computed is not homogeneous in time, it may be interesting to split the workload in many tasks as possible, such that slow tasks do not dominate the final computational time.   \n\nBoth the above considerations can be used to tunning the nbatches parameter of the cell list. This parameter is initialized from a tuple of integers, defining the number of batches that will be used for constructing the cell lists and for the mapping of the computations. \n\nBy default, the number of batches for the computation of the cell lists is smaller than nthreads() if the number of particles per cell is small. The default value by the internal function CellListMap._nbatches_build_cell_lists(cl::CellList). \n\nThe values assumed for each number of batches can bee seen by printing the nbatches parameter of the cell lists:\n\njulia> Threads.nthreads()\n64\n\njulia> x, box = CellListMap.xatomic(10^4) # random set with atomic density of water\n\njulia> cl = CellList(x,box);\n\njulia> cl.nbatches\nNumberOfBatches\n  Number of batches for cell list construction: 8 \n  Number of batches for function mapping: 32 \n\nThe construction of the cell lists is performed by creating copies of the data, and currently does not scale very well. Thus, no more than 8 batches are used by default, to avoid delays associated to data copying and garbage collection. The number of batches of the mapping function uses an heuristic which currently limits somewhat the number of batches for small systems, when the overhead of spawning tasks is greater than the computation.  Using more batches than threads for the function mapping is effective most times in avoiding uneven workload, but it may be a problem if the output to be reduced is too large, as the threaded version of the output contains nbatches copies of the output. \n\nUsing less batches than the number of threads also allows the efficient use of nested multi-threading, as the computations will only use the number of threads required, leaving the other threads available for other tasks.\n\nThe number of batches is set on the construction of the cell list, using the nbatches keyword parameter. For example:\n\njulia> cl = CellList(x,box,nbatches=(1,4))\nCellList{3, Float64}\n  1000000 real particles.\n  1000 cells with real particles.\n  1727449 particles in computing box, including images.\n\njulia> cl.nbatches\nNumberOfBatches\n  Number of batches for cell list construction: 1\n  Number of batches for function mapping: 4\n\nfine tunning of the performance for a specific problem can be obtained by adjusting this parameter. \n\nIf the number of batches is set as zero for any of the two options, the default value is retained. For example:\n\njulia> cl = CellList(x,box,nbatches=(0,4));\n\njulia> cl.nbatches\nNumberOfBatches\n  Number of batches for cell list construction: 8 \n  Number of batches for function mapping: 4\n\njulia> cl = CellList(x,box,nbatches=(4,0));\n\njulia> cl.nbatches\nNumberOfBatches\n  Number of batches for cell list construction: 4\n  Number of batches for function mapping: 64\n\nThe number of batches can also be retrieved from the cell list using the nbatches function:\n\njulia> cl = CellList(x,box,nbatches=(2,4));\n\njulia> cl.nbatches\nNumberOfBatches\n  Number of batches for cell list construction: 2\n  Number of batches for function mapping: 4\n\njulia> nbatches(cl) # returns cl.nbatches.map_computation\n4\n\njulia> nbatches(cl,:map) # returns cl.nbatches.map_computation\n4\n\njulia> nbatches(cl,:build) # returns cl.nbatches.build_cell_lists\n2\n\nThe call nbatches(cl) is important for defining the number of copies of preallocated threaded output variables, as explained in the previous section.","category":"section"},{"location":"LowLevel/#Performance-tunning-and-additional-options","page":"Low level interface","title":"Performance tunning and additional options","text":"Preallocating the cell lists and cell list auxiliary arrays\nPreallocating threaded output auxiliary arrays\nOptimizing the cell grid","category":"section"},{"location":"LowLevel/#Preallocating-the-cell-lists-and-cell-list-auxiliary-arrays","page":"Low level interface","title":"Preallocating the cell lists and cell list auxiliary arrays","text":"The arrays containing the cell lists can be initialized only once, and then updated. This is useful for iterative runs. Note that, since the list size depends on the box size and cutoff, if the box properties changes some arrays might be increased (never shrink) on this update. \n\n# Initialize cell lists with initial coordinates\ncl = CellList(x,box)\n# Allocate auxiliary arrays for threaded cell list construction\naux = CellListMap.AuxThreaded(cl)\nfor i in 1:nsteps\n    x = ... # new coordinates\n    box = Box(sides,cutoff) # perhaps the box has changed\n    UpdateCellList!(x,box,cl,aux) # modifies cl\n    map_pairwise!(...)\nend\n\nThe procedure is identical if using two sets of coordinates, in which case, one would do:\n\ncl = CellList(x,y,box)\naux = CellListMap.AuxThreaded(cl)\nfor i in 1:nsteps\n    x = ... # new coordinates\n    box = Box(sides,cutoff) # perhaps the box has changed\n    UpdateCellList!(x,y,box,cl,aux) # modifies cl\n    map_pairwise(...)\nend\n\nBy passing the aux auxiliary structure, the UpdateCellList! functions will only allocate some minor variables associated to the launching of multiple threads and, possibly, to the expansion of the cell lists if the box or the number of particles became greater. \n\nwarning: Warning\nIf the number of batches of threading is changed, the structure of auxiliary arrays must be reinitialized. Otherwise, incorrect results can be obtained.","category":"section"},{"location":"LowLevel/#Preallocating-threaded-output-auxiliary-arrays","page":"Low level interface","title":"Preallocating threaded output auxiliary arrays","text":"On parallel runs, note that output_threaded is, by default, initialized on the call to map_pairwise!. Thus, if the calculation must be run multiple times (for example, for several steps of a trajectory), it is probably a good idea to preallocate the threaded output, particularly if it is a large array. For example, the arrays of forces should be created only once, and reset to zero after each use:\n\nforces = zeros(SVector{3,Float64},N)\nforces_threaded = [ deepcopy(forces) for i in 1:nbatches(cl) ]\nfor i in 1:nsteps\n    map_pairwise!(f, forces, box, cl, output_threaded=forces_threaded)\n    # work with the final forces vector\n    ...\n    # Reset forces_threaded\n    for i in 1:nbatches(cl)\n        @. forces_threaded[i] = zero(SVector{3,Float64}) \n    end\nend\n\nIn this case, the forces vector will be updated by the default reduction method. nbatches(cl) is the number of batches of the parallel calculation, which is defined on the construction of the cell list (see the Parallelization section).","category":"section"},{"location":"LowLevel/#Optimizing-the-cell-grid","page":"Low level interface","title":"Optimizing the cell grid","text":"The partition of the space into cells is dependent on a parameter lcell which can be passed to Box. For example:\n\nbox = Box(x,box,lcell=2)\ncl = CellList(x,box)\nmap_pairwise!(...)\n\nThis parameter determines how fine is the mesh of cells. There is a trade-off between the number of cells and the number of particles per cell. For low-density systems, greater meshes are better, because each cell will have only a few particles and the computations loop over a smaller number of cells. For dense systems, it is better to run over more cells with less particles per cell. It is a good idea to test different values of lcell to check which is the optimal choice for your system. Usually the best value is lcell=1, because in CellListMap implements a method to avoid spurious computations of distances on top of the cell lists, but for very dense systems, or for very large cutoffs (meaning, for situations in which the number of particles per cell may be very large), a greater lcell may provide a better performance. It is unlikely that lcell > 3 is useful in any practical situation. For molecular systems with normal densities lcell=1 is likely the optimal choice. The performance can be tested using the progress meter, as explained below.  \n\nAs a rough guide, lcell > 1 is only worthwhile if the number of particles per cell is greater than  ~200-400.  \n\nnote: Note\nThe number of cells in which the particles will be classified is, for each dimension lcell*length/cutoff.  Thus if the length of the box is too large relative to the cutoff, many cells will be created, and this imposes a perhaps large memory requirement. Usually, it is a good practice to limit the number of cells to be not greater than the number of particles, and for that the cutoff may have to be increased, if there is a memory bottleneck. A reasonable choice is to use cutoff = max(real_cutoff, length/n^(1/D)) where n is the  number of particles and D is the dimension (2 or 3). With that the number of cells will be close to n in the worst case.  ","category":"section"},{"location":"LowLevel/#Output-progress","page":"Low level interface","title":"Output progress","text":"For long-running computations, the user might want to see the progress. A progress meter can be turned on with the show_progress option. For example:\n\nmap_pairwise!(f,output,box,cl,show_progress=true)\n\nwill print something like:\n\nProgress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                    | ETA: 0:18:25\n\nThus, besides being useful for following the progress of a long run, it is useful to test different values of lcell to tune the performance of the code, by looking at the estimated time to finish (ETA) and killing the execution after a sample run. The default and recommended option for production runs is to use show_progress=false, because tracking the progress introduces a small overhead into the computation. ","category":"section"},{"location":"LowLevel/#Some-benchmarks","page":"Low level interface","title":"Some benchmarks","text":"","category":"section"},{"location":"LowLevel/#Computing-a-histogram-of-pairwise-velocities","page":"Low level interface","title":"Computing a histogram of pairwise velocities","text":"The goal here is to provide a good implementation of cell lists. We compare it with the implementation of the nice cython/python halotools package, in the computation of an histogram of mean pairwise velocities. \n\n<center>\n<img src=../assets/b_cd.png>\n<br>\n<img src=../assets/b_cv.png>\n</center>\n\nThe full test is available at this repository. And we kindly thank Carolina Cuesta for providing the example. These benchmarks were run on an Intel i7 8th gen laptop, with 4 cores (8 threads). ","category":"section"},{"location":"LowLevel/#Additional-options","page":"Low level interface","title":"Additional options","text":"","category":"section"},{"location":"LowLevel/#Input-coordinates-as-matrices","page":"Low level interface","title":"Input coordinates as matrices","text":"For compatibility with other software, the input coordinates can be provided as matrices. The matrices must have dimensions (2,N) or (3,N), where N is the number of particles (because Julia is column-major, thus this has the same memory layout of an array of length N of static vectors). \n\nFor example:\n\njulia> x = rand(3,100);\n\njulia> box = Box([1,1,1],0.1);\n\njulia> cl = CellList(x,box)\nCellList{3, Float64}\n  100 real particles.\n  99 cells with real particles.\n  162 particles in computing box, including images.\n\njulia> map_pairwise!((x,y,i,j,d2,n) -> n += 1, 0, box, cl) # count neighbors\n23","category":"section"},{"location":"LowLevel/#Docstrings","page":"Low level interface","title":"Docstrings","text":"","category":"section"},{"location":"LowLevel/#CellListMap.Box-Union{Tuple{T}, Tuple{CellListMap.Limits, T}} where T","page":"Low level interface","title":"CellListMap.Box","text":"Box(unitcell::Limits, cutoff; lcell::Int=1)\n\nThis constructor receives the output of limits(x) or limits(x,y) where x and y are the coordinates of the particles involved, and constructs a Box with size larger than the maximum coordinates ranges of all particles plus twice the cutoff. This is used to  emulate pairwise interactions in non-periodic boxes. The output box is an NonPeriodicCell box type, which internally is treated as Orthorhombic with boundaries that guarantee that particles do not see images of each other. \n\nExamples\n\njulia> using CellListMap, PDBTools\n\njulia> x = coor(readPDB(CellListMap.argon_pdb_file));\n\njulia> box = Box(limits(x), 10.0)\nBox{NonPeriodicCell, 3}\n  unit cell matrix = [ 39.83 0.0 0.0; 0.0 39.96 0.0; 0.0 0.0 39.99 ]\n  cutoff = 10.0\n  number of computing cells on each dimension = [6, 6, 6]\n  computing cell sizes = [13.28, 13.32, 13.33] (lcell: 1)\n  Total number of cells = 216\n\njulia> y = 1.2 .* x;\n\njulia> box = Box(limits(x,y),10)\nBox{NonPeriodicCell, 3}\n  unit cell matrix = [ 43.6 0.0 0.0; 0.0 43.76 0.0; 0.0 0.0 43.79 ]\n  cutoff = 10.0\n  number of computing cells on each dimension = [7, 7, 7]\n  computing cell sizes = [10.9, 10.94, 10.95] (lcell: 1)\n  Total number of cells = 343\n\n\n\n\n\n","category":"method"},{"location":"LowLevel/#CellListMap.Box-Union{Tuple{UnitCellType}, Tuple{AbstractMatrix, Any, Int64, Type{UnitCellType}}} where UnitCellType","page":"Low level interface","title":"CellListMap.Box","text":"Box(unit_cell_matrix::AbstractMatrix, cutoff, lcell::Int=1, UnitCellType=TriclinicCell)\n\nConstruct box structure given the cell matrix, where columns correspond to the lattice vectors. This constructor will always return  a TriclinicCell box type, unless the UnitCellType parameter is set  manually to OrthorhombicCell\n\nExamples\n\nBuilding a box with a triclinic unit cell matrix:\n\njulia> using CellListMap \n\njulia> unit_cell = [ 100   50    0 \n                       0  120    0\n                       0    0  130 ];\n\njulia> box = Box(unit_cell, 10.0)\nBox{TriclinicCell, 3}\n  unit cell matrix = [ 100.0 0.0 0.0; 50.0 120.0 0.0; 0.0 0.0 130.0 ]\n  cutoff = 10.0\n  number of computing cells on each dimension = [20, 13, 16]\n  computing cell sizes = [10.0, 10.0, 10.0] (lcell: 1)\n  Total number of cells = 4160\n\n\nBuilding a box with a orthorhombic unit cell matrix, from a square matrix:\n\njulia> using CellListMap\n\njulia> unit_cell = [ 100 0 0; 0 120 0; 0 0 150 ]; # cell is orthorhombic\n\njulia> box = Box(unit_cell, 10.0, UnitCellType=OrthorhombicCell) # forcing OrthorhombicCell\nBox{OrthorhombicCell, 3}\n  unit cell matrix = [ 100.0 0.0 0.0; 0.0 120.0 0.0; 0.0 0.0 150.0 ]\n  cutoff = 10.0\n  number of computing cells on each dimension = [13, 15, 18]\n  computing cell sizes = [10.0, 10.0, 10.0] (lcell: 1)\n  Total number of cells = 3510\n\n\n\n\n\n\n","category":"method"},{"location":"LowLevel/#CellListMap.Box-Union{Tuple{UnitCellType}, Tuple{AbstractVector, Any, Int64, Type{UnitCellType}}} where UnitCellType","page":"Low level interface","title":"CellListMap.Box","text":"Box(sides::AbstractVector, cutoff, lcell::Int=1, UnitCellType=OrthorhombicCell)\n\nFor orthorhombic unit cells, Box can be initialized with a vector of the length of each side. \n\nExample\n\njulia> using CellListMap\n\njulia> box = Box([120,150,100],10)\nBox{OrthorhombicCell, 3}\n  unit cell matrix = [ 120.0 0.0 0.0; 0.0 150.0 0.0; 0.0 0.0 100.0 ]\n  cutoff = 10.0\n  number of computing cells on each dimension = [15, 18, 13]\n  computing cell sizes = [10.0, 10.0, 10.0] (lcell: 1)\n  Total number of cells = 3510\n\n\n\n\n\n","category":"method"},{"location":"LowLevel/#CellListMap.unitcelltype-Union{Tuple{Box{T}}, Tuple{T}} where T","page":"Low level interface","title":"CellListMap.unitcelltype","text":"unitcelltype(::Box{T}) where T = T\n\nReturns the type of a unitcell from the Box structure.\n\nExample\n\njulia> using CellListMap\n\njulia> box = Box([1,1,1], 0.1);\n\njulia> unitcelltype(box)\nOrthorhombicCell\n\njulia> box = Box([1 0 0; 0 1 0; 0 0 1], 0.1);\n\njulia> unitcelltype(box)\nTriclinicCell\n\n\n\n\n\n","category":"method"},{"location":"LowLevel/#CellListMap.map_pairwise","page":"Low level interface","title":"CellListMap.map_pairwise","text":"map_pairwise(args...;kargs...) = map_pairwise!(args...;kargs...)\n\nis an alias for map_pairwise! which is defined for two reasons: first, if the output of the funciton is immutable, it may be  clearer to call this version, from a coding perspective. Second, the python interface through juliacall does not accept the  bang as a valid character. \n\n\n\n\n\n","category":"function"},{"location":"LowLevel/#CellListMap.map_pairwise!-Union{Tuple{F}, Tuple{F, Any, Box, CellList}} where F","page":"Low level interface","title":"CellListMap.map_pairwise!","text":"map_pairwise!(\n    f::Function,\n    output,\n    box::Box,\n    cl::CellList\n    ;parallel::Bool=true,\n    show_progress::Bool=false\n)\n\nThis function will run over every pair of particles which are closer than  box.cutoff and compute the Euclidean distance between the particles,  considering the periodic boundary conditions given in the Box structure.  If the distance is smaller than the cutoff, a function f of the  coordinates of the two particles will be computed. \n\nThe function f receives six arguments as input: \n\nf(x,y,i,j,d2,output)\n\nWhich are the coordinates of one particle, the coordinates of the  second particle, the index of the first particle, the index of the second  particle, the squared distance between them, and the output variable.  It has also to return the same output variable. Thus, f may or not  mutate output, but in either case it must return it. With that, it is  possible to compute an average property of the distance of the particles  or, for example, build a histogram. The squared distance d2 is computed  internally for comparison with the  cutoff, and is passed to the f because many times it is used for the  desired computation. \n\nExample\n\nComputing the mean absolute difference in x position between random particles,  remembering the number of pairs of n particles is n(n-1)/2. The function does  not use the indices or the distance, such that we remove them from the parameters  by using a closure.\n\njulia> n = 100_000;\n\njulia> box = Box([250,250,250],10);\n\njulia> x = [ SVector{3,Float64}(sides .* rand(3)) for i in 1:n ];\n\njulia> cl = CellList(x,box);\n\njulia> f(x,y,sum_dx) = sum_dx + abs(x[1] - y[1])\n\njulia> normalization = N / (N*(N-1)/2) # (number of particles) / (number of pairs)\n\njulia> avg_dx = normalization * map_pairwise!((x,y,i,j,d2,sum_dx) -> f(x,y,sum_dx), 0.0, box, cl)\n\n\n\n\n\n\n","category":"method"},{"location":"LowLevel/#CellListMap.map_pairwise!-Union{Tuple{Swap}, Tuple{T}, Tuple{N}, Tuple{V}, Tuple{F2}, Tuple{F1}, Tuple{F1, Any, Box, CellListMap.CellListPair{V, N, T, Swap}}} where {F1, F2, V, N, T, Swap}","page":"Low level interface","title":"CellListMap.map_pairwise!","text":"map_pairwise!(f::Function,output,box::Box,cl::CellListPair)\n\nThe same but to evaluate some function between pairs of the particles of the vectors.\n\n\n\n\n\n","category":"method"},{"location":"LowLevel/#CellListMap.AuxThreaded-Tuple{CellListMap.CellListPair}","page":"Low level interface","title":"CellListMap.AuxThreaded","text":"AuxThreaded(cl::CellListPair{N,T}) where {N,T}\n\nConstructor for the AuxThreaded type for lists of disjoint particle sets,  to be passed to UpdateCellList! for in-place update of cell lists. \n\nExample\n\njulia> box = Box([250,250,250],10);\n\njulia> x = [ 250*rand(3) for i in 1:50_000 ];\n\njulia> y = [ 250*rand(3) for i in 1:10_000 ];\n\njulia> cl = CellList(x,y,box);\n\njulia> aux = CellListMap.AuxThreaded(cl)\nCellListMap.AuxThreaded{3, Float64}\n Auxiliary arrays for nthreads = 8\n\njulia> UpdateCellList!(x,box,cl,aux)\nCellList{3, Float64}\n  100000 real particles.\n  31190 cells with real particles.\n  1134378 particles in computing box, including images.\n\n\n\n\n\n\n","category":"method"},{"location":"LowLevel/#CellListMap.AuxThreaded-Union{Tuple{CellList{N, T}}, Tuple{T}, Tuple{N}} where {N, T}","page":"Low level interface","title":"CellListMap.AuxThreaded","text":"AuxThreaded(cl::CellList{N,T}) where {N,T}\n\nConstructor for the AuxThreaded type, to be passed to UpdateCellList! for in-place  update of cell lists. \n\nExample\n\njulia> box = Box([250,250,250],10);\n\njulia> x = [ 250*rand(3) for _ in 1:100_000 ];\n\njulia> cl = CellList(x,box);\n\njulia> aux = CellListMap.AuxThreaded(cl)\nCellListMap.AuxThreaded{3, Float64}\n Auxiliary arrays for nthreads = 8\n\njulia> UpdateCellList!(x,box,cl,aux)\nCellList{3, Float64}\n  100000 real particles.\n  31190 cells with real particles.\n  1134378 particles in computing box, including images.\n\n\n\n\n\n\n","category":"method"},{"location":"LowLevel/#CellListMap.CellList-Union{Tuple{T}, Tuple{N}, Tuple{UnitCellType}, Tuple{AbstractVector{<:AbstractVector}, AbstractVector{<:AbstractVector}, Box{UnitCellType, N, T}}} where {UnitCellType, N, T}","page":"Low level interface","title":"CellListMap.CellList","text":"CellList(\n    x::AbstractVector{<:AbstractVector},\n    y::AbstractVector{<:AbstractVector},\n    box::Box{UnitCellType,N,T};\n    parallel::Bool=true,\n    nbatches::Tuple{Int,Int}=(0,0),\n    autoswap::Bool=true,\n    validate_coordinates::Union{Function,Nothing}=_validate_coordinates\n) where {UnitCellType,N,T}\n\nFunction that will initialize a CellListPair structure from scratch, given two vectors of particle coordinates and a Box, which contain the size of the system, cutoff, etc. By default, the cell list will be constructed for smallest vector, but this is not always the optimal choice. Using autoswap=false the cell list is constructed for the second (y)\n\nExample\n\njulia> box = Box([250,250,250],10);\n\njulia> x = [ 250*rand(SVector{3,Float64}) for i in 1:1000 ];\n\njulia> y = [ 250*rand(SVector{3,Float64}) for i in 1:10000 ];\n\njulia> cl = CellList(x,y,box)\nCellListMap.CellListPair{Vector{SVector{3, Float64}}, 3, Float64}\n   10000 particles in the reference vector.\n   961 cells with real particles of target vector.\n\njulia> cl = CellList(x,y,box,autoswap=false)\nCellListMap.CellListPair{Vector{SVector{3, Float64}}, 3, Float64}\n   1000 particles in the reference vector.\n   7389 cells with real particles of target vector.\n\n\n\n\n\n\n","category":"method"},{"location":"LowLevel/#CellListMap.CellList-Union{Tuple{T}, Tuple{N}, Tuple{UnitCellType}, Tuple{AbstractVector{<:AbstractVector}, Box{UnitCellType, N, T}}} where {UnitCellType, N, T}","page":"Low level interface","title":"CellListMap.CellList","text":"CellList(\n    x::AbstractVector{AbstractVector},\n    box::Box{UnitCellType,N,T};\n    parallel::Bool=true,\n    nbatches::Tuple{Int,Int}=(0,0),\n    validate_coordinates::Union{Function,Nothing}=_validate_coordinates\n) where {UnitCellType,N,T}\n\nFunction that will initialize a CellList structure from scratch, given a vector or particle coordinates (a vector of vectors, typically of static vectors)  and a Box, which contain the size ofthe system, cutoff, etc. Except for small systems, the number of parallel batches is equal to the number of threads, but it can be tunned for optimal performance in some cases.\n\nExample\n\njulia> box = Box([250,250,250],10);\n\njulia> x = [ 250*rand(SVector{3,Float64}) for i in 1:100000 ];\n\njulia> cl = CellList(x,box)\nCellList{3, Float64}\n  100000 real particles.\n  15600 cells with real particles.\n  126276 particles in computing box, including images.\n\n\n\n\n\n\n","category":"method"},{"location":"LowLevel/#CellListMap.UpdateCellList!-Tuple{AbstractVector{<:AbstractVector}, AbstractVector{<:AbstractVector}, Box, CellListMap.CellListPair}","page":"Low level interface","title":"CellListMap.UpdateCellList!","text":"UpdateCellList!(\n    x::AbstractVector{<:AbstractVector},\n    y::AbstractVector{<:AbstractVector},\n    box::Box,\n    cl:CellListPair,\n    parallel=true,\n    validate_coordinates::Union{Function,Nothing}=_validate_coordinates\n)\n\nFunction that will update a previously allocated CellListPair structure, given  new updated particle positions, for example. This method will allocate new  aux threaded auxiliary arrays. For a non-allocating version, see the  UpdateCellList!(x,y,box,cl,aux) method.\n\nThe validate_coordinates function is called before the update of the cell list, and should throw an error if the coordinates are invalid. By default, this function throws an error if some coordinates are missing or are NaN. Set to nothing to disable this check, or provide a custom function.\n\njulia> box = Box([250,250,250],10);\n\njulia> x = [ 250*rand(SVector{3,Float64}) for i in 1:1000 ];\n\njulia> y = [ 250*rand(SVector{3,Float64}) for i in 1:10000 ];\n\njulia> cl = CellList(x,y,box);\n\njulia> UpdateCellList!(x,y,box,cl); # update lists\n\n\n\n\n\n\n","category":"method"},{"location":"LowLevel/#CellListMap.UpdateCellList!-Tuple{AbstractVector{<:AbstractVector}, Box, CellList}","page":"Low level interface","title":"CellListMap.UpdateCellList!","text":"UpdateCellList!(\n    x::AbstractVector{<:AbstractVector},\n    box::Box,\n    cl:CellList;\n    parallel=true,\n    validate_coordinates::Union{Function,Nothing}=_validate_coordinates\n)\n\nFunction that will update a previously allocated CellList structure, given new  updated particle positions. This function will allocate new threaded auxiliary arrays in parallel calculations. To preallocate these auxiliary arrays, use the UpdateCellList!(x,box,cl,aux) method instead. \n\nThe validate_coordinates function is called before the update of the cell list, and should throw an error if the coordinates are invalid. By default, this function  throws an error if some coordinates are missing or are NaN. Set to nothing to disable this check, or provide a custom function.\n\nExample\n\njulia> box = Box([250,250,250],10);\n\njulia> x = [ 250*rand(SVector{3,Float64}) for i in 1:1000 ];\n\njulia> cl = CellList(x,box);\n\njulia> box = Box([260,260,260],10);\n\njulia> x = [ 260*rand(SVector{3,Float64}) for i in 1:1000 ];\n\njulia> UpdateCellList!(x,box,cl); # update lists\n\n\n\n\n\n\n","category":"method"},{"location":"LowLevel/#CellListMap.UpdateCellList!-Union{Tuple{Swap}, Tuple{T}, Tuple{N}, Tuple{V}, Tuple{AbstractVector{<:AbstractVector}, AbstractVector{<:AbstractVector}, Box, CellListMap.CellListPair{V, N, T, Swap}, Union{Nothing, CellListMap.AuxThreaded}}} where {V, N, T, Swap<:CellListMap.NotSwapped}","page":"Low level interface","title":"CellListMap.UpdateCellList!","text":"UpdateCellList!(\n    x::AbstractVector{<:AbstractVector},\n    y::AbstractVector{<:AbstractVector},\n    box::Box,\n    cl_pair::CellListPair,\n    aux::Union{Nothing,AuxThreaded};\n    parallel::Bool=true,\n    validate_coordinates::Union{Function,Nothing}=_validate_coordinates\n)\n\nThis function will update the cl_pair structure that contains the cell lists for disjoint sets of particles. It receives the preallocated aux structure to avoid reallocating auxiliary arrays necessary for the threaded construct of the lists. \n\nExample\n\njulia> box = Box([250,250,250],10);\n\njulia> x = [ 250*rand(3) for i in 1:50_000 ];\n\njulia> y = [ 250*rand(3) for i in 1:10_000 ];\n\njulia> cl = CellList(x,y,box)\nCellListMap.CellListPair{Vector{SVector{3, Float64}}, 3, Float64}\n   50000 particles in the reference vector.\n   7381 cells with real particles of target vector.\n\njulia> aux = CellListMap.AuxThreaded(cl)\nCellListMap.AuxThreaded{3, Float64}\n Auxiliary arrays for nthreads = 8\n\njulia> x = [ 250*rand(3) for i in 1:50_000 ];\n\njulia> y = [ 250*rand(3) for i in 1:10_000 ];\n\njulia> UpdateCellList!(x,y,box,cl,aux)\nCellList{3, Float64}\n  10000 real particles.\n  7358 cells with real particles.\n  12591 particles in computing box, including images.\n\n\nTo illustrate the expected ammount of allocations, which are a consequence of thread spawning only:\n\njulia> using BenchmarkTools\n\njulia> @btime UpdateCellList!($x,$y,$box,$cl,$aux)\n  715.661 Î¼s (41 allocations: 3.88 KiB)\nCellListMap.CellListPair{Vector{SVector{3, Float64}}, 3, Float64}\n   50000 particles in the reference vector.\n   7414 cells with real particles of target vector.\n   \njulia> @btime UpdateCellList!($x,$y,$box,$cl,$aux,parallel=false)\n   13.042 ms (0 allocations: 0 bytes)\n CellListMap.CellListPair{Vector{SVector{3, Float64}}, 3, Float64}\n    50000 particles in the reference vector.\n    15031 cells with real particles of target vector.\n \n\n\n\n\n\n","category":"method"},{"location":"LowLevel/#CellListMap.UpdateCellList!-Union{Tuple{T}, Tuple{N}, Tuple{AbstractVector{<:AbstractVector}, Box, CellList{N, T}, Union{Nothing, CellListMap.AuxThreaded{N, T}}}} where {N, T}","page":"Low level interface","title":"CellListMap.UpdateCellList!","text":"UpdateCellList!(\n    x::AbstractVector{<:AbstractVector},\n    box::Box,\n    cl::CellList{N,T},\n    aux::Union{Nothing,AuxThreaded{N,T}};\n    parallel::Bool=true,\n    validate_coordinates::Union{Function,Nothing}=_validate_coordinates\n) where {N,T}\n\nFunction that updates the cell list cl new coordinates x and possibly a new box box, and receives a preallocated aux structure of auxiliary vectors for threaded cell list construction. Given a preallocated aux vector, allocations in this function should be minimal, only associated with the spawning threads, or to expansion of the cell lists if the number of cells or number of particles  increased. \n\nExample\n\njulia> box = Box([250,250,250],10);\n\njulia> x = [ 250*rand(SVector{3,Float64}) for i in 1:100000 ];\n\njulia> cl = CellList(x,box);\n\njulia> aux = CellListMap.AuxThreaded(cl)\nCellListMap.AuxThreaded{3, Float64}\n Auxiliary arrays for nthreads = 8\n\njulia> x = [ 250*rand(SVector{3,Float64}) for i in 1:100000 ];\n\njulia> UpdateCellList!(x,box,cl,aux)\nCellList{3, Float64}\n  100000 real particles.\n  15599 cells with real particles.\n  125699 particles in computing box, including images.\n\n\nTo illustrate the expected ammount of allocations, which are a consequence of thread spawning only:\n\njulia> using BenchmarkTools\n\njulia> @btime UpdateCellList!($x,$box,$cl,$aux)\n  16.384 ms (41 allocations: 3.88 KiB)\nCellList{3, Float64}\n  100000 real particles.\n  15599 cells with real particles.\n  125699 particles in computing box, including images.\n\njulia> @btime UpdateCellList!($x,$box,$cl,$aux,parallel=false)\n  20.882 ms (0 allocations: 0 bytes)\nCellList{3, Float64}\n  100000 real particles.\n  15603 cells with real particles.\n  125896 particles in computing box, including images.\n\n\n\n\n\n\n","category":"method"},{"location":"LowLevel/#CellListMap.nbatches-Tuple{CellList}","page":"Low level interface","title":"CellListMap.nbatches","text":"nbatches(cl)\n\nReturns the number of batches for parallel processing that will be used in the pairwise function mappings associated to cell list cl.  It returns the cl.nbatches.map_computation value. This function is important because it must be used to set the number of copies of custom preallocated output arrays.\n\nA second argument can be provided, which may be :map or :build, in which case the function returns either the number of batches used  for pairwise mapping or for the construction of the cell lists. Since this second value is internal and does not affect the interface,  it can be usually ignored. \n\nExample\n\njulia> x = rand(3,1000); box = Box([1,1,1],0.1);\n\njulia> cl = CellList(x,box,nbatches=(2,16));\n\njulia> nbatches(cl)\n16\n\njulia> nbatches(cl,:map)\n16\n\njulia> nbatches(cl,:build)\n2\n\n\n\n\n\n","category":"method"},{"location":"LowLevel/#CellListMap.limits-Tuple{AbstractVector{<:AbstractVector}, AbstractVector{<:AbstractVector}}","page":"Low level interface","title":"CellListMap.limits","text":"limits(x,y; validate_coordinates::Union{Nothing, Function})\n\nReturns the lengths of a orthorhombic box that encompasses all the particles defined in x and y, to used to set a box without effective periodic boundary conditions.\n\nThe validate_coordinates function is used to validate the coordinates of the particles. By default, it will throw an error if any of the coordinates contain NaN or missing values. To disable this validation, set validate_coordinates = nothing. Custom checks can be implemented by passing a function that takes the coordinates as input and throws an error if the coordinates are invalid.\n\n\n\n\n\n","category":"method"},{"location":"LowLevel/#CellListMap.limits-Tuple{AbstractVector{<:AbstractVector}}","page":"Low level interface","title":"CellListMap.limits","text":"limits(x; validate_coordinates::Union{Nothing,Function})\n\nReturns the lengths of a orthorhombic box that encompasses all the particles defined in x,  to be used to set a box without effective periodic boundary conditions.\n\nThe validate_coordinates function is used to validate the coordinates of the particles. By default, it will throw an error if any of the coordinates contain NaN or missing values. To disable this validation, set validate_coordinates = nothing. Custom checks can be implemented by passing a function that takes the coordinates as input and throws an error if the coordinates are invalid.\n\n\n\n\n\n","category":"method"},{"location":"#CellListMap.jl","page":"Overview","title":"CellListMap.jl","text":"CellListMap.jl implements an efficient cell list scheme for the computation of interactions, neighbor lists, or any other property dependent on the distances between pairs of two- or three-dimensional particles, within a cutoff. \n\nThe package provides an interface to compute a generic function for each pair of particles closer  than a cutoff, using general periodic boundary conditions. Parallel and serial implementations can be used. ","category":"section"},{"location":"#Overview","page":"Overview","title":"Overview","text":"CellListMap is a package that implements a fast scheme for computing properties of systems of particles in 2 or 3 dimensions, within a cutoff. In brief, it is designed to replace double loops running over the pairs of particles of a system. Naively, a loop over all pair of particles is written as:\n\nfor i in 1:N\n    for j in i+1:N\n        # compute distance, possibly considering periodic boundary conditions\n        d = distance(particle[i],particle[j]) \n        if d <= cutoff \n            # compute property dependent on d\n        end\n    end\nend\n\nwhere N is the number of particles. \n\nAlternatively, if the interaction is between two disjoint sets of particles, the naive loop is\n\nfor i in 1:N \n    for j in 1:M\n        # compute distance, possibly considering periodic boundary conditions\n        d = distance(first_set[i], second_set[j])\n        if d <= cutoff\n            # compute property dependent on d\n        end\n    end\nend\n\nwhere N and M are the numbers of particles of each set. If the cutoff is significantly smaller than the dimension of the system, these loops are very expensive, and it is possible to avoid looping over particles that are farther from each other than the cutoff.\n\nCellListMap implements an efficient and parallel cell-list method, with optimizations, to substitute such double-loops while taking into account periodic boundary conditions. Cell lists are an alternative to distance trees and are particularly effective when the distribution of the particles is roughly homogeneous. For highly heterogeneous systems distance trees like those implemented in  NearestNeighbors.jl might be more performant. ","category":"section"},{"location":"#High-level-interface-for-particle-systems","page":"Overview","title":"High level interface for particle systems","text":"Since version 0.8.30, a simpler, higher level interface was introduced, that will facilitate the use of CellListMap without any loss in performance. The new interface is flexible enough for the majority of applications. See the ParticleSystem interface menu for details. ","category":"section"},{"location":"#Cutoff-delimited-neighbor-lists","page":"Overview","title":"Cutoff-delimited neighbor lists","text":"The user might be more comfortable in using the package to compute the list of neighboring particles. A custom interface for this application is provided though the Neighbor lists interface. \n\nNote that, in general, neighbor lists are used to compute other pairwise dependent properties, and these can be, in principle, computed directly with CellListMap without the need to explicitly compute or store the lists of neighbors. ","category":"section"},{"location":"#Lower-level-interface","page":"Overview","title":"Lower level interface","text":"The Low level interface allows the customization and optimization of very demanding calculations (although the ParticleSystem interface does not have any performance limitation and is easier to use).","category":"section"},{"location":"#Installation","page":"Overview","title":"Installation","text":"This is a Julia package. Install Julia first following the instructions in the download page.\n\nOnce Julia is installed, install the CellListMap package from the Julia REPL with:\n\njulia> import Pkg\n\njulia> Pkg.add(\"CellListMap\")","category":"section"},{"location":"#Help!","page":"Overview","title":"Help!","text":"Please ask for help if having any difficulty using the package. Reach us by:\n\nAsking a question on the Julia Discourse forum. Please mark @lmiq on your post, otherwise we may miss it! This may be very effective to get help from  many Julia users on questions that might not be directly related this package.\nOpening an issue if you think you found a problem in the package. Even documentation problems can be reported.\nJoining us at Zulip-chat in the m3g stream of the Julia Zulip forum.\nSending an e-mail to: lmartine@unicamp.br.","category":"section"}]
}
