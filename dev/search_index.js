var documenterSearchIndex = {"docs":
[{"location":"ParticleSystem/updating/#Updating-the-system","page":"Updating the system","title":"Updating the system","text":"If the pairwise! function will compute energy and/or forces in an iterative procedure (a simulation, for instance), we need to update the coordinates, and perhaps the unit cell and the cutoff.","category":"section"},{"location":"ParticleSystem/updating/#Updating-coordinates","page":"Updating the system","title":"Updating coordinates","text":"The coordinates can be updated (mutated, or the array of coordinates can change in size by pushing or deleting particles), simply by directly accessing the xpositions (and/or ypositions) field of the system. These position arrays are of type ParticleSystemPositions, which wraps a Vector{SVector{N,T}} and tracks mutations automatically. When positions are modified through the supported interface (see The ParticleSystemPositions type), the cell lists are recomputed automatically on the next call to pairwise!. Thus, the coordinates in the ParticleSystem structure must be updated independently of updates in the original array of coordinates.\n\nLet us exemplify the interface with the computation of forces:\n\njulia> using CellListMap, StaticArrays\n\njulia> positions = rand(SVector{3,Float64}, 1000);\n\njulia> system = ParticleSystem(\n           xpositions = positions,\n           unitcell=[1,1,1],\n           cutoff = 0.1,\n           output = similar(positions),\n           output_name = :forces\n       );\n\njulia> system.xpositions[1]\n3-element SVector{3, Float64} with indices SOneTo(3):\n 0.6391290709055079\n 0.43679325975360894\n 0.8231829019768698\n\njulia> system.xpositions[1] = zeros(SVector{3,Float64})\n3-element SVector{3, Float64} with indices SOneTo(3):\n 0.0\n 0.0\n 0.0\n\njulia> push!(system.xpositions, SVector(0.5, 0.5, 0.5))\n1001-element Vector{SVector{3, Float64}}:\n [0.0, 0.0, 0.0]\n [0.5491373098208292, 0.23899915605319244, 0.49058287555218516]\n ⋮\n [0.4700394061063937, 0.5440026379397457, 0.7411235688716618]\n [0.5, 0.5, 0.5]\n\nwarning: Warning\nThe output variable may have to be resized accordingly, depending on the calculation being performed. Use the resize_output! function (do not use Base.resize! on your output array directly).In the case of compound outputs (custom output structures) like that of the Computing both energy and forces example, calling resize_output! will return an error and require the user to define Base.resize! for the custom type.\n\nIf the output array has to be resized, that has to be done with the  resize_output! function, which will keep the consistency of the auxiliary multi-threading buffers. This is, for instance, the case in the example of computation of forces, as the forces array must be of the same length as the array of positions:\n\njulia> resize_output!(system, length(system.xpositions));\n\njulia> pairwise!(update_forces!, system)\n1001-element Vector{SVector{3, Float64}}:\n [756.2076075886971, -335.1637545330828, 541.8627090466914]\n [-173.02442398784672, -178.782819965489, 4.570607952876692]\n ⋮\n [-722.5400961501635, 182.65287417718935, 380.0394926753039]\n [20.27985502389337, -193.77607810950286, -155.28968519541544]\n\nIn this case, if the output is not resized, a BoundsError is be obtained, because updates of forces at unavailable positions will be attempted.","category":"section"},{"location":"ParticleSystem/updating/#Updating-the-unit-cell","page":"Updating the system","title":"Updating the unit cell","text":"The unit cell can be updated to new dimensions at any moment, with the update_unitcell! function:\n\njulia> using CellListMap, StaticArrays\n\njulia> system = ParticleSystem(;\n           positions=rand(SVector{3,Float64}, 1000),\n           unitcell=[1.0, 1.0, 1.0],\n           cutoff=0.1,\n           output = 0.0,\n        );\n\njulia> update_unitcell!(system, SVector(1.2, 1.2, 1.2))\nParticleSystem1 of dimension 3, composed of:\n    Box{OrthorhombicCell, 3}\n      unit cell matrix = [ 1.2, 0.0, 0.0; 0.0, 1.2, 0.0; 0.0, 0.0, 1.2 ]\n      cutoff = 0.1\n      number of computing cells on each dimension = [13, 13, 13]\n      computing cell sizes = [0.11, 0.11, 0.11] (lcell: 1)\n      Total number of cells = 2197\n    CellListMap.CellList{3, Float64}\n      1000 real particles.\n      623 cells with real particles.\n      1719 particles in computing box, including images.\n    Parallelization auxiliary data set for:\n      Number of batches for cell list construction: 8\n      Number of batches for function mapping: 12\n    Type of output variable (forces): Vector{SVector{3, Float64}}\n\n\nnote: Note\nThe unit cell can be set initially using a vector or a unit cell matrix. If a vector is provided the system is considered Orthorhombic, if a matrix is provided, a Triclinic system is built. Unit cells updates must preserve the system type.\nThe unit cell of non-periodic systems (initialized with nothing) cannot be updated manually.\nIt is recommended (but not mandatory) to use static arrays (or Tuples) to update the unitcell, as in this case the update will be non-allocating.","category":"section"},{"location":"ParticleSystem/updating/#Updating-the-cutoff","page":"Updating the system","title":"Updating the cutoff","text":"The cutoff can also be updated, using the update_cutoff! function:\n\njulia> using CellListMap, StaticArrays\n\njulia> system = ParticleSystem(;\n           positions=rand(SVector{3,Float64}, 1000),\n           unitcell=[1.0, 1.0, 1.0],\n           cutoff=0.1,\n           output = 0.0,\n        );\n\njulia> update_cutoff!(system, 0.2)\nParticleSystem1{default_output_name} of dimension 3, composed of:\n    Box{OrthorhombicCell, 3}\n      unit cell matrix = [ 1.0 0.0 0.0; 0.0 1.0 0.0; 0.0 0.0 1.0 ]\n      cutoff = 0.2\n      number of computing cells on each dimension = [8, 8, 8]\n      computing cell sizes = [0.2, 0.2, 0.2] (lcell: 1)\n      Total number of cells = 512\n    CellList{3, Float64}\n      1000 real particles.\n      636 cells with real particles.\n      1738 particles in computing box, including images.\n    Parallelization auxiliary data set for 8 batch(es).\n    Type of output variable (default_output_name): Float64\n","category":"section"},{"location":"neighborlists/#Neighbor-lists","page":"Neighbor lists","title":"Neighbor lists","text":"Neighbor lists can be computed, returning all pairs of particles that are found within the cutoff, and the corresponding distances.  \n\nNon-periodic systems\nPeriodic systems\nIn-place computation of neighbor lists\nOptions\n\nnote: Note\nWhen computing neighbor lists with cell-lists, it is possible for pairs of particles that are at a distance equal to the cutoff to either be included or excluded due to numerical rounding. As a result, these neighbor lists should only be utilized for calculating properties that vanish at the cutoff distance.","category":"section"},{"location":"neighborlists/#Non-periodic-systems","page":"Neighbor lists","title":"Non-periodic systems","text":"Without periodic boundary conditions, just provide the coordinates and the cutoff:\n\njulia> using CellListMap\n\njulia> x = [ rand(2) for _ in 1:10_000 ];\n\njulia> neighborlist(x,0.05)\n376457-element Vector{Tuple{Int64, Int64, Float64}}:\n (1, 363, 0.04855594810064624)\n (1, 513, 0.03356381123125866)\n (1, 1209, 0.005159666709130686)\n ⋮\n (6575, 7378, 0.03791567990447959)\n (7378, 3450, 0.01748757015908321)\n\nnote: Note\nThe order of the pairs in the output list is not guaranteed and may change, in particular, for parallel executions.\n\nIf the neighbor lists between two sets of points are required, use the following notation,  in this case using coordinates as arrays of static arrays:\n\njulia> using StaticArrays\n\njulia> x = rand(SVector{3,Float64},10^4);\n\njulia> y = rand(SVector{3,Float64},10^3);\n\njulia> list = neighborlist(x,y,0.1)\n37309-element Vector{Tuple{Int64, Int64, Float64}}:\n (1, 971, 0.09867846773727411)\n (1, 567, 0.06630101425431004)\n (1, 3, 0.04103170149300593)\n ⋮\n (10000, 156, 0.08549899843141298)\n (10000, 444, 0.0737386384422871)\n\nwhere, similarly, the third parameter is the cutoff. The returning array contains tuples with the index of the particle in the first vector, the index of the particle in the second vector, and their distance.","category":"section"},{"location":"neighborlists/#Periodic-systems","page":"Neighbor lists","title":"Periodic systems","text":"If periodic boundary conditions are used, the unitcell can be provided explicitly as keyword parameters:\n\njulia> x = [ rand(2) for _ in 1:10_000 ]; \n\njulia> neighborlist(x, 0.05; unitcell=[1,1])\n392100-element Vector{Tuple{Int64, Int64, Float64}}:\n (1, 5, 0.03445098850037766)\n (1, 393, 0.039448810592487206)\n (1, 1632, 0.02276457565643465)\n ⋮\n (9501, 9781, 0.03351665194098955)\n (9501, 5429, 0.04199258248973222)\n\nIn the example above, an Orthorhombic cell was assumed, and thus a vector of sides was provided. For general periodic boundary conditions, a unit cell matrix can be provided, for example:\n\njulia> neighborlist(x, 0.05; unitcell=[1.0 0.5; 0.5 1.0])\n580693-element Vector{Tuple{Int64, Int64, Float64}}:\n (1, 457, 0.03935441952786555)\n (1, 1467, 0.033407692174569875)\n (1, 1767, 0.04490555313598093)\n ⋮\n (3652, 8475, 0.04721628783510375)\n (6260, 8475, 0.04946130971686825)\n\nnote: Note\nPositions and unit cells can be 2 or 3-dimensional.","category":"section"},{"location":"neighborlists/#In-place-computation-of-neighbor-lists","page":"Neighbor lists","title":"In-place computation of neighbor lists","text":"If neighbor lists are computed within a interactive scenario, it is interesting preallocate all the necessary data and just update the lists at every iteration. This can be achieved by constructing the InPlaceNeighborList  object in advance. The performance gain of performing the operations in place might vary and may not be  important for single runs, as the allocations do not dominate the computing time. \n\nWe will first illustrate the interface for a non-parallel run:\n\njulia> using CellListMap, StaticArrays\n\njulia> x = rand(SVector{3,Float64}, 10^4);\n\njulia> system = InPlaceNeighborList(x=x, cutoff=0.1, unitcell=[1,1,1], parallel=false)\nInPlaceNeighborList with types: \nCellList{3, Float64}\nBox{OrthorhombicCell, 3, Float64, Float64, 9}\nCurrent list buffer size: 0\n\nNote that the buffer size has size 0. The first time the neighbor lists are computed, the list will be allocated. We will use the neighborlist! (with the bang) function, because it will effectively  mutate the system, by allocating all necessary data:\n\njulia> @time list = neighborlist!(system)\n  0.017765 seconds (12 allocations: 7.445 MiB)\n209190-element Vector{Tuple{Int64, Int64, Float64}}:\n (1, 1375, 0.09425551992016712)\n (1, 3076, 0.045320021406080775)\n (1, 3666, 0.07780146666634076)\n ⋮\n (9962, 6983, 0.07355578793348823)\n (9962, 7457, 0.07597724209140656)\n\nNow, if we modify the coordinates, we can update the system and recompute the neighbor lists:\n\njulia> x_new = rand(SVector{3,Float64}, 10^4);\n\njulia> @time update!(system, x_new)\n  0.003562 seconds\nInPlaceNeighborList with types: \nCellList{3, Float64}\nBox{OrthorhombicCell, 3, Float64, Float64, 9}\nCurrent list buffer size: 209190\n\njulia> @time list = neighborlist!(system);\n  0.012338 seconds\n\nnote: Note\nHere we illustrate the behavior of the functions in their second calls, to remove the  effects of compilation on the allocation results.\nThe cutoff and unitcell  can be modified by providing additional keyword parameters to the update! function (for example update!(system, x; cutoff=0.1)).\nAllocations can occur if the cutoff, unit cell, or number of particles change such that greater buffers are required. The number of allocations tend to diminish as  the buffers become large enough to accommodate the possible variations of the computation.\n\nFor parallel runs, the allocations are minimal, but some small auxiliary data is required for the launching of multiple threads. We illustrate here the convergence of the allocations to the  minimum required for multi-threaded calculations:\n\njulia> system = InPlaceNeighborList(x=x, cutoff=0.1, unitcell=[1,1,1], parallel=true);\n\njulia> @time list = neighborlist!(system);\n  0.007762 seconds (230 allocations: 18.142 MiB)\n\njulia> x_new = rand(SVector{3,Float64},10^4);\n\njulia> @time update!(system, x_new)\n  0.005283 seconds (20.30 k allocations: 6.200 MiB)\nInPlaceNeighborList with types: \nCellList{3, Float64}\nBox{OrthorhombicCell, 3, Float64, Float64, 9}\nCurrent list buffer size: 209190\n\njulia> @time neighborlist!(system);\n  0.008190 seconds (166 allocations: 6.461 MiB)\n\njulia> x_new = rand(SVector{3,Float64},10^4);\n\njulia> @time update!(system, x_new);\n  0.002723 seconds (221 allocations: 208.922 KiB)\n\njulia> @time neighborlist!(system);\n  0.006227 seconds (165 allocations: 2.863 MiB)\n\njulia> x_new = rand(SVector{3,Float64},10^4);\n\njulia> @time update!(system, x_new);\n  0.002396 seconds (275 allocations: 144.078 KiB)\n\njulia> @time neighborlist!(system);\n  0.004996 seconds (161 allocations: 15.141 KiB)","category":"section"},{"location":"neighborlists/#Options","page":"Neighbor lists","title":"Options","text":"Additional optional parameters can be used in a neighborlist call:\n\nKeyword Values types Default About\nparallel Bool true turns on and off parallelization\nshow_progress Bool false turns on and off progress bar\nnbatches Tuple{Int,Int} (0,0) Number of batches used in parallelization (see here)","category":"section"},{"location":"ecosystem/#Ecosystem-integration","page":"Ecosystem integration","title":"Ecosystem integration","text":"Agents.jl\nUnitful and units\nAutomatic differentiation\nMeasurements","category":"section"},{"location":"ecosystem/#Agents.jl","page":"Ecosystem integration","title":"Agents.jl","text":"Agents.jl provides a comprehensive framework for simulation, analysis and visualization of agent-based systems. CellListMap can be used to accelerate these simulations, and the integration of the packages is rather simple, particularly using the ParticleSystem interface. A complete integration example can be obtained in the Agents documentation (currently at the development branch). \n\nThe example will produce the following animation:\n\n<video width=\"auto\" controls autoplay loop>\n<source src=\"https://juliadynamics.github.io/Agents.jl/stable/examples/celllistmap.mp4\" type=\"video/mp4\">\n</video>","category":"section"},{"location":"ecosystem/#Unitful-and-units","page":"Ecosystem integration","title":"Unitful and units","text":"The functions of CellListMap.jl support the propagation of generic (isbits) types, and thus units and thus automatic differentiation and the use of Unitful. A set of working examples can be found in the generic_types.jl file.\n\nWe start illustrating the support for unit propagation. We need to define all involved quantities in the same units:","category":"section"},{"location":"ecosystem/#Using-the-ParticleSystem-interface","page":"Ecosystem integration","title":"Using the ParticleSystem interface","text":"The only requirement is to attach proper units to all quantities (positions, cutoff, unitcell, and output variables). Here we compute the square of the distances of the particles within the cutoff, where the particle coordinates are in Angstroms, while the box size and cutoff are defined in nanometers:\n\nusing CellListMap, Unitful, PDBTools\npositions = coor(read_pdb(CellListMap.argon_pdb_file))u\"Å\"\nsystem = ParticleSystem(\n    positions = positions,\n    cutoff = 0.8u\"nm\",\n    unitcell = [2.1,2.1,2.1]u\"nm\",\n    output = 0.0u\"nm^2\",\n    output_name = :sumsqr\n)\npairwise!((pair, out) -> out += pair.d2, system)","category":"section"},{"location":"ecosystem/#Units-in-neighbor-lists","page":"Ecosystem integration","title":"Units in neighbor lists","text":"CellListMap.neighborlist also propagates units correctly. Continuing the example above:\n\ncutoff = 0.8u\"nm\";\nneighborlist(positions, cutoff)","category":"section"},{"location":"ecosystem/#Automatic-differentiation","page":"Ecosystem integration","title":"Automatic differentiation","text":"Allowing automatic differentiation follows the same principles, meaning that we only need to allow the propagation of dual types through the computation by proper initialization of the input data. However, it is easier to work with the low level interface, which accepts matrices as the input for positions and a more fine control of the types of the variables. Matrices are easier input types for auto diff packages.\n\nThe variables are each component of each vector, thus the easiest way to represent the points to interface with differentiation packages is providing the coordinates as a matrix:\n\njulia> x = rand(3,1000)\n3×1000 Matrix{Float64}:\n 0.186744  0.328719  0.874102  0.503535   …  0.328161  0.0895699  0.917338\n 0.176157  0.972954  0.80729   0.624724      0.655268  0.470754   0.327578\n 0.648482  0.537362  0.599624  0.0688776     0.92333   0.497984   0.208924\n\nThe key here is allow all the types of the parameters to follow the type propagation of the elements of x inside the differentiation routine. The function we define to compute the derivative is, then:\n\njulia> function sumsqr(x, sides, cutoff)\n           sys = ParticleSystem(\n               positions=x,\n               unitcell=eltype(x).(sides),\n               cutoff=eltype(x).(cutoff),\n               output=zero(eltype(x))\n           )\n           return  pairwise!((pair, sumsqr) -> sumsqr += pair.d2, sys)\n       end\n\nNote that we convert cutoff and sides  to the same type of the input x  of the function, and set the type of the output variable accordingly. For a simple call to the function this is inconsequential:\n\njulia> cutoff = 0.1; sides = [1,1,1];\n\njulia> sumsqr(x,sides,cutoff)\n12.897650398753228\n\nbut the conversion is required to allow the differentiation to take place:\n\njulia> ForwardDiff.gradient(x -> sumsqr(x,sides,cutoff),x)\n3×1000 Matrix{Float64}:\n -0.132567   0.029865  -0.101301  …   0.249267    0.0486424  -0.0400487\n  0.122421   0.207495  -0.184366     -0.201648   -0.105031    0.218342\n  0.0856502  0.288924   0.122445     -0.0147022  -0.103314   -0.0862264","category":"section"},{"location":"ecosystem/#Measurements","page":"Ecosystem integration","title":"Measurements","text":"Propagating uncertainties through the Measurements  and other similar packages requires a different strategy, because within CellListMap only isbits types can be used, which is not the case of the type Measurement type. \n\nIn cases like this, it is better to bypass all the internals of CellListMap  and provide the data to the function that computes pairwise properties directly as a closure. For example:\n\nA vector of particles with uncertainties in their coordinates can be created with: \n\nusing CellListMap\nusing Measurements\nusing StaticArrays\nusing LinearAlgebra: norm\n\nx_input = [ SVector{3}(measurement(rand(),0.01*rand()) for i in 1:3) for j in 1:1000 ]\n\nThe variables within the CellListMap functions will be stripped from the uncertainties, and the ParticleSystem will be built from these coordinates:\n\nx_strip = [ getproperty.(v,:val) for v in x_input ]\n\nsys = ParticleSystem(\n    positions=x_strip,\n    unitcell=[1,1,1],\n    cutoff=0.1,\n    output=0.0\n)\n\nThis would be result of the sum of distances:\n\npairwise!((pair, sumd) -> sumd += pair.d, sys)\n\nTo compute the same result but propagating the uncertainties, the computation for each pair has to capture the coordinates with uncertainties. To be tread-safe, then, one has to manually guarantee that the sum of squares cannot occur concurrently. Here, then, we introduce a lock: \n\nfunction sumd_with_uncertainties(sys, x_input)\n    lk = ReentrantLock()\n    sumd = measurement(0.,0.)\n    pairwise!(\n        (pair, _) -> begin\n            (; i, j) = pair\n            x1 = x_input[i]\n            x2 = CellListMap.wrap_relative_to(x_input[j], x1, sys.unitcell)\n            @lock lk sumd += norm(x2 - x1)\n            return 0.0 # not used\n        end, \n        sys\n    )\n    return sumd\nend\nsumd_with_uncertainties(sys, x_input)\n\nIn the function above, the pair.x and pair.y coordinates, which correspond to the coordinates in x_input[pair.i] and x_input[pair.j], but already wrapped relative to each other, are ignored, because they don't carry the uncertainties. We use only the indexes pair.i and pair.j to recompute the relative position of the particles according to the periodic boundary conditions (using the CellListMap.wrap_relative_to function) and their (squared) distance. Since the x_input  array carries the uncertainties, the computation of sumsqr will propagate them.   \n\nnote: Note\nAll these computations should be performed inside the scope of a function for optimal performance. The examples here can be followed by copying and pasting the code into the REPL, but this is not the recommended practice for critical code. The strategy of bypassing the internal computations of CellListMap may be useful for improving performance even if the previous and simpler method is possible. ","category":"section"},{"location":"ParticleSystem/single_set_compound/#Single-set:-Compound-outputs","page":"Single set: Compound outputs","title":"Single set: Compound outputs","text":"This section shows how to compute compound outputs (e.g., both energy and forces) in a single computation pass, which requires defining custom output types.","category":"section"},{"location":"ParticleSystem/single_set_compound/#Computing-both-energy-and-forces","page":"Single set: Compound outputs","title":"Computing both energy and forces","text":"In this example we define a general type of output variable, for which custom copy, reset, and reduction functions must be defined. It can be followed for the computation of other general properties from the particle positions.\n\nnote: Note\nInterface to be implemented:Method Return What it does\ncopy_output(x::T) new instance of type T Copies an element of the output type T.\nreset_output!(x::T) mutated x Resets (usually zero) the value of x to the initial value it must assume before mapping.  If x is immutable, the function can return a new instance of T.\nreducer(x::T,y::T) mutated x Reduces x and y into x (for example x = x + y). If x is immutable, returns a new instance of type T.Remark: if the output is an array of an immutable type T, the methods above can be defined for single instances of T, which is simpler than for the arrays.\n\nusing CellListMap, StaticArrays, PDBTools\n\nThe computation of energies and forces in a single call is an interesting example for the definition of a custom output type and the required interface functions. Let us first define an output variable containing both quantities:\n\nmutable struct EnergyAndForces\n    energy::Float64\n    forces::Vector{SVector{3,Float64}}\nend\n\nNow we need to define what it means to copy, reset, and reduce this new type of output. We overload the default corresponding functions, for our new output type:\n\nThe copy method creates a new instance of the EnergyAndForces type, with copied data:\n\nfunction CellListMap.copy_output(x::EnergyAndForces)\n    return EnergyAndForces(copy(x.energy), copy(x.forces))\nend\n\nThe reset method will zero both the energy and all forces:\n\nfunction CellListMap.reset_output!(output::EnergyAndForces)\n    output.energy = 0.0\n    for i in eachindex(output.forces)\n        output.forces[i] = SVector(0.0, 0.0, 0.0)\n    end\n    return output\nend\n\nThe reducer function defines what it means to combine two output variables obtained on independent threads. In this case, we sum the energies and forces. Different reduction functions might be necessary for other custom types (see the Custom parallel reduction section and the CellListMap.reduce_output! function for advanced control over the reduction strategy).\n\nfunction CellListMap.reducer(x::EnergyAndForces, y::EnergyAndForces)\n    e_tot = x.energy + y.energy\n    x.forces .+= y.forces\n    return EnergyAndForces(e_tot, x.forces)\nend\n\nNote that in the above example, we reuse the x.forces array in the return instance of EnergyAndForces. You must always reduce from right to left, and reuse the possible buffers of the first argument of the reducer (in this case, x).\n\nwarning: Warning\nAll these functions must return the modified output variable, to adhere to the interface.\nThe proper definition of a reduction function is crucial for correctness. Please verify your results if using the default reducer function, which sums the elements.\n\nNow we can proceed as before, defining a function that updates the output variable appropriately:\n\nfunction energy_and_forces!(pair, output::EnergyAndForces)\n    (; i, j, x, y, d2, d) = pair\n    output.energy += 1/d\n    df = (1/d2)*(1/d)*(y - x)\n    output.forces[i] += df\n    output.forces[j] -= df\n    return output\nend\n\nTo finally define the system and compute the properties:\n\nargon_coordinates = coor(read_pdb(CellListMap.argon_pdb_file))\n\nsystem = ParticleSystem(\n    xpositions = argon_coordinates,\n    unitcell = [21.0, 21.0, 21.0],\n    cutoff = 8.0,\n    output = EnergyAndForces(0.0, similar(argon_coordinates)),\n    output_name = :energy_and_forces\n);\n\npairwise!(energy_and_forces!, system);\n\nThe output can be seen with the aliases of the system.output variable:\n\njulia> system.energy_and_forces.energy\n207.37593043370862\n\njulia> system.energy_and_forces.forces\n100-element Vector{SVector{3, Float64}}:\n [0.02649383330735732, 0.18454277989323772, -0.012253902366284958]\n [0.07782602581235692, 0.27910822337402613, 0.21926615329195248]\n ⋮\n [0.11307234751448932, 0.006353545239676281, -0.05955687310348303]\n [-0.031012009183076745, 0.03543655648545698, 0.03184912163097636]","category":"section"},{"location":"Internals/#Internals","page":"Internals","title":"Internals","text":"warning: Internal API\nThe functions and types documented in this section are not part of the public API and may change without notice between versions. They are documented here for reference and for developers who need to understand the internal workings of the package.","category":"section"},{"location":"Internals/#Examples","page":"Internals","title":"Examples","text":"The full code of the examples described here is available at the examples directory.\n\nMean difference of coordinates\nHistogram of distances\nGravitational potential\nGravitational force\nNearest neighbor\nImplementing Neighbor lists","category":"section"},{"location":"Internals/#Mean-difference-of-coordinates","page":"Internals","title":"Mean difference of coordinates","text":"Computing the mean difference in x position between random particles. The closure is used to remove the indexes and the distance of the particles from the parameters of the input function, as they are not needed in this case.\n\nusing CellListMap: Box, CellList\n\n# System properties\nN = 100_000\nsides = [250,250,250]\ncutoff = 10\n\n# Particle positions\nx = [ sides .* rand(3) for i in 1:N ]\n\n# Initialize linked lists and box structures\nbox = Box(sides,cutoff)\ncl = CellList(x,box)\n\n# Function to be evaluated from positions\nf(x,y,sum_dx) = sum_dx + abs(x[1] - y[1])\nnormalization = N / (N*(N-1)/2) # (number of particles) / (number of pairs)\n\n# Run calculation (0.0 is the initial value)\navg_dx = normalization * pairwise!(\n    (pair, sum_dx) -> f(pair.x, pair.y, sum_dx), 0.0, box, cl\n)\n\nThe example above can be run with Examples.average_displacement() and is available in the average_displacement.jl file.","category":"section"},{"location":"Internals/#Histogram-of-distances","page":"Internals","title":"Histogram of distances","text":"Computing the histogram of the distances between particles (considering the same particles as in the above example). Again, we use a closure to remove the positions and indexes of the particles from the function arguments, because they are not needed. The distance, on the other side, is needed in this example:\n\n# Function that accumulates the histogram of distances\nfunction build_histogram!(d2,hist)\n    d = sqrt(d2)\n    ibin = floor(Int,d) + 1\n    hist[ibin] += 1\n    return hist\nend;\n\n# Initialize (and preallocate) the histogram\nhist = zeros(Int,10);\n\n# Run calculation\npairwise!(\n    (pair, hist) -> build_histogram!(pair.d2, hist),\n    hist, box, cl\n)\n\nNote that, since hist is mutable, there is no need to assign the output of pairwise! to it.\n\nThe example above can be run with Examples.distance_histogram() and is available in the distance_histogram.jl file.","category":"section"},{"location":"Internals/#Gravitational-potential","page":"Internals","title":"Gravitational potential","text":"In this test we compute the \"gravitational potential\", assigning to each particle a different mass. In this case, the closure is used to pass the masses to the function that computes the potential.\n\n# masses\nconst mass = rand(N)\n\n# Function to be evaluated for each pair\nfunction potential(i,j,d2,mass,u)\n    d = sqrt(d2)\n    u = u - 9.8*mass[i]*mass[j]/d\n    return u\nend\n\n# Run pairwise computation\nu = pairwise!((pair, u) -> potential(pair.i, pair.j, pair.d2, mass, u), 0.0, box, cl)\n\nThe example above can be run with Examples.gravitational_potential() and is available in the gravitational_potential.jl file.","category":"section"},{"location":"Internals/#Gravitational-force","page":"Internals","title":"Gravitational force","text":"In the following example, we update a force vector of for all particles.\n\n# masses\nconst mass = rand(N)\n\n# Function to be evaluated for each pair: update force vector\nfunction calc_forces!(pair,forces, mass)\n    (; i, j, x, y, d2) = pair\n    G = 9.8*mass[i]*mass[j]/d2\n    d = sqrt(d2)\n    df = (G/d)*(x - y)\n    forces[i] = forces[i] - df\n    forces[j] = forces[j] + df\n    return forces\nend\n\n# Initialize and preallocate forces\nforces = [ zeros(SVector{3,Float64}) for i in 1:N ]\n\n# Run pairwise computation\npairwise!(\n    (pair, forces) -> calc_forces!(pair, forces, mass),\n    forces, box, cl\n)\n\n\nThe example above can be run with Examples.gravitational_force() and is available in the gravitational_force.jl file.\n\nnote: Note\nThe parallelization works by splitting the forces vector in as many tasks as necessary, and each task will update an independent forces array, which will be reduced at the end. Therefore, there is no need to deal with atomic operations or blocks in the calc_forces! function above for the update of forces, which is implemented as if the code was running serially. The same applies to other examples in this section.","category":"section"},{"location":"Internals/#Nearest-neighbor","page":"Internals","title":"Nearest neighbor","text":"Here we compute the indexes of the particles that satisfy the minimum distance between two sets of points, using the linked lists. The distance and the indexes are stored in a tuple, and a reducing method has to be defined for that tuple to run the calculation.  The function does not need the coordinates of the points, only their distance and indexes.\n\n# Number of particles, sides and cutoff\nN1=1_500\nN2=1_500_000\nsides = [250,250,250]\ncutoff = 10.\nbox = Box(sides,cutoff)\n\n# Particle positions\nx = [ SVector{3,Float64}(sides .* rand(3)) for i in 1:N1 ]\ny = [ SVector{3,Float64}(sides .* rand(3)) for i in 1:N2 ]\n\n# Initialize auxiliary linked lists\ncl = CellList(x,y,box)\n\n# Function that keeps the minimum distance\nf(pair, mind) = pair.d2 < mind[3] ? (pair.i,pair.j,pair.d2) : mind\n\n# We have to define our own reduce function here\nfunction reduce_mind(output,output_threaded)\n    mind = output_threaded[1]\n    for i in 2:length(output_threaded)\n        if output_threaded[i][3] < mind[3]\n            mind = output_threaded[i]\n        end\n    end\n    return mind\nend\n\n# Initial value\nmind = ( 0, 0, +Inf )\n\n# Run pairwise computation\nmind = pairwise!(f, mind, box, cl; reduce=reduce_mind)\n\nThe example above can be run with Examples.nearest_neighbor() and is available in the nearest_neighbor.jl file.\n\nThe example Examples.nearest_neighbor_nopbc() of nearest_neighbor_nopbc.jl describes a similar problem but without periodic boundary conditions. Depending on the distribution of points and size it is a faster method than usual ball-tree methods.","category":"section"},{"location":"Internals/#Implementing-Neighbor-lists","page":"Internals","title":"Implementing Neighbor lists","text":"The implementation of the CellListMap.neighborlist (see Neighbor lists) is as follows: The empty pairs output array will be split in one vector for each thread, and reduced with a custom reduction function.\n\n# Function to be evaluated for each pair: push pair\nfunction push_pair!(pair,pairs)\n    (;i, j, d) = pair\n    push!(pairs,(i,j,d))\n    return pairs\nend\n\n# Reduction function\nfunction reduce_pairs(pairs,pairs_threaded)\n    for i in eachindex(pairs_threaded)\n        append!(pairs,pairs_threaded[i])\n    end\n    return pairs\nend\n\n# Initialize output\npairs = Tuple{Int,Int,Float64}[]\n\n# Run pairwise computation\npairwise!(push_pair!, pairs, box, cl, reduce=reduce_pairs)\n\nThe full example can be run with Examples.neighborlist(), available in the file neighborlist.jl.","category":"section"},{"location":"Internals/#Periodic-boundary-conditions","page":"Internals","title":"Periodic boundary conditions","text":"Orthorhombic periodic boundary conditions\nTriclinic periodic boundary conditions\nWithout periodic boundary conditions","category":"section"},{"location":"Internals/#Orthorhombic-periodic-boundary-conditions","page":"Internals","title":"Orthorhombic periodic boundary conditions","text":"Orthorhombic periodic boundary conditions allow some special methods that are faster than those for general cells. To initialize an Orthorhombic cell, just provide the length of the cell on each side, and the cutoff. For example:\n\njulia> box = Box([100,70,130],12)\nBox{OrthorhombicCell, 3, Float64, 9}\n  unit cell matrix: [100.0 0.0 0.0; 0.0 70.0 0.0; 0.0 0.0 130.0]\n  cutoff: 12.0\n  number of computing cells on each dimension: [10, 7, 12]\n  computing cell sizes: [12.5, 14.0, 13.0] (lcell: 1)\n  Total number of cells: 840","category":"section"},{"location":"Internals/#Triclinic-periodic-boundary-conditions","page":"Internals","title":"Triclinic periodic boundary conditions","text":"Triclinic periodic boundary conditions of any kind can be used. However, the input has some limitations for the moment. The lattice vectors must have strictly positive coordinates, and the smallest distance within the cell cannot be smaller than twice the size of the cutoff. An error will be produced if the cell does not satisfy these conditions.\n\nLet us illustrate building a two-dimensional cell, for easier visualization. A matrix of column-wise lattice vectors is provided in the construction of the box, and that is all.\n\nHere, the lattice vectors are [1,0] and [0.5,1] (and we illustrate with cutoff=0.1):\n\njulia> box = Box([ 1.0  0.5\n                   0.0  1.0 ], 0.1);\n\njulia> x = 10*rand(SVector{2,Float64},1000);\n\nWe have created random coordinates for 1000 particles, that are not necessarily wrapped according to the periodic boundary conditions. We can see the coordinates in the minimum image cell with:\n\njulia> using Plots\n\njulia> CellListMap.draw_computing_cell(x,box)\n\n<img src=../assets/lattice.png>\n\nThe construction of the cell list is, as always, done with:\n\njulia> cl = CellList(x,box)\nCellList{2, Float64}\n  109 cells with real particles.\n  2041 particles in computing box, including images.\n\n\nUpon construction of the cell lists, the cell is rotated such that the longest axis becomes oriented along the x-axis, and the particles are replicated to fill a rectangular box (or orthorhombic box, in three-dimensions), with boundaries that exceed the actual system size. This improves the performance of the pairwise computations by avoiding the necessity of wrapping coordinates on the main loop (these is an implementation detail only).\n\nIn summary, to use arbitrary periodic boundary conditions, just initialize the box with the matrix of lattice vectors as columns. In three dimensions, for example, one could use:\n\njulia> unitcell = [ 50.  0. 00.\n                     0. 30. 30.\n                     0. 00. 50. ]\n\njulia> box = Box(unitcell,  2.)\n\njulia> x = 100*rand(SVector{3,Float64},10000);\n\njulia> p = [ CellListMap.wrap_to_first(x,unitcell) for x in x ];\n\njulia> using Plots\n\njulia> scatter(Tuple.(p),aspect_ratio=1,framestyle=:box,label=:none)\n\nto work with an arbitrary 3D lattice, Which in this case looks like:\n\n<img src=../assets/3Dlattice.png>","category":"section"},{"location":"Internals/#Without-periodic-boundary-conditions","page":"Internals","title":"Without periodic boundary conditions","text":"To avoid the use of periodic boundary conditions it is enough to define an Orthorhombic box with lengths in each direction that are larger than the limits of the coordinates of the particles plus the cutoff. This can be done automatically with the limits function. The box must be constructed with:\n\njulia> x = [ [100,100,100] .* rand(3) for i in 1:100_000 ];\n\njulia> box = Box(limits(x),12)\nBox{NonPeriodicCell, 3}\n  unit cell matrix = [ 112.0, 0.0, 0.0; 0.0, 112.0, 0.0; 0.0, 0.0, 112.0 ]\n  cutoff = 12.0\n  number of computing cells on each dimension = [11, 11, 11]\n  computing cell sizes = [12.44, 12.44, 12.44] (lcell: 1)\n  Total number of cells = 1331\n\nor, for computing the interaction between two disjoint sets of particles, call the limits function with two arguments:\n\njulia> x = [ [100,100,100] .* rand(3) for i in 1:100_000 ];\n\njulia> y = [ [120,180,100] .* rand(3) for i in 1:100_000 ];\n\njulia> box = Box(limits(x,y),12)\nBox{NonPeriodicCell, 3}\n  unit cell matrix = [ 132.0, 0.0, 0.0; 0.0, 192.0, 0.0; 0.0, 0.0, 112.0 ]\n  cutoff = 12.0\n  number of computing cells on each dimension = [12, 17, 11]\n  computing cell sizes = [13.2, 12.8, 12.44] (lcell: 1)\n  Total number of cells = 2244\n\nNote that the unit cell length is, on each direction, the maximum coordinates of all particles plus the cutoff. This will avoid the computation of pairs of periodic images. The algorithms used for computing interactions in Orthorhombic cells will then be used.","category":"section"},{"location":"Internals/#Parallelization-splitting-and-reduction","page":"Internals","title":"Parallelization splitting and reduction","text":"How output is updated thread-safely\nCustom reduction functions\nNumber of batches\n\nThe parallel execution requires the splitting of the computation among tasks.","category":"section"},{"location":"Internals/#How-output-is-updated-thread-safely","page":"Internals","title":"How output is updated thread-safely","text":"To allow general output types, the approach of CellListMap is to copy the output variable the number of times necessary for each parallel task to update an independent output variables, which are reduced at the end. This, of course, requires some additional memory, particularly if the output being updated is formed by arrays. These copies can be preallocated, and custom reduction functions can be defined.\n\nTo control these steps, set manually the output_threaded and reduce optional input parameters of the pairwise! function.\n\nBy default, we define:\n\noutput_threaded = [ deepcopy(output) for i in 1:nbatches(cl, :map) ]\n\nwhere nbatches(cl, :map) is the number of batches into which the mapped computation will be divided. The number of batches is not necessarily equal to the number of threads available (an heuristic is used to optimize performance, as a function of the workload per batch), but can be manually set, as described in the Number of batches section below.\n\nThe default reduction function just assumes the additivity of the results obtained by each batch.","category":"section"},{"location":"Internals/#Custom-reduction-functions","page":"Internals","title":"Custom reduction functions","text":"In some cases, as in the Nearest neighbor example, the output is a tuple and reduction consists in keeping the output from each thread having the minimum value for the distance. Thus, the reduction operation is not a simple sum over the elements of each threaded output. We can, therefore, overwrite the default reduction method, by passing the reduction function as the reduce parameter of pairwise!:\n\nmind = pairwise!(f, mind,box,cl; reduce=reduce_mind)\n\nwhere here the reduce function is set to be the custom function that keeps the tuple associated to the minimum distance obtained between threads:\n\nfunction reduce_mind(output,output_threaded)\n    mind = output_threaded[1]\n    for i in 2:length(output_threaded)\n        if output_threaded[i][3] < mind[3]\n            mind = output_threaded[i]\n        end\n    end\n    return mind\nend\n\nThis function must return the updated output variable, being it mutable or not, to be compatible with the interface.\n\nUsing the length of the output_threaded vector as the measure of how many copies of the array is available is convenient because it will be insensitive in changes in the number of batches that may be set.","category":"section"},{"location":"Internals/#Number-of-batches","page":"Internals","title":"Number of batches","text":"Every calculation with cell lists has two steps: the construction of the lists, and the mapping of the computation among the pairs of particles that satisfy the cutoff criterion.\n\nThe construction of the cell list is harder to parallelize, because assigning each particle to a cell is fast, such that the cost of merging a set of lists generated in parallel can be as costly as building the lists themselves. Therefore, it is frequent that it is not worthwhile (actually it is detrimental for performance) to split the construction of the cell lists in too many threads. This is particularly relevant for smaller systems, for which the cost of constructing the lists can be comparable to the cost of actually computing the mapped function.\n\nAt the same time, the homogeneity of the computation of the mapped function may be fast or not, homogeneous or not. These characteristics affect the optimal workload splitting strategy. For very large systems, or systems for which the function to be computed is not homogeneous in time, it may be interesting to split the workload in many tasks as possible, such that slow tasks do not dominate the final computational time.\n\nBoth the above considerations can be used to tuning the nbatches parameter of the cell list. This parameter is initialized from a tuple of integers, defining the number of batches that will be used for constructing the cell lists and for the mapping of the computations.\n\nBy default, the number of batches for the computation of the cell lists is smaller than nthreads() if the number of particles per cell is small. The default value is defined by the internal function CellListMap._nbatches_build_cell_lists(cl::CellList).\n\nThe values assumed for each number of batches can bee seen by printing the nbatches parameter of the cell lists:\n\njulia> Threads.nthreads()\n64\n\njulia> x, box = xatomic(10^4) # random set with atomic density of water\n\njulia> cl = CellList(x,box);\n\njulia> cl.nbatches\nNumberOfBatches\n  Number of batches for cell list construction: 8\n  Number of batches for function mapping: 32\n\nThe construction of the cell lists is performed by creating copies of the data, and currently does not scale very well. Thus, no more than 8 batches are used by default, to avoid delays associated to data copying and garbage collection. The number of batches of the mapping function uses an heuristic which currently limits somewhat the number of batches for small systems, when the overhead of spawning tasks is greater than the computation. Using more batches than threads for the function mapping is effective most times in avoiding uneven workload, but it may be a problem if the output to be reduced is too large, as the threaded version of the output contains nbatches copies of the output.\n\nUsing less batches than the number of threads also allows the efficient use of nested multi-threading, as the computations will only use the number of threads required, leaving the other threads available for other tasks.\n\nThe number of batches is set on the construction of the cell list, using the nbatches keyword parameter. For example:\n\njulia> cl = CellList(x,box,nbatches=(1,4))\nCellList{3, Float64}\n  1000000 real particles.\n  1000 cells with real particles.\n  1727449 particles in computing box, including images.\n\njulia> cl.nbatches\nNumberOfBatches\n  Number of batches for cell list construction: 1\n  Number of batches for function mapping: 4\n\nfine tuning of the performance for a specific problem can be obtained by adjusting this parameter.\n\nIf the number of batches is set as zero for any of the two options, the default value is retained. For example:\n\njulia> cl = CellList(x,box,nbatches=(0,4));\n\njulia> cl.nbatches\nNumberOfBatches\n  Number of batches for cell list construction: 8\n  Number of batches for function mapping: 4\n\njulia> cl = CellList(x,box,nbatches=(4,0));\n\njulia> cl.nbatches\nNumberOfBatches\n  Number of batches for cell list construction: 4\n  Number of batches for function mapping: 64\n\nThe number of batches can also be retrieved from the cell list using the nbatches function:\n\njulia> cl = CellList(x,box,nbatches=(2,4));\n\njulia> cl.nbatches\nNumberOfBatches\n  Number of batches for cell list construction: 2\n  Number of batches for function mapping: 4\n\njulia> nbatches(cl) # returns cl.nbatches.map_computation\n4\n\njulia> nbatches(cl,:map) # returns cl.nbatches.map_computation\n4\n\njulia> nbatches(cl,:build) # returns cl.nbatches.build_cell_lists\n2\n\nThe call nbatches(cl) is important for defining the number of copies of preallocated threaded output variables, as explained in the previous section.","category":"section"},{"location":"Internals/#Automatic-update-of-the-number-of-batches","page":"Internals","title":"Automatic update of the number of batches","text":"When the number of batches is left at the default (i.e., set to zero at construction), the number of batches is automatically updated whenever UpdateCellList! is called and the number of particles has changed. This means that if you add or remove particles from the system, the number of batches will be recomputed according to the heuristic functions, without any action required from the user.\n\nIf the number of batches is explicitly set to a non-zero value, it will be kept fixed and will not be updated automatically. For example:\n\njulia> cl = CellList(x, box, nbatches=(0, 0)); # automatic mode (default)\n\njulia> cl = UpdateCellList!(x[1:end-100], box, cl); # fewer particles: nbatches updated\n\njulia> cl = CellList(x, box, nbatches=(2, 4)); # fixed mode\n\njulia> cl = UpdateCellList!(x[1:end-100], box, cl); # fewer particles: nbatches unchanged","category":"section"},{"location":"Internals/#Performance-tuning-and-additional-options","page":"Internals","title":"Performance tuning and additional options","text":"Preallocating the cell lists and cell list auxiliary arrays\nPreallocating threaded output auxiliary arrays\nOptimizing the cell grid","category":"section"},{"location":"Internals/#Preallocating-the-cell-lists-and-cell-list-auxiliary-arrays","page":"Internals","title":"Preallocating the cell lists and cell list auxiliary arrays","text":"The arrays containing the cell lists can be initialized only once, and then updated. This is useful for iterative runs. Note that, since the list size depends on the box size and cutoff, if the box properties changes some arrays might be increased (never shrink) on this update.\n\n# Initialize cell lists with initial coordinates\ncl = CellList(x,box)\n# Allocate auxiliary arrays for threaded cell list construction\naux = CellListMap.AuxThreaded(cl)\nfor i in 1:nsteps\n    x = ... # new coordinates\n    box = Box(sides,cutoff) # perhaps the box has changed\n    UpdateCellList!(x,box,cl,aux) # modifies cl\n    pairwise!(...)\nend\n\nThe procedure is identical if using two sets of coordinates, in which case, one would do:\n\ncl = CellList(x,y,box)\naux = CellListMap.AuxThreaded(cl)\nfor i in 1:nsteps\n    x = ... # new coordinates\n    box = Box(sides,cutoff) # perhaps the box has changed\n    UpdateCellList!(x,y,box,cl,aux) # modifies cl\n    pairwise!(...)\nend\n\nBy passing the aux auxiliary structure, the UpdateCellList! functions will only allocate some minor variables associated to the launching of multiple threads and, possibly, to the expansion of the cell lists if the box or the number of particles became greater.\n\nwarning: Warning\nIf the number of batches of threading is changed, the structure of auxiliary arrays must be reinitialized. Otherwise, incorrect results can be obtained.","category":"section"},{"location":"Internals/#Preallocating-threaded-output-auxiliary-arrays","page":"Internals","title":"Preallocating threaded output auxiliary arrays","text":"On parallel runs, note that output_threaded is, by default, initialized on the call to pairwise!. Thus, if the calculation must be run multiple times (for example, for several steps of a trajectory), it is probably a good idea to preallocate the threaded output, particularly if it is a large array. For example, the arrays of forces should be created only once, and reset to zero after each use:\n\nforces = zeros(SVector{3,Float64},N)\nforces_threaded = [ deepcopy(forces) for i in 1:nbatches(cl) ]\nfor i in 1:nsteps\n    pairwise!(f, forces, box, cl, output_threaded=forces_threaded)\n    # work with the final forces vector\n    ...\n    # Reset forces_threaded\n    for i in 1:nbatches(cl)\n        @. forces_threaded[i] = zero(SVector{3,Float64})\n    end\nend\n\nIn this case, the forces vector will be updated by the default reduction method. nbatches(cl) is the number of batches of the parallel calculation, which is defined on the construction of the cell list (see the Parallelization section).","category":"section"},{"location":"Internals/#Optimizing-the-cell-grid","page":"Internals","title":"Optimizing the cell grid","text":"The partition of the space into cells is dependent on a parameter lcell which can be passed to Box. For example:\n\nbox = Box(x,box,lcell=2)\ncl = CellList(x,box)\npairwise!(...)\n\nThis parameter determines how fine is the mesh of cells. There is a trade-off between the number of cells and the number of particles per cell. For low-density systems, greater meshes are better, because each cell will have only a few particles and the computations loop over a smaller number of cells. For dense systems, it is better to run over more cells with less particles per cell. It is a good idea to test different values of lcell to check which is the optimal choice for your system. Usually the best value is lcell=1, because in CellListMap implements a method to avoid spurious computations of distances on top of the cell lists, but for very dense systems, or for very large cutoffs (meaning, for situations in which the number of particles per cell may be very large), a greater lcell may provide a better performance. It is unlikely that lcell > 3 is useful in any practical situation. For molecular systems with normal densities lcell=1 is likely the optimal choice. The performance can be tested using the progress meter, as explained below.\n\nAs a rough guide, lcell > 1 is only worthwhile if the number of particles per cell is greater than  ~200-400.\n\nnote: Note\nThe number of cells in which the particles will be classified is, for each dimension lcell*length/cutoff. Thus if the length of the box is too large relative to the cutoff, many cells will be created, and this imposes a perhaps large memory requirement. Usually, it is a good practice to limit the number of cells to be not greater than the number of particles, and for that the cutoff may have to be increased, if there is a memory bottleneck. A reasonable choice is to use cutoff = max(real_cutoff, length/n^(1/D)) where n is the number of particles and D is the dimension (2 or 3). With that the number of cells will be close to n in the worst case.","category":"section"},{"location":"Internals/#Output-progress","page":"Internals","title":"Output progress","text":"For long-running computations, the user might want to see the progress. A progress meter can be turned on with the show_progress option. For example:\n\npairwise!(f,output,box,cl,show_progress=true)\n\nwill print something like:\n\nProgress:  43%|█████████████████                    | ETA: 0:18:25\n\nThus, besides being useful for following the progress of a long run, it is useful to test different values of lcell to tune the performance of the code, by looking at the estimated time to finish (ETA) and killing the execution after a sample run. The default and recommended option for production runs is to use show_progress=false, because tracking the progress introduces a small overhead into the computation.","category":"section"},{"location":"Internals/#Some-benchmarks","page":"Internals","title":"Some benchmarks","text":"","category":"section"},{"location":"Internals/#Computing-a-histogram-of-pairwise-velocities","page":"Internals","title":"Computing a histogram of pairwise velocities","text":"The goal here is to provide a good implementation of cell lists. We compare it with the implementation of the nice cython/python halotools package, in the computation of an histogram of mean pairwise velocities.\n\n<center>\n<img src=../assets/b_cd.png>\n<br>\n<img src=../assets/b_cv.png>\n</center>\n\nThe full test is available at this repository. And we kindly thank Carolina Cuesta for providing the example. These benchmarks were run on an Intel i7 8th gen laptop, with 4 cores (8 threads).","category":"section"},{"location":"Internals/#Additional-options","page":"Internals","title":"Additional options","text":"","category":"section"},{"location":"Internals/#Input-coordinates-as-matrices","page":"Internals","title":"Input coordinates as matrices","text":"For compatibility with other software, the input coordinates can be provided as matrices. The matrices must have dimensions (2,N) or (3,N), where N is the number of particles (because Julia is column-major, thus this has the same memory layout of an array of length N of static vectors).\n\nFor example:\n\njulia> x = rand(3,100);\n\njulia> box = Box([1,1,1],0.1);\n\njulia> cl = CellList(x,box)\nCellList{3, Float64}\n  100 real particles.\n  99 cells with real particles.\n  162 particles in computing box, including images.\n\njulia> pairwise!((pair,n) -> n += 1, 0, box, cl) # count neighbors\n23","category":"section"},{"location":"Internals/#Docstrings","page":"Internals","title":"Docstrings","text":"","category":"section"},{"location":"Internals/#CellListMap.AuxThreaded-Tuple{CellListMap.CellListPair}","page":"Internals","title":"CellListMap.AuxThreaded","text":"AuxThreaded(cl::CellListPair{N,T}) where {N,T}\n\nConstructor for the AuxThreaded type for lists of disjoint particle sets,  to be passed to UpdateCellList! for in-place update of cell lists. \n\nExample\n\njulia> using CellListMap\n\njulia> box = Box([250,250,250],10);\n\njulia> x = [ 250*rand(3) for i in 1:50_000 ];\n\njulia> y = [ 250*rand(3) for i in 1:10_000 ];\n\njulia> cl = CellList(x,y,box);\n\njulia> aux = CellListMap.AuxThreaded(cl)\nCellListMap.AuxThreaded{3, Float64}\n Auxiliary arrays for nthreads = 8\n\njulia> UpdateCellList!(x,y,box,cl,aux)\nCellList{3, Float64}\n  100000 real particles.\n  31190 cells with real particles.\n  1134378 particles in computing box, including images.\n\n\n\n\n\n\n","category":"method"},{"location":"Internals/#CellListMap.AuxThreaded-Union{Tuple{CellListMap.CellList{N, T}}, Tuple{T}, Tuple{N}} where {N, T}","page":"Internals","title":"CellListMap.AuxThreaded","text":"AuxThreaded(cl::CellList{N,T}) where {N,T}\n\nConstructor for the AuxThreaded type, to be passed to UpdateCellList! for in-place  update of cell lists. \n\nExample\n\njulia> using CellListMap\n\njulia> box = Box([250,250,250],10);\n\njulia> x = [ 250*rand(3) for i in 1:10000 ];\n\njulia> cl = CellList(x,box);\n\njulia> aux = CellListMap.AuxThreaded(cl)\nCellListMap.AuxThreaded{3, Float64}\n Auxiliary arrays for nthreads = 8\n\njulia> UpdateCellList!(x,box,cl,aux)\nCellList{3, Float64}\n  100000 real particles.\n  31190 cells with real particles.\n  1134378 particles in computing box, including images.\n\n\n\n\n\n\n","category":"method"},{"location":"Internals/#CellListMap.wrap_relative_to-Tuple{Any, Any, AbstractMatrix}","page":"Internals","title":"CellListMap.wrap_relative_to","text":"wrap_relative_to(x, xref, unit_cell_matrix::AbstractMatrix)\n\nWraps the coordinates of point x such that it is the minimum image relative to xref. \n\n\n\n\n\n","category":"method"},{"location":"Internals/#CellListMap.wrap_relative_to-Tuple{Any, Any, AbstractVector}","page":"Internals","title":"CellListMap.wrap_relative_to","text":"wrap_relative_to(x,xref,sides::AbstractVector)\n\nWraps the coordinates of point x such that it is the minimum image relative to xref, for an Orthorhombic cell of which only the sides are provided.\n\n\n\n\n\n","category":"method"},{"location":"ParticleSystem/options/#Additional-options","page":"Options","title":"Additional options","text":"This section covers additional options for fine-tuning the behavior and performance of the ParticleSystem interface.","category":"section"},{"location":"ParticleSystem/options/#Turn-parallelization-on-and-off","page":"Options","title":"Turn parallelization on and off","text":"The use of parallel computations can be tunned on and of by the system.parallel boolean flag. For example, using 6 cores (12 threads) for the calculation of the minimum-distance example:\n\njulia> f(system) = pairwise!(minimum_distance, system)\nf (generic function with 1 method)\n\njulia> Threads.nthreads()\n8\n\njulia> system.parallel = true\ntrue\n\njulia> @btime f($system)\n  268.265 μs (144 allocations: 16.91 KiB)\nMinimumDistance(783, 497, 0.007213710914619913)\n\njulia> system.parallel = false\nfalse\n\njulia> @btime f($system)\n  720.304 μs (0 allocations: 0 bytes)\nMinimumDistance(783, 497, 0.007213710914619913)","category":"section"},{"location":"ParticleSystem/options/#Displaying-a-progress-bar","page":"Options","title":"Displaying a progress bar","text":"Displaying a progress bar: for very long runs, the user might want to see the progress of the computation. Use the show_progress keyword parameter of the pairwise! function for that.\n\nFor example, we execute the computation above, but with much more particles:\n\njulia> xpositions = rand(SVector{3,Float64},10^6);\n\njulia> ypositions = rand(SVector{3,Float64},10^6);\n\njulia> system = ParticleSystem(\n                  xpositions = xpositions,\n                  ypositions = ypositions,\n                  unitcell=[1.0,1.0,1.0],\n                  cutoff = 0.1,\n                  output = MinimumDistance(0,0,+Inf),\n                  output_name = :minimum_distance,\n               );\n\njulia> pairwise!(minimum_distance, system; show_progress = true)\nProgress:  24%|██████████▏                               |  ETA: 0:00:29\n\nBy activating the show_progress flag, a nice progress bar is shown.","category":"section"},{"location":"ParticleSystem/options/#Fine-control-of-the-parallelization","page":"Options","title":"Fine control of the parallelization","text":"The number of batches launched in parallel runs can be tunned by the nbatches keyword parameter of the ParticleSystem constructor. By default, the number of batches is defined as heuristic function dependent on the number of particles, and possibly returns optimal values in most cases. For a detailed discussion about this parameter, see Number of batches.\n\nFor example, to set the number of batches for cell list calculation to 4 and the number of batches for mapping to 8, we can do:\n\njulia> system = ParticleSystem(\n           xpositions = rand(SVector{3,Float64},1000),\n           unitcell=[1,1,1],\n           cutoff = 0.1,\n           output = 0.0,\n           output_name = :energy,\n           nbatches=(4,8), # use this keyword\n       );\n\nMost times it is expected that the default parameters are optimal. But particularly for inhomogeneous systems increasing the number of batches of the mapping phase (second parameter of the tuple) may improve the performance by reducing the idle time of threads.\n\nWhen the number of batches is left at the default (i.e., nbatches=(0,0) or omitted), it is automatically recomputed whenever UpdateParticleSystem! detects that the number of particles has changed. This allows adding or removing particles from the system without having to manually adjust the parallelization parameters:\n\njulia> system = ParticleSystem(\n           xpositions = rand(SVector{3,Float64}, 1000),\n           unitcell = [1,1,1],\n           cutoff = 0.1,\n           output = 0.0,\n           output_name = :energy,\n       );\n\njulia> nbatches(system) # default batches for 1000 particles\n(2, 4)\n\njulia> system.xpositions = rand(SVector{3,Float64}, 100000); # resize\n\njulia> UpdateParticleSystem!(system); # nbatches recomputed automatically\n\njulia> nbatches(system) # updated for 100000 particles\n(8, 32)\n\nIf the number of batches is explicitly set to non-zero values, they will be kept fixed and will not change when the number of particles changes.","category":"section"},{"location":"ParticleSystem/options/#Control-CellList-cell-size","page":"Options","title":"Control CellList cell size","text":"The cell sizes of the construction of the cell lists can be controlled with the keyword lcell of the ParticleSystem constructor. For example:\n\njulia> system = ParticleSystem(\n           xpositions = rand(SVector{3,Float64},1000),\n           unitcell=[1,1,1],\n           cutoff = 0.1,\n           output = 0.0,\n           output_name = :energy,\n           lcell=2,\n       );\n\nMost times using lcell=1 (default) or lcell=2 will provide the optimal performance. For very dense systems, or systems for which the number of particles within the cutoff is very large, larger values of lcell may improve the performance. To be tested by the user.\n\nnote: Note\nThe number of cells in which the particles will be classified is, for each dimension lcell*length/cutoff. Thus if the length of the box is too large relative to the cutoff, many cells will be created, and this imposes a perhaps large memory requirement. Usually, it is a good practice to limit the number of cells to be not greater than the number of particles, and for that the cutoff may have to be increased, if there is a memory bottleneck. A reasonable choice is to use cutoff = max(real_cutoff, length/n^(1/D)) where n is the number of particles and D is the dimension (2 or 3). With that the number of cells will be close to n in the worst case.","category":"section"},{"location":"ParticleSystem/options/#Coordinates-as-matrices","page":"Options","title":"Coordinates as matrices","text":"Coordinates can also be provided as matrices of size (D,N) where D is the dimension (2 or 3) and N is the number of particles. For example:\n\nusing CellListMap\nsystem = ParticleSystem(\n    xpositions=rand(2,100),\n    ypositions=rand(2,200),\n    cutoff=0.1,\n    unitcell=[1,1],\n    output=0.0,\n)\n\nwarning: Warning\nThis interface less flexible than when the coordinates are input as vectors of vectors, because the number of particles cannot be changed, because matrices cannot be resized. Otherwise, matrices can be used as input.","category":"section"},{"location":"ParticleSystem/two_sets/#Two-sets-of-particles","page":"Two sets of particles","title":"Two sets of particles","text":"If the computation involves two sets of particles, a similar interface is available. The only difference is that the coordinates of the two sets must be provided to the ParticleSystem constructor as the xpositions and ypositions arrays.","category":"section"},{"location":"ParticleSystem/two_sets/#Minimum-distance-example","page":"Two sets of particles","title":"Minimum-distance example","text":"We will illustrate this interface by computing the minimum distance between two sets of particles, which allows us to showcase further the definition of custom type interfaces:\n\nusing CellListMap, StaticArrays\n\nFirst, we define a variable type that will carry the indexes and the distance of the closest pair of particles:\n\nstruct MinimumDistance\n    i::Int\n    j::Int\n    d::Float64\nend\n\nThe function that, given two particles, retains the minimum distance, is:\n\nfunction minimum_distance(pair, md)\n    (; i, j, d) = pair\n    if d < md.d\n        md = MinimumDistance(i, j, d)\n    end\n    return md\nend\n\nWe overload copy, reset, and reducer functions, accordingly:\n\nimport CellListMap: copy_output, reset_output!, reducer!\ncopy_output(md::MinimumDistance) = md\n\nreset_output!(md::MinimumDistance) = MinimumDistance(0, 0, +Inf)\n\nreducer!(md1::MinimumDistance, md2::MinimumDistance) = md1.d < md2.d ? md1 : md2\n\nNote that since MinimumDistance is immutable, copying it is the same as returning the value. Also, resetting the minimum distance consists of setting its d field to +Inf. And, finally, reducing the threaded distances consists of keeping the pair with the shortest distance.","category":"section"},{"location":"ParticleSystem/two_sets/#Cross-interactions-with-two-cell-lists","page":"Two sets of particles","title":"Cross-interactions with two cell lists","text":"Next, we build the system. Here we choose to provide both sets of particles to the ParticleSystem constructor, which means that cell lists will be built for both sets:\n\nxpositions = rand(SVector{3,Float64},1000);\nypositions = rand(SVector{3,Float64},1000);\nsystem = ParticleSystem(\n   xpositions = xpositions,\n   ypositions = ypositions,\n   unitcell=[1.0,1.0,1.0],\n   cutoff = 0.1,\n   output = MinimumDistance(0,0,+Inf),\n   output_name = :minimum_distance,\n)\n\nAnd finally we can obtain the minimum distance between the sets:\n\npairwise!(minimum_distance, system)","category":"section"},{"location":"ParticleSystem/introduction/#ParticleSystem-interface","page":"ParticleSystem","title":"ParticleSystem interface","text":"","category":"section"},{"location":"ParticleSystem/introduction/#The-mapped-function","page":"ParticleSystem","title":"The mapped function","text":"The purpose of CellListMap is to compute a pairwise-dependent function for all pairs of particles that are closer to each other than a defined cutoff. This pairwise function must be implemented by the user and adhere to the following interface:\n\nfunction f(pair, output)\n    (; i, j, x, y, d2, d) = pair\n    # update output variable using above pair data\n    return output\nend\n\nwhere pair is a NeighborPair object, containing fields i, j, x, y, d2 and d, which here we extract from the object using destructuring syntax. \n\nx and y are the positions of the particles, already wrapped relative to each other according to the periodic boundary conditions (a minimum-image set of positions), i and j are the indexes of the particles in the arrays of coordinates, d2 is the squared distance between the particles, d is the distance, and output is the variable to be computed. \n\ninfo: Info\nDetails of the mapped function interfaceThe pair input of the function contains the  data that the user may use to update the output variable. The NeighborPair object contains fields x, y, i, j, d2 and the lazily computed d, meaning:Input/Output Type Meaning\nx SVector The coordinates of particle i of the pair.\ny SVector The coordinates of particle j of the pair (minimum-image relative to x).\ni Int Index of first particle in the original array of coordinates.\nj Int Index of second particle in the original array of coordinates.\nd2 <:Real Squared distance between the particles.\nd <:Real Squared distance between the particles (computed lazily).\noutput user defined the name of the variable to be updated.Notes: x and y may be 2D or 3D vectors, depending on the dimension of the system. The type of the coordinates of x, y, and of d2 are dependent on the input arrays and cutoff, and can be Float64, Float32, unitful quantities, etc.Return value Type Meaning\noutput user defined the updated value of output.The output variable must be returned by the function, being it mutable or immutable.","category":"section"},{"location":"ParticleSystem/introduction/#Basic-examples","page":"ParticleSystem","title":"Basic examples","text":"For example, computing the energy, as the sum of the inverse of the distance between particles, can be done with a function like:\n\nfunction energy(pair, u)\n    u += 1 / pair.d\n    return u\nend\n\nand this function is passed directly to pairwise!:\n\nu = pairwise!(energy, system)\n\n(what system is will be explained in the examples below). Note that the energy function only uses pair.d (the distance), but all other fields (pair.x, pair.y, pair.i, pair.j, pair.d2) are available.\n\nAlternatively, the function might require additional parameters, such as the masses of the particles. In this case, we can use a closure to provide such data:\n\nfunction energy(pair, u, masses)\n    (; i, j, d)  = pair \n    u += masses[i]*masses[j] / d\n    return u\nend\nconst masses = # ... some masses\nu = pairwise!((pair, u) -> energy(pair, u, masses), system)\n\nHere we reinforce the fact that the energy functions defined above compute the contribution to the energy of the interaction of a single pair of particles. This function will be called for every pair of particles within the cutoff, automatically, in the pairwise! call.\n\nnote: Note\nThe output of the CellListMap computation may be of any kind. Most commonly, it is an energy, a set of forces, or other data type that can be represented either as a number, an array of numbers, or an array of vectors (SVectors in particular), such as an arrays of forces.Additionally, the properties are frequently additive (the energy is the sum of the energy of the particles, or the forces are added by summation).For these types of output data the usage does not require the implementation of any data-type dependent function.","category":"section"},{"location":"ParticleSystem/introduction/#The-ParticleSystem-constructor","page":"ParticleSystem","title":"The ParticleSystem constructor","text":"The ParticleSystem constructor receives the properties of the system and sets up automatically the most commonly used data structures necessary.\n\nnote: Note\nSystems can be 2 or 3-dimensional.\nThe unitcell parameter may be:\na vector, in which case the system periodic boundaries are Orthorhombic, this is faster.\na matrix, in which case the system periodic boundaries are Triclinic (general). The lattice vectors correspond to the columns of the matrix.\nnothing (by default), in which case no periodic boundary conditions will be used.\nUnitful quantities can be provided, given appropriate types for all input parameters.","category":"section"},{"location":"ParticleSystem/introduction/#ParticleSystemPositions","page":"ParticleSystem","title":"The ParticleSystemPositions type","text":"The positions stored in a ParticleSystem (accessible via system.xpositions and, for two-set systems, system.ypositions) are of type ParticleSystemPositions{N,T}. This is a wrapper around a Vector{SVector{N,T}} that carries an internal updated flag. When coordinates are mutated through the supported interface, the flag is set automatically, so that cell lists are recomputed on the next call to pairwise!.\n\nA ParticleSystemPositions can be constructed from a vector of vectors (e.g. Vector{Vector{Float64}}), but typically this construction occurs only internal on the call to ParticleSystem. The mutation interface is important when the user wants to vary the coordinates of the system. Mutation must strictly follow the available API methods, otherwise subsequent computations might be wrong because they can be based on outdated cell lists.  ","category":"section"},{"location":"ParticleSystem/introduction/#Mutating-interface","page":"ParticleSystem","title":"Mutating interface","text":"The following functions mutate the positions and flag the array as updated, triggering recomputation of the cell lists on the next pairwise! call:\n\nFunction Description\nsetindex! Set the position of a single particle by index\nempty! Remove all positions\nresize! Resize the number of positions\nappend! Append positions from another collection\npush! Append positions from another collection\nBroadcasting In-place broadcast (e.g. p .= new_positions)\nview Views share the updated state of the original array, such that mutations to views are tracked.","category":"section"},{"location":"ParticleSystem/introduction/#Read-only-interface","page":"ParticleSystem","title":"Read-only interface","text":"Function Description\ngetindex Retrieve the position of a particle by index\nlength Number of particles\nsize Size tuple (length,)\naxes Index axes of the underlying vector\nkeys Linear indices\neachindex Iterator over valid indices\nfirstindex First valid index\nlastindex Last valid index\nfirst First position\nlast Last position\nndims Always returns 1\niterate Iteration protocol\ncopy Shallow copy (preserves updated flag)\nsimilar Allocate an uninitialized array of same shape\nview Create a view sharing the updated flag","category":"section"},{"location":"API/#Application-interface","page":"Public Interface","title":"Application interface","text":"","category":"section"},{"location":"API/#Neighborlist-interface","page":"Public Interface","title":"Neighborlist interface","text":"","category":"section"},{"location":"API/#Simple-neighborlists","page":"Public Interface","title":"Simple neighborlists","text":"","category":"section"},{"location":"API/#In-place-neighborlists","page":"Public Interface","title":"In-place neighborlists","text":"","category":"section"},{"location":"API/#ParticleSystems","page":"Public Interface","title":"ParticleSystems","text":"","category":"section"},{"location":"API/#Structures","page":"Public Interface","title":"Structures","text":"Public and exported:\n\nPublic but not exported:","category":"section"},{"location":"API/#The-parwise!-methods","page":"Public Interface","title":"The parwise! methods","text":"","category":"section"},{"location":"API/#Updating-systems","page":"Public Interface","title":"Updating systems","text":"","category":"section"},{"location":"API/#Custom-parallel-reduction","page":"Public Interface","title":"Custom parallel reduction","text":"These are public, but not exported.","category":"section"},{"location":"API/#Auxiliary-functions","page":"Public Interface","title":"Auxiliary functions","text":"These are public, but not exported.","category":"section"},{"location":"API/#CellListMap.neighborlist-Tuple{Any, Any}","page":"Public Interface","title":"CellListMap.neighborlist","text":"neighborlist(x, cutoff; unitcell=nothing, parallel=true, show_progress=false)\n\nComputes the list of pairs of particles in x which are closer to each other than cutoff. If the keyword parameter unitcell is provided (as a vector of sides or a general unit cell matrix, periodic boundary conditions are considered). \n\nnote: Note\nThe order of the pairs in the output of neighborlist is not guaranteed, and may change, in particular, in parallel runs.\n\nExample\n\nCompute the neighborlist between within a set Argon atoms, considering the system non-periodic (do not provide a unitcell):\n\njulia> using CellListMap, PDBTools\n\njulia> x = coor(read_pdb(CellListMap.argon_pdb_file));\n\njulia> neighborlist(x, 8.0; parallel=false)\n857-element Vector{Tuple{Int64, Int64, Float64}}:\n (1, 20, 3.163779526466901)\n (1, 61, 4.08865164675529)\n (1, 67, 5.939772435456664)\n ⋮\n (78, 88, 7.0061163797598445)\n (88, 54, 7.933654063435482)\n\nAnd now, considering the system periodic:\n\njulia> using CellListMap, PDBTools\n\njulia> x = coor(read_pdb(CellListMap.argon_pdb_file));\n\njulia> neighborlist(x, 8.0; unitcell = [21.0, 21.0, 21.0], parallel=false)\n1143-element Vector{Tuple{Int64, Int64, Float64}}:\n (1, 7, 3.3638756414119397)\n (1, 20, 3.163779526466901)\n (1, 47, 6.243868666689442)\n ⋮\n (68, 38, 7.409287768713663)\n (68, 90, 7.8758006026725464)\n\n\n\n\n\n","category":"method"},{"location":"API/#CellListMap.neighborlist-Tuple{Any, Any, Any}","page":"Public Interface","title":"CellListMap.neighborlist","text":"neighborlist(\n    x, y, cutoff; \n    unitcell=nothing, \n    parallel=true, \n    show_progress=false, \n    nbatches=(0,0)\n)\n\nComputes the list of pairs of particles of x which are closer than r to the particles of y. \n\nnote: Note\nThe order of the pairs in the output of neighborlist! is not guaranteed, and may change, in particular, in parallel runs.\n\nExamples\n\nCompute the neighborlist between two sets of Argon atoms, considering the system non-periodic (do not provide a unitcell):\n\njulia> using CellListMap, PDBTools\n\njulia> x = coor(read_pdb(CellListMap.argon_pdb_file, \"index <= 50\"));\n\njulia> y = coor(read_pdb(CellListMap.argon_pdb_file, \"index > 50\"));\n\njulia> CellListMap.neighborlist(x, y, 8.0; parallel=false)\n439-element Vector{Tuple{Int64, Int64, Float64}}:\n (1, 11, 4.08865164675529)\n (1, 17, 5.939772435456664)\n (1, 30, 2.4572288423012236)\n ⋮\n (46, 48, 4.9269093987894745)\n (46, 1, 7.99947286297016)\n\nNow, considering the system periodic:\n\njulia> using CellListMap, PDBTools\n\njulia> x = coor(read_pdb(CellListMap.argon_pdb_file, \"index <= 50\"));\n\njulia> y = coor(read_pdb(CellListMap.argon_pdb_file, \"index > 50\"));\n\njulia> CellListMap.neighborlist(x, y, 8.0; unitcell = [21.0, 21.0, 21.0], parallel=false)\n584-element Vector{Tuple{Int64, Int64, Float64}}:\n (1, 13, 7.0177634180502215)\n (1, 24, 7.97689645513632)\n (1, 29, 3.177029085967527)\n ⋮\n (18, 10, 6.9654396670725)\n (18, 37, 6.222988130894417)\n\n\n\n\n\n","category":"method"},{"location":"API/#CellListMap.InPlaceNeighborList","page":"Public Interface","title":"CellListMap.InPlaceNeighborList","text":"InPlaceNeighborList(;\n    x::AbstractVecOrMat,\n    y::Union{AbstractVecOrMat,Nothing}=nothing,\n    cutoff::T,\n    unitcell::Union{AbstractVecOrMat,Nothing}=nothing,\n    parallel::Bool=true,\n    show_progress::Bool=false,\n) where {T}\n\nFunction that initializes the InPlaceNeighborList structure, to be used for in-place computation of neighbor lists.\n\nIf only x is provided, the neighbor list of the set is computed. \nIf x and y are provided, the neighbor list between the sets is computed.\nIf unitcell is provided, periodic boundary conditions will be used. The unitcell can be a vector of Orthorhombic box sides, or an actual unitcell matrix for general cells. \nIf unicell is not provide (value nothing), no periodic boundary conditions will be considered. \n\nExamples\n\nHere the neighborlist structure is constructed for the first time, and used to compute the neighbor lists with the mutating neighborlist! function:\n\njulia> using CellListMap, StaticArrays\n\njulia> x = rand(SVector{3,Float64}, 10^4);\n\njulia> system = InPlaceNeighborList(x=x, cutoff=0.1, unitcell=[1,1,1]) \nInPlaceNeighborList with types: \nCellList{3, Float64}\nBox{OrthorhombicCell, 3, Float64, Float64, 9}\nCurrent list buffer size: 0\n\njulia> neighborlist!(system)\n210034-element Vector{Tuple{Int64, Int64, Float64}}:\n (1, 357, 0.09922225615002134)\n (1, 488, 0.043487074695938925)\n (1, 2209, 0.017779967072139684)\n ⋮\n (9596, 1653, 0.0897570322108541)\n (9596, 7927, 0.0898266280344037)\n\nThe coordinates of the system, its unitcell, or the cutoff can be changed with the update! function. If the number of pairs of the list does not change  significantly, the new calculation is minimally allocating, or non-allocating  at all, in particular if the computation is run without parallelization:\n\nnote: Note\nThe order of the pairs in the output of neighborlist! is not guaranteed, and may change, in particular, in parallel runs.\n\nIf the structure is used repeatedly for similar systems, the allocations will vanish, except for minor allocations used in the threading computation (if a  non-parallel computation is executed, the allocations will vanish completely):\n\njulia> x = rand(SVector{3,Float64}, 10^4);\n\njulia> system = InPlaceNeighborList(x=x, cutoff=0.1, unitcell=[1,1,1]);\n\njulia> @time neighborlist!(system);\n  0.008004 seconds (228 allocations: 16.728 MiB)\n\njulia> update!(system, rand(SVector{3,Float64}, 10^4); cutoff = 0.1, unitcell = [1,1,1]);\n\njulia> @time neighborlist!(system);\n  0.024811 seconds (167 allocations: 7.887 MiB)\n\njulia> update!(system, rand(SVector{3,Float64}, 10^4); cutoff = 0.1, unitcell = [1,1,1]);\n\njulia> @time neighborlist!(system);\n  0.005213 seconds (164 allocations: 1.439 MiB)\n\njulia> update!(system, rand(SVector{3,Float64}, 10^4); cutoff = 0.1, unitcell = [1,1,1]);\n\njulia> @time neighborlist!(system);\n  0.005276 seconds (162 allocations: 15.359 KiB)\n\n\n\n\n\n\n","category":"type"},{"location":"API/#CellListMap.update!","page":"Public Interface","title":"CellListMap.update!","text":"update!(system::InPlaceNeighborList, x::AbstractVecOrMat; cutoff=nothing, unitcell=nothing)\nupdate!(system::InPlaceNeighborList, x::AbstractVecOrMat, y::AbstractVecOrMat; cutoff=nothing, unitcell=nothing)\n\nUpdates a InPlaceNeighborList system, by updating the coordinates, cutoff, and unitcell.\n\nExamples\n\nFor self-pairs computations\n\njulia> x = rand(SVector{3,Float64}, 10^3);\n\njulia> system = InPlaceNeighborList(x=x; cutoff=0.1)\nInPlaceNeighborList with types: \nCellList{3, Float64}\nBox{NonPeriodicCell, 3, Float64, Float64, 9}\nCurrent list buffer size: 0\n\njulia> neighborlist!(system);\n\njulia> new_x = rand(SVector{3,Float64}, 10^3);\n\njulia> update!(system, new_x; cutoff = 0.05)\nInPlaceNeighborList with types: \nCellList{3, Float64}\nBox{NonPeriodicCell, 3, Float64, Float64, 9}\nCurrent list buffer size: 1826\n\njulia> neighborlist!(system)\n224-element Vector{Tuple{Int64, Int64, Float64}}:\n (25, 486, 0.03897345036790646)\n ⋮\n (723, 533, 0.04795768478723409)\n (868, 920, 0.042087156715720137)\n\n\n\n\n\n","category":"function"},{"location":"API/#CellListMap.neighborlist!","page":"Public Interface","title":"CellListMap.neighborlist!","text":"neighborlist(system::InPlaceNeighborList)\n\nComputes the neighbor list in-place, given a InPlaceNeighborList system.\n\nExample\n\nIn the following example, we compute the neighbor list of a set of random particles, and then we change the coordinates and recompute the neighbor list without reallocations (or with minimal allocations if run in parallel):\n\njulia> using CellListMap, StaticArrays\n\njulia> x = rand(SVector{3,Float64}, 10^4);\n\njulia> system = InPlaceNeighborList(x=x, cutoff=0.1, unitcell=[1,1,1], parallel=false);\n\njulia> neighborlist!(system)\n210034-element Vector{Tuple{Int64, Int64, Float64}}:\n (1, 2669, 0.04444346517920411)\n (1, 8475, 0.02554075837438248)\n ⋮\n (9463, 5955, 0.08698158178214915)\n (9463, 2308, 0.09482635540291776)\n\njulia> x .= rand(SVector{3,Float64}, 10^4); # change coordinates\n\njulia> @time neighborlist!(system; parallel=false)\n  0.007978 seconds\n209418-element Vector{Tuple{Int64, Int64, Float64}}:\n (1, 1253, 0.09420839394144173)\n (1, 2048, 0.01448095691254145)\n ⋮\n (9728, 6367, 0.08204145034963985)\n (9728, 2594, 0.06536277710826768)\n\n\n\n\n\n","category":"function"},{"location":"API/#CellListMap.NeighborPair","page":"Public Interface","title":"CellListMap.NeighborPair","text":"NeighborPair{N,T,T2}\n\nStructure that holds the information of a pair of particles that are neighbors within the cutoff distance.\n\nFields accessed by the user:\n\ni::Int: index of the first particle in the original array of coordinates.\nj::Int: index of the second particle in the original array of coordinates.\nx::SVector{N,T}: coordinates of the first particle (minimum-image adjusted).\ny::SVector{N,T}: coordinates of the second particle (minimum-image adjusted).\nd::T: Euclidean distance between the particles (computed lazily).\nd2::T2: squared Euclidean distance between the particles.\n\n\n\n\n\n","category":"type"},{"location":"API/#CellListMap.ParticleSystem","page":"Public Interface","title":"CellListMap.ParticleSystem","text":"ParticleSystem(\n    xpositions::AbstractVector{SVector{N,T}};\n    ypositions::Union{AbstractVector{SVector{N,T}}, Nothing} = nothing,\n    unitcell::Union{SVector, SMatrix, Nothing} = nothing,\n    cutoff::Number,\n    output,\n    output_name::Symbol = :output,\n    parallel::Bool = true,\n    nbatches::Tuple{Int,Int} = (0, 0),\n    lcell = 1,\n    validate_coordinates = _validate_coordinates,\n)\n\nType-stable constructor. Accepts a Vector{SVector{N,T}} for positions and an SVector (orthorhombic), SMatrix (triclinic), or nothing (non-periodic) for the unit cell. All type parameters are resolved at compile time.\n\nParticleSystem(;\n    xpositions::Union{AbstractVector{<:AbstractVector},AbstractMatrix},\n    #or\n    xpositions::Union{AbstractVector{<:AbstractVector},AbstractMatrix},\n    ypositions::Union{AbstractVector{<:AbstractVector},AbstractMatrix},\n    # and\n    unitcell::Union{Nothing,AbstractVecOrMat} = nothing,\n    cutoff::Number,\n    output,\n    output_name::Symbol = :output,\n    parallel::Bool = true,\n    nbatches::Tuple{Int,Int} = (0, 0),\n    validate_coordinates = _validate_coordinates,\n)\n\nFlexible keyword-only constructor. Accepts any supported coordinate type (vectors of vectors, matrices, or SVector arrays) and any AbstractVecOrMat for the unit cell. Converts inputs and delegates to the type-stable constructor.\n\nConstructor of the ParticleSystem type given the positions of the particles.\n\nPositions can be provided as vectors of 2D or 3D vectors (preferentially static vectors from StaticArrays), or as (2,N) or (3,N) matrices (v0.8.28 is required for matrices).\nIf only the xpositions array is provided, a single set of coordinates is considered, and the computation will be mapped for the N(N-1) pairs of this set.\nIf the xpositions and ypositions arrays of coordinates are provided, the computation will be mapped to the N×M pairs of particles, being N and M the number of particles of each set of coordinates.\n\nThe unit cell (either a vector for Orthorhombic cells or a full unit cell matrix for Triclinic cells - where columns contain the lattice vectors), the cutoff used for the construction of the cell lists and the output variable of the calculations. If unitcell == nothing, the system is considered not-periodic, in which case artificial periodic boundaries will be built such that images are farther from each other than the cutoff.\n\nnote: Note\nThe output value is the initial value of the output. Tipicaly this is set to zero(typeof(output)). In subsequent call to pairwise!, the initial value can be optionally reset to zero(typeof(output)).\n\noutput_name can be set to a symbol that best identifies the output variable. For instance, if output_name=:forces, the forces can be retrieved from the structure using the system.forces notation.\n\nThe parallel and nbatches flags control the parallelization scheme of computations (see https://m3g.github.io/CellListMap.jl/stable/parallelization/#Number-of-batches)). By default the parallelization is turned on and nbatches is set with heuristics that may provide good efficiency in most cases.\n\nThe validate_coordinates function can be used to validate the coordinates before computations, and throw appropriate error messages. By default the validation checks if the coordinates are not missing or NaN. The function must have a single input parameter and be (x) -> nothing to skip any validation.\n\nExample\n\nIn these examples, we compute the sum of the squared distances between the particles that are within the cutoff:\n\nSingle set of particles\n\njulia> using CellListMap\n\njulia> using PDBTools: read_pdb, coor\n\njulia> positions = coor(read_pdb(CellListMap.argon_pdb_file));\n\njulia> sys = ParticleSystem(\n           xpositions = positions,\n           unitcell = [21.0, 21.0, 21.0],\n           cutoff = 8.0,\n           output = 0.0,\n        );\n\njulia> pairwise!((pair,output) -> output += pair.d2, sys)\n43774.54367600001\n\nTwo sets of particles\n\njulia> using CellListMap, PDBTools\n\njulia> xpositions = coor(read_pdb(CellListMap.argon_pdb_file))[1:50];\n\njulia> ypositions = coor(read_pdb(CellListMap.argon_pdb_file))[51:100];\n\njulia> sys = ParticleSystem(\n           xpositions = xpositions,\n           ypositions = ypositions,\n           unitcell = [21.0, 21.0, 21.0],\n           cutoff = 8.0,\n           output = 0.0,\n           parallel = false, # use true for parallelization\n        );\n\njulia> pairwise!((pair,output) -> output += pair.d2, sys)\n21886.196785000004\n\n\n\n\n\n","category":"function"},{"location":"API/#CellListMap.ParticleSystemPositions","page":"Public Interface","title":"CellListMap.ParticleSystemPositions","text":"ParticleSystemPositions{N,T}\n\nWrapper around a Vector{SVector{N,T}} that carries particle coordinates and an internal updated flag. When coordinates are mutated through the supported interface, the flag is set automatically, so that cell lists are recomputed on the next call to pairwise!.\n\nA ParticleSystemPositions can be constructed from:\n\nA vector of vectors (e.g. Vector{Vector{Float64}}).\nA vector of SVectors (e.g. Vector{SVector{3,Float64}}).\nAn (D, M) matrix, where D is the dimension and M the number of particles.\n\nMutating interface\n\nThe following functions mutate the positions and flag the array as updated, triggering recomputation of the cell lists on the next pairwise! call:\n\nFunction Description\nsetindex! Set the position of a single particle by index\nempty! Remove all positions\nresize! Resize the number of positions\nappend! Append positions from another collection\npush! Add element\nBroadcasting In-place broadcast (e.g. p .= new_positions)\n\nRead-only interface\n\nFunction Description\ngetindex Retrieve the position of a particle by index\nlength Number of particles\nsize Size tuple (length,)\naxes Index axes of the underlying vector\nkeys Linear indices\neachindex Iterator over valid indices\nfirstindex First valid index\nlastindex Last valid index\nfirst First position\nlast Last position\nndims Always returns 1\niterate Iteration protocol\ncopy Shallow copy (preserves updated flag)\nsimilar Allocate an uninitialized array of same shape\nview Create a view sharing the updated flag\nshow Pretty-printing\n\n\n\n\n\n","category":"type"},{"location":"API/#CellListMap.AbstractParticleSystem","page":"Public Interface","title":"CellListMap.AbstractParticleSystem","text":"AbstractParticleSystem{OutputName}\n\nAn abstract type representing a particle system that computes interactions between particles using cell lists. Can be used to control dispatch of functions that operate on particle systems, because all particle systems should be a subtype of this type.\n\nUse the ParticleSystem constructor and interface for anything else than dispatch.\n\n\n\n\n\n","category":"type"},{"location":"API/#CellListMap.ParticleSystem1","page":"Public Interface","title":"CellListMap.ParticleSystem1","text":"ParticleSystem1\n\nStructure that carries the information necessary for pairwise! computations, for systems with one set of positions (thus, replacing the loops over N(N-1)  pairs of particles of the set). Can be used to control dispatch.\n\nUse the ParticleSystem constructor and interface for anything else than dispatch.\n\n\n\n\n\n","category":"type"},{"location":"API/#CellListMap.ParticleSystem2","page":"Public Interface","title":"CellListMap.ParticleSystem2","text":"ParticleSystem2\n\nStructure that carries the information necessary for pairwise! computations, for systems with two set of positions (thus, replacing the loops over N×M  pairs of particles, being N and M the number of particles of each set). Can be used to control dispatch.\n\nUse the ParticleSystem constructor and interface for anything else than dispatch.\n\n\n\n\n\n","category":"type"},{"location":"API/#CellListMap.pairwise!-Union{Tuple{F}, Tuple{F, CellListMap.AbstractParticleSystem}} where F<:Function","page":"Public Interface","title":"CellListMap.pairwise!","text":"pairwise!(\n    f::Function, system::AbstractParticleSystem; \n    show_progress=true, reset=true,\n)\n\nFunction that maps the f function into all pairs of particles of system that are found to be within the cutoff. \n\nThe function f receives a NeighborPair struct and the output:\n\nfunction f(pair, output)\n    # pair.i, pair.j: indices of the particles\n    # pair.x, pair.y: coordinates (minimum-image adjusted)\n    # pair.d: distance between particles\n    # pair.d2: squared distance\n    # update output\n    return output\nend\n\nThread-safety is taken care automatically in parallel executions.\n\npairwise is an alias to pairwise! for syntax consistency when the output variable is immutable.\n\nIf reset is set to false, the value of system.output will not be set to zero(typeof(system.output)) before the new accumulation.\n\nExample\n\nIn this example we compute the sum of 1/(1+d) where d is the distance between particles of a set, for d < cutoff. \n\njulia> sys = ParticleSystem(\n           xpositions = rand(SVector{3,Float64},1000), \n           unitcell=[1,1,1], \n           cutoff = 0.1, \n           output = 0.0\n           );\n\njulia> pairwise!((pair, output) -> output += 1 / (1 + pair.d), sys)\n1870.0274887950268\n\n\n\n\n\n","category":"method"},{"location":"API/#CellListMap.update_cutoff!","page":"Public Interface","title":"CellListMap.update_cutoff!","text":"update_cutoff!(system, cutoff)\n\nFunction to update the cutoff` of the system. \n\nThis function can be used to update the system geometry in iterative schemes.\n\nExample\n\nHere we initialize a particle system with a cutoff of 8.0 and then update the cutoff to 10.0. \n\njulia> using CellListMap, PDBTools\n\njulia> x = coor(read_pdb(CellListMap.argon_pdb_file));\n\njulia> sys = ParticleSystem(\n           xpositions = x,\n           unitcell=[21.0,21.0,21.0],\n           cutoff = 8.0,\n           output = 0.0\n       );\n\njulia> update_cutoff!(sys, 10.0)\nParticleSystem1{default_output_name} of dimension 3, composed of:\n    Box{CellListMap.OrthorhombicCell, 3}\n      unit cell matrix = [ 21.0 0.0 0.0; 0.0 21.0 0.0; 0.0 0.0 21.0 ]\n      cutoff = 10.0\n      number of computing cells on each dimension = [5, 5, 5]\n      computing cell sizes = [10.5, 10.5, 10.5] (lcell: 1)\n      Total number of cells = 125\n    CellListMap.CellList{3, Float64}\n      100 real particles.\n      8 cells with real particles.\n      800 particles in computing box, including images.\n    Parallelization auxiliary data set for 8 batch(es).\n    Type of output variable (default_output_name): Float64\n\n\n\n\n\n","category":"function"},{"location":"API/#CellListMap.update_unitcell!","page":"Public Interface","title":"CellListMap.update_unitcell!","text":"update_unitcell!(system, unitcell)\n\nFunction to update the unit cell of the system. The unicell must be of the  same type (OrthorhombicCell, TriclinicCell) of the original system  (changing the type of unit cell requires reconstructing the system).\n\nThe unitcell can be a N×N matrix or a vector of dimension N, where N is the dimension of the system (2D or 3D).\n\nThis function can be used to update the system geometry in iterative schemes, where the size of the simulation box changes during the simulation.\n\nnote: Note\nManual updating of the unit cell of non-periodic systems is not allowed.\n\nExample\n\njulia> using CellListMap, StaticArrays, PDBTools\n\njulia> xpositions = coor(read_pdb(CellListMap.argon_pdb_file));\n\njulia> sys = ParticleSystem(\n           xpositions = xpositions,\n           unitcell=[21,21,21],\n           cutoff = 8.0,\n           output = 0.0\n       );\n\njulia> update_unitcell!(sys, [30.0, 30.0, 30.0])\nParticleSystem1{default_output_name} of dimension 3, composed of:\n    Box{CellListMap.OrthorhombicCell, 3}\n      unit cell matrix = [ 30.0 0.0 0.0; 0.0 30.0 0.0; 0.0 0.0 30.0 ]\n      cutoff = 8.0\n      number of computing cells on each dimension = [6, 6, 6]\n      computing cell sizes = [10.0, 10.0, 10.0] (lcell: 1)\n      Total number of cells = 216\n    CellListMap.CellList{3, Float64}\n      100 real particles.\n      8 cells with real particles.\n      800 particles in computing box, including images.\n    Parallelization auxiliary data set for 8 batch(es).\n    Type of output variable (default_output_name): Float64\n\n\n\n\n\n\n","category":"function"},{"location":"API/#CellListMap.resize_output!","page":"Public Interface","title":"CellListMap.resize_output!","text":"resize_output!(sys::AbstractParticleSystem, n::Int)\n\nResizes the output array and the auxiliary output arrays used for multithreading, if the number of particles of the system changed.\n\nThe function will error if Base.resize! is not defined for the  type of system.output. In this case, a Base.resize! method must be implemented by the user. \n\nwarn: Warn\nThis function must be used whenever the output is dependent on the number of particles, and that changes, because it adjust the size of the copies of the output variable used for multi-threading.\n\n\n\n\n\n","category":"function"},{"location":"API/#CellListMap.copy_output","page":"Public Interface","title":"CellListMap.copy_output","text":"copy_output(x)\n\nDefines how the output variable is copied. Identical to Base.copy(x) and implemented for the types in Union{Number, StaticArraysCore.FieldVector, StaticArraysCore.SVector}.\n\nOther custom output types must have their copy_output method implemented.\n\nExample\n\nusing CellListMap\n# Custom data type\nstruct A x::Int end\n# Custom output type (array of A)\noutput = [ A(0) for _ in 1:100 ]\n# How to copy an array of `A`\nCellListMap.copy_output(v::Vector{A}) = [ x for x in v ]\n\n# Alternatively, in this case, one could have defined:\nBase.copy(a::A) = a\nCellListMap.copy_output(v::Vector{A}) = copy(v)\n\nThe user must guarantee that the copy is independent of the original array. For many custom types it is possible to define \n\nCellListMap.copy_output(v::Vector{T}) where {T<:CustomType} = deepcopy(v)\n\n\n\n\n\n","category":"function"},{"location":"API/#CellListMap.reset_output!","page":"Public Interface","title":"CellListMap.reset_output!","text":"reset_output(x)\nreset_output!(x)\n\nFunction that defines how to reset (or zero) the output variable. For Union{Number, StaticArraysCore.FieldVector, StaticArraysCore.SVector} it is  implemented as zero(x).\n\nOther custom output types must have their reset_output! method implemented. \n\nThe function must return the variable itself. If it is immutable, a new instante of the variable must be created, with the reset value. \n\nnote: Note\nBy default, if reset_output! is defined for one element type, reset_output! is defined for arrays of that type by calling reset_output! for each element of the array.  The user must overload the reset_output!  function for the custom type array if that is not the desired behavior.\n\nreset_output and reset_output! are aliases, and by convention reset_output! is preferred for mutable types.\n\nExample\n\nIn this example, we define a reset_output function that will set to +Inf the minimum distance between particles (not always resetting means zeroing).\n\njulia> using CellListMap\n\njulia> struct MinimumDistance d::Float64 end\n\njulia> CellListMap.reset_output(x::MinimumDistance) = MinimumDistance(+Inf)\n\njulia> x = MinimumDistance(1.0)\nMinimumDistance(1.0)\n\njulia> CellListMap.reset_output(x)\nMinimumDistance(Inf)\n\nSee the reducer help entry for a complete example of how to use reset_output.\n\n\n\n\n\n","category":"function"},{"location":"API/#CellListMap.reducer!","page":"Public Interface","title":"CellListMap.reducer!","text":"reducer(x,y)\nreducer!(x,y)\n\nDefines how to reduce (combine, or merge) to variables computed in parallel to obtain a single instance of the variable with the reduced result. \n\nreducer and reducer! are aliases, and reducer! is preferred, by convention for mutating functions.\n\nThe most common reducer is the sum, and this is how it is implemented for Union{Number, StaticArraysCore.FieldVector, StaticArraysCore.SVector}. For example, when computing energies, or forces, the total energy is the sum of the energies. The force on one particle is the sum of the forces between the particle and every other particle. Thus, the implemented reducer is the sum: \n\nreducer(x,y) = +(x,y)\n\nHowever, in  many cases, reduction must be done differently. For instance, if the minimum distance between particles is to be computed, it is interesting to define a custom type and associated reducer. For example:\n\nstruct MinimumDistance d::Float64 end\nreducer(x::MinimumDistance, y::MinimumDistance) = MinimumDistance(min(x.d, y.d))\n\nThe overloading of reducer allows the use of parallel computations for custom,  complex data types, containing different types of variables, fields, or sizes.\n\nThe appropriate behavior of the reducer should be carefully inspected by the user to avoid spurious results. \n\nExample\n\nIn this example we show how to obtain the minimum distance among argon atoms in a simulation box.\n\njulia> using CellListMap, PDBTools\n\njulia> positions = coor(read_pdb(CellListMap.argon_pdb_file));\n\njulia> struct MinimumDistance d::Float64 end # Custom output type\n\njulia> CellListMap.copy_output(d::MinimumDistance) = MinimumDistance(d.d) # Custom copy function for `Out`\n\njulia> CellListMap.reset_output(d::MinimumDistance) = MinimumDistance(+Inf) # How to reset an array with elements of type `MinimumDistance`\n\njulia> CellListMap.reducer(md1::MinimumDistance, md2::MinimumDistance) = MinimumDistance(min(md1.d, md2.d)) # Custom reduction function\n\njulia> # Construct the system\n       sys = ParticleSystem(;\n           positions = positions,\n           unitcell = [21,21,21],\n           cutoff = 8.0,\n           output = MinimumDistance(+Inf),\n       );\n\njulia> # Obtain the minimum distance between atoms:\n       pairwise!((pair,output) -> pair.d < output.d ? MinimumDistance(pair.d) : output, sys)\nMinimumDistance(2.1991993997816563)\n\n\n\n\n\n","category":"function"},{"location":"API/#CellListMap.reduce_output!","page":"Public Interface","title":"CellListMap.reduce_output!","text":"reduce_output!(output, output_threaded)\n\nFunction that defines how to reduce the vector of output_threaded variables (one per batch) into the single output variable, after a parallel computation. The default implementation calls CellListMap.reducer(output, output_threaded[i]) for each batch sequentially.\n\nFor custom output types that are large collections (e.g. lists of pairs), overloading this function can avoid significant allocation overhead. The generic implementation performs nbatches incremental resize! calls on output, each copying the existing data to a new buffer. For output types where the final size is known only after computing all batches, this leads to O(N × nbatches) total memory traffic in the reduce step. A custom overload can compute the total size first, resize once, and then copy each batch directly.\n\nRequirements for the overload\n\nThe signature must be reduce_output!(output::MyType, output_threaded::Vector{<:MyType})\nThe function must return output.\n\nExample\n\nThe following shows a custom overload for a hypothetical PairList output type that holds a growing list of pairs. The overload resizes the output list once and copies each batch with copyto!, avoiding the O(N × nbatches) overhead of the generic implementation:\n\nstruct PairList\n    n::Int\n    list::Vector{Tuple{Int,Int,Float64}}\nend\n\nfunction CellListMap.reduce_output!(output::PairList, output_threaded::Vector{<:PairList})\n    ntot = output.n + sum(nb.n for nb in output_threaded; init = 0)\n    if length(output.list) < ntot\n        resize!(output.list, ntot)\n    end\n    offset = output.n\n    for nb in output_threaded\n        output.list[offset + 1:offset + nb.n] .= @view(nb.list[1:nb.n])\n        offset += nb.n\n    end\n    output.n = ntot\n    return output\nend\n\n\n\n\n\n","category":"function"},{"location":"API/#CellListMap.wrap_relative_to","page":"Public Interface","title":"CellListMap.wrap_relative_to","text":"wrap_relative_to(x, xref, unit_cell_matrix::AbstractMatrix)\n\nWraps the coordinates of point x such that it is the minimum image relative to xref. \n\n\n\n\n\nwrap_relative_to(x,xref,sides::AbstractVector)\n\nWraps the coordinates of point x such that it is the minimum image relative to xref, for an Orthorhombic cell of which only the sides are provided.\n\n\n\n\n\n","category":"function"},{"location":"API/#CellListMap.get_computing_box","page":"Public Interface","title":"CellListMap.get_computing_box","text":"get_computing_box(sys::AbstractParticleSystem)\n\nRetrieves the computing box of the system. The computing box is large enough to contain all coordinates of the particles, plus the cutoff.\n\n\n\n\n\n","category":"function"},{"location":"ParticleSystem/single_set_simple/#Single-set:-Simple-outputs","page":"Single set: Simple outputs","title":"Single set: Simple outputs","text":"This section shows examples of computing simple outputs (a single scalar or a single array) for a single set of particles.","category":"section"},{"location":"ParticleSystem/single_set_simple/#Potential-energy-example","page":"Single set: Simple outputs","title":"Potential energy example","text":"For example, here we read the coordinates of Argon atoms from a PDB file. The coordinates are given as vector of SVectors. We then compute an \"energy\", which in this case is simply the sum of 1/d over all pair of particles, within a cutoff.\n\nusing CellListMap, PDBTools\nargon_coordinates = coor(read_pdb(CellListMap.argon_pdb_file))\nsystem = ParticleSystem(\n    xpositions=argon_coordinates,\n    unitcell=[21.0,21.0,21.0],\n    cutoff = 8.0,\n    output = 0.0,\n    output_name = :energy\n)\n\nNow, let us compute the energy of the particles, assuming a simple formula which depends on the inverse of the distance between pairs:\n\nfunction energy(pair, energy)\n    energy += 1 / pair.d\n    return energy\nend\n\npairwise!(energy, system)\n\nBecause output_name was set to :energy, the system.energy field accesses the resulting value of the computation:\n\nsystem.energy\n\nIf the output_name field is not provided, the output value from the system.output field.","category":"section"},{"location":"ParticleSystem/single_set_simple/#The-initial-value-of-output","page":"Single set: Simple outputs","title":"The initial value of output","text":"The output = 0.0 in the construction of the example above is used, by default, to set the type of the output variable, here a Float64. This value is stored in  the output field, but it is, by default, reset to zero(typeof(output)) when calling the pairwise! function.\n\nTo use the initial value provided and accumulate on top of it in the call to pairwise!,  the reset=false option must be provided, as:\n\npairwise!(energy, system; reset=false)\n\nNote that the result is twice the previous value, because the initial value of the energy was not reset. If we instead call pairwise! with the default parameters, we recompute the energy from scratch:\n\npairwise!(energy, system) # reset=true by default","category":"section"},{"location":"ParticleSystem/single_set_simple/#Computing-forces","page":"Single set: Simple outputs","title":"Computing forces","text":"Following the example above, let us compute the forces between the particles. We have to define the function that computes the force between a pair of particles and updates the array of forces:\n\nfunction update_forces!(pair, forces)\n    (; i, j, x, y, d2, d) = pair\n    df = (1/d2)*(1/d)*(y - x)\n    forces[i] += df\n    forces[j] -= df\n    return forces\nend\n\nImportantly, the function must return the forces array to follow the API.\n\nNow, let us setup the system with the new type of output variable, which will be now an array of forces with the same type as the positions:\n\nusing PDBTools\nargon_coordinates = coor(read_pdb(CellListMap.argon_pdb_file))\nsystem = ParticleSystem(\n    xpositions=argon_coordinates,\n    unitcell=[21.0, 21.0, 21.0],\n    cutoff = 8.0,\n    output = similar(argon_coordinates),\n    output_name = :forces\n)\n\nA call to pairwise! with the appropriate function definition will update the forces:\n\npairwise!((pair, forces) -> update_forces!(pair, forces), system)\n\nIf we want now to accumulate additional forces, we need to use reset=false in the call to pairwise!. ","category":"section"},{"location":"unitcell/#Unitcell-requirements","page":"Unitcell requirements","title":"Unitcell requirements","text":"The unitcell provided by the user must satisfy certain conditionsfor the cell list algorithm to work correctly. If the conditions are not satisfied, the computation will throw an early error. These conditions guarantee that the box is not too small for the given required cutoff, considering the perodic conditions. In the  simple case of orthorhombic boxes, the conditions imply that each side must be greater than twice the cutoff. These conditions are usually met except for very small systems, which are not within the current scope of this package.","category":"section"},{"location":"unitcell/#In-3D","page":"Unitcell requirements","title":"In 3D","text":"Given an unitcell matrix of the form leftvecavecbveccright, where veca, vecb, and  vecc are the lattice vectors, the following conditions must be met:\n\nveca cdot fracvecb times veccvecb times vecc gt 2r_cut\n\nvecb cdot fracvecc times vecavecc times veca gt 2r_cut\n\nvecc cdot fracveca times vecbveca times vecb gt 2r_cut\n\nwhere r_cut is the cutoff. ","category":"section"},{"location":"unitcell/#In-2D","page":"Unitcell requirements","title":"In 2D","text":"Given an unitcell matrix of the form leftvecavecbright, where veca and vecb  are the lattice vectors, the following conditions must be met:\n\nsqrtveca^2 - left(vecacdot fracvecbvecbright)^2 gt 2r_cut \n\nsqrtvecb^2 - left(vecbcdot fracvecavecaright)^2 gt 2r_cut \n\nwhere r_cut is the cutoff. ","category":"section"},{"location":"citation/#Citation","page":"Citation","title":"Citation","text":"If you use this software, please be kind to cite the following article in relevant publications, to keep us motivated in developing  new features and enhancements:\n\nL. Martínez, CellListMap.jl: Efficient and customizable cell list implementation for calculation of pairwise particle properties within a cutoff. Computer Physics Communications, 279, 108452, (2022). DOI: 10.1016/j.cpc.2022.108452","category":"section"},{"location":"ParticleSystem/examples/#Complete-examples","page":"Complete examples","title":"Complete examples","text":"This section contains complete, self-contained example codes that can be copied and run directly.","category":"section"},{"location":"ParticleSystem/examples/#Simple-energy-computation","page":"Complete examples","title":"Simple energy computation","text":"In this example, a simple potential energy defined as the sum of the inverse of the distance between the particles is computed.\n\nusing CellListMap\nusing StaticArrays\nsystem = ParticleSystem(\n    xpositions = rand(SVector{3,Float64},1000),\n    unitcell=[1.0,1.0,1.0],\n    cutoff = 0.1,\n    output = 0.0,\n    output_name = :energy\n)\npairwise!((pair, energy) -> energy += 1 / pair.d, system)","category":"section"},{"location":"ParticleSystem/examples/#Force-computation","page":"Complete examples","title":"Force computation","text":"Here we compute the force vector associated to the potential energy function of the previous example.\n\nusing CellListMap\nusing StaticArrays\npositions = rand(SVector{3,Float64},1000)\nsystem = ParticleSystem(\n    xpositions = positions,\n    unitcell=[1.0,1.0,1.0],\n    cutoff = 0.1,\n    output = similar(positions),\n    output_name = :forces\n)\nfunction update_forces!(pair, forces)\n    (; x, y, i, j, d2, d) = pair\n    df = (1/d2)*(1/d)*(y - x)\n    forces[i] += df\n    forces[j] -= df\n    return forces\nend\npairwise!(update_forces!, system)","category":"section"},{"location":"ParticleSystem/examples/#Energy-and-forces","page":"Complete examples","title":"Energy and forces","text":"In this example, the potential energy and the forces are computed in a single run, and a custom data structure is defined to store both values.\n\nusing CellListMap\nusing StaticArrays\n# Define custom type\nmutable struct EnergyAndForces\n    energy::Float64\n    forces::Vector{SVector{3,Float64}}\nend\n# Custom copy, reset and reducer functions\nimport CellListMap: copy_output, reset_output!, reducer\ncopy_output(x::EnergyAndForces) = EnergyAndForces(copy(x.energy), copy(x.forces))\nfunction reset_output!(output::EnergyAndForces)\n    output.energy = 0.0\n    for i in eachindex(output.forces)\n        output.forces[i] = SVector(0.0, 0.0, 0.0)\n    end\n    return output\nend\nfunction reducer(x::EnergyAndForces, y::EnergyAndForces)\n    e_tot = x.energy + y.energy\n    x.forces .+= y.forces\n    return EnergyAndForces(e_tot, x.forces)\nend\n# Function that updates energy and forces for each pair\nfunction energy_and_forces!(pair, output::EnergyAndForces)\n    (; i, j, x, y, d2, d) = pair\n    output.energy += 1/d\n    df = (1/d2)*(1/d)*(y - x)\n    output.forces[i] += df\n    output.forces[j] -= df\n    return output\nend\n# Initialize system\npositions = rand(SVector{3,Float64},1000);\nsystem = ParticleSystem(\n    xpositions = positions,\n    unitcell=[1.0,1.0,1.0],\n    cutoff = 0.1,\n    output = EnergyAndForces(0.0, similar(positions)),\n    output_name = :energy_and_forces\n)\n# Compute energy and forces\npairwise!(energy_and_forces!, system)","category":"section"},{"location":"ParticleSystem/examples/#Two-sets-of-particles","page":"Complete examples","title":"Two sets of particles","text":"In this example we illustrate the interface for the computation of properties of two sets of particles, by computing the minimum distance between the two sets.\n\nusing CellListMap\nusing StaticArrays\n# Custom structure to store the minimum distance pair\nstruct MinimumDistance\n    i::Int\n    j::Int\n    d::Float64\nend\n# Function that updates the minimum distance found\nfunction minimum_distance(pair, md)\n    (; i, j, d) = pair\n    if d < md.d\n        md = MinimumDistance(i, j, d)\n    end\n    return md\nend\n# Define appropriate methods for copy, reset and reduce\nimport CellListMap: copy_output, reset_output!, reducer!\ncopy_output(md::MinimumDistance) = md\nreset_output!(md::MinimumDistance) = MinimumDistance(0, 0, +Inf)\nreducer!(md1::MinimumDistance, md2::MinimumDistance) = md1.d < md2.d ? md1 : md2\n# Build system\nxpositions = rand(SVector{3,Float64},100);\nypositions = rand(SVector{3,Float64},1000);\nsystem = ParticleSystem(\n       xpositions = xpositions,\n       ypositions = ypositions,\n       unitcell=[1.0,1.0,1.0],\n       cutoff = 0.1,\n       output = MinimumDistance(0,0,+Inf),\n       output_name = :minimum_distance,\n)\n# Compute the minimum distance\npairwise!(minimum_distance, system)","category":"section"},{"location":"ParticleSystem/examples/#Particle-simulation","page":"Complete examples","title":"Particle simulation","text":"In this example, a complete particle simulation is illustrated, with a simple potential.  This example can illustrate how particle positions and forces can be updated. Run this simulation with:\n\njulia> system = init_system(N=200); # number of particles\n\njulia> trajectory = simulate(system);\n\njulia> animate(trajectory)\n\nOne important characteristic of this example is that the system is built outside the function that performs the simulation. This is done because the construction of the system is type-unstable (it is dimension, geometry and output-type dependent). Adding a function barrier avoids type-instabilities to propagate to the simulation causing possible performance problems.\n\nusing StaticArrays\nusing CellListMap\nimport CellListMap.wrap_relative_to\n# Function that updates the forces, for potential of the form:\n# if d < cutoff k*(d^2-cutoff^2)^2 else 0.0 with k = 10^6\nfunction update_forces!(pair, forces, cutoff)\n    (;i, j, x, y, d2) = pair\n    r = y - x\n    dudr = 10^6 * 4 * r * (d2 - cutoff^2)\n    forces[i] += dudr\n    forces[j] -= dudr\n    return forces\nend\n# Function that initializes the system: it is preferable to initialize\n# the system outside the function that performs the simulation, because\n# the system (data)type is defined on initialization. Initializing it outside\n# the simulation function avoids possible type-instabilities.\nfunction init_system(;N::Int=200)\n    Vec2D = SVector{2,Float64}\n    positions = rand(Vec2D, N)\n    unitcell = [1.0, 1.0]\n    cutoff = 0.1\n    system = ParticleSystem(\n        positions=positions,\n        cutoff=cutoff,\n        unitcell=unitcell,\n        output=similar(positions),\n        output_name=:forces,\n    )\n    return system\nend\nfunction simulate(system=init_system(); nsteps::Int=100, isave=1)\n    # initial velocities\n    velocities = [ randn(eltype(system.positions)) for _ in 1:length(system.positions) ]\n    dt = 1e-3\n    trajectory = typeof(system.positions)[]\n    for step in 1:nsteps\n        # compute forces at this step\n        pairwise!(\n            (pair, forces) -> update_forces!(pair, forces, system.cutoff),\n            system\n        )\n        # Update positions and velocities\n        for i in eachindex(system.positions, system.forces)\n            f = system.forces[i]\n            x = system.positions[i]\n            v = velocities[i]\n            x = x + v * dt + (f / 2) * dt^2\n            v = v + f * dt\n            # wrapping to origin for obtaining a pretty animation\n            x = wrap_relative_to(x, SVector(0.0, 0.0), system.unitcell)\n            # !!! IMPORTANT: Update arrays of positions and velocities\n            system.positions[i] = x\n            velocities[i] = v\n        end\n        # Save step for printing\n        if step % isave == 0\n            push!(trajectory, copy(system.positions))\n        end\n    end\n    return trajectory\nend\n\nusing Plots\nfunction animate(trajectory)\n    anim = @animate for step in trajectory\n        scatter(\n            Tuple.(step),\n            label=nothing,\n            lims=(-0.5, 0.5),\n            aspect_ratio=1,\n            framestyle=:box,\n        )\n    end\n    gif(anim, \"simulation.gif\", fps=10)\nend","category":"section"},{"location":"python/#Calling-from-Python","page":"Calling from Python","title":"Calling from Python","text":"Callling CellListMap from python can be useful if lists of neighbors or other properties have to be computed many times, making the overhead of initializing Julia negligible. As the example and benchmark below demonstrates, the current implementation of cell lists in this package is faster than common alternatives available in the python ecosystem. ","category":"section"},{"location":"python/#Installing","page":"Calling from Python","title":"Installing","text":"First, install juliacall using the pip package manager, with\n\n% pip install juliacall\n\nUsing ipython3 (only Python geq 3 is supported), do:\n\nIn [1]: from juliacall import Main as jl\n\nwhich, on the first use only, will install the latest stable version of Julia. \n\nThen, install CellListMap, with:\n\nIn [2]: jl.Pkg.add(\"CellListMap\")","category":"section"},{"location":"python/#A-Python-module","page":"Calling from Python","title":"A Python module","text":"The CellListMap.py  provides a complete small python module that interfaces the neighborlist function of CellListMap  with python, returning numpy arrays of indices and distances: \n\nBy saving the file above in a CellListMap.py file, within python we just need to do:\n\nIn [1]: import CellListMap as cl\n\nIn [2]: import numpy as np\n\nIn [3]: coords = np.random.random((50_000,3))\n\nIn [4]: i_inds, j_inds, d = cl.neighborlist(coords, 0.05)\n\nThe output i_inds, j_inds and d variables are numpy arrays with the indexes of the particles and their distances.\n\nFor periodic systems, the unitcell must be provided, as uni-dimensional np.array (for orthorhombic systems) or a np.matrix (for general periodic boundary conditions). For example: \n\nIn [5]: i_inds, j_inds, d = cl.neighborlist(coords, 0.05, unitcell=np.array([1, 1, 1]))\n\nIn [6]: i_inds, j_inds, d = cl.neighborlist(coords, 0.05, unitcell=np.matrix('1 0 0; 0 1 0; 0 0 1'))\n\nThe neighborlist_cross function provided above has a similar syntax, but to compute the neighboring particles of two independent sets:\n\nIn [7]: x = np.random.random((50_000,3))\n\nIn [8]: y = np.random.random((50_000,3))\n\nIn [9]: i_inds, j_inds, d = cl.neighborlist_cross(x, y, 0.05, unitcell=np.array([1, 1, 1]))\n\nnote: Note\nThe indexes of the particles the i_inds and j_inds arrays are 0-based, to conform the numpy array standard. \n\ntip: Tip\nTo run the code multi-threaded, set the JULIA_NUM_THREADS environment variable before launching python:% export JULIA_NUM_THREADS=8","category":"section"},{"location":"python/#Under-the-hood:-interfacing-with-the-Julia-package","page":"Calling from Python","title":"Under the hood: interfacing with the Julia package","text":"note: Note\nThe details of the above module are explained below, for a more in depth understanding of the interface between Julia and Python through the PythonCall.jl library.We highly recommend using the CellListMap.py module provided above.\n\nThe typical input coordinates, in python, are a numpy array with shape (N,dim) where N is the number of particles and dim is the dimension of the space (2 or 3 for CellListMap). Here, we generate a set of 50,000 particles in three dimensions:\n\nIn [1]: import numpy as np\n\nIn [2]: coords = np.random.random((50_000,3))\n\nJulia is column-major, and python is row-major, thus if we want to use the functions from CellListMap we need to transpose the coordinates:\n\nIn [3]: coords_t = coords.transpose()\n\nThese transposed coordinates can be used in the CellListMap.neighborlist function. For example:\n\nIn [4]: jl.seval(\"using CellListMap\")\n\nIn [6]: neighbor_list = jl.neighborlist(coords_t,0.05)\n\nwhich will return a list of tuples, containing all pairs of coordinates withing the cutoff (remember that the first call to a Julia function will always take longer than subsequent calls, because the function is JIT compiled):\n\nIn [12]: neighbor_list.shape\nOut[12]: (618774,)\n\nIn [13]: neighbor_list[1]\nOut[13]: (1, 37197, 0.047189685889846615)\n\nNote that the third element of the tuple is the distance between the points.","category":"section"},{"location":"python/#Converting-the-list-to-numpy-arrays","page":"Calling from Python","title":"Converting the list to numpy arrays","text":"The output of CellListMap.neighborlist is a Julia Vector{Tuple{Int,Int,Float64}} array (or Float32, if the coordinates and cutoff were given in 32-bit precision). This Julia list can be accessed from within python normally:\n\nIn [36]: neighbor_list = jl.neighborlist(coords_t, 0.05);\n\nIn [37]: neighbor_list[0:2]\nOut[37]: \n2-element view(::Vector{Tuple{Int64, Int64, Float64}}, 1:1:2) with eltype Tuple{Int64, Int64, Float64}:\n (1, 6717, 0.020052121336342873)\n (1, 7208, 0.03880915662838867)\n\nIn [38]: neighbor_list[0][0]\nOut[38]: 1\n\nIn [40]: neighbor_list[0][2]\nOut[40]: 0.020052121336342873\n\nYet, this list may not be interoperable with many other python packages, particularly with numpy standard  operations. Thus, it may be interesting to convert the list to numpy  arrays. This can be done with a simple helper function, which uses a Julia function to copy the list values to the numpy arrays:\n\njl.seval(\"\"\"\nfunction copy_to_numpy_arrays(nb_list, i_inds, j_inds, d)\n    for i in eachindex(nb_list)\n        i_inds[i], j_inds[i], d[i] = nb_list[i]\n    end\n    return nothing\nend\n\"\"\")\ndef neighborlist(x, cutoff) :\n    x_t = x.transpose()\n    nb_list = jl.neighborlist(x_t, cutoff)\n    i_inds = np.full((len(nb_list),), 0, dtype=np.int64)\n    j_inds = np.full((len(nb_list),), 0, dtype=np.int64)\n    d = np.full((len(nb_list),), 0.0, dtype=np.float64)\n    jl.copy_to_numpy_arrays(nb_list, i_inds, j_inds, d)\n    i_inds -= 1 # make indexes 0-based\n    j_inds -= 1 # make indexes 0-based\n    return i_inds, j_inds, d\n\nNow, the output of the python neighborlist contains the numpy arrays for the indexes of the two particles involved in each pair, and their distances:\n\nIn [61]: neighborlist(coords,0.05)\nOut[61]: \n(array([    0,     0,     0, ..., 49802, 49802, 49885]),\n array([ 6717,  7208,  9303, ..., 11542, 27777, 43853]),\n array([0.02005212, 0.03880916, 0.04543936, ..., 0.04671987, 0.02671908,\n        0.02772025]))\n\nThe overhead of these conversions, array creation and copies is not very large, and the benchmarks below are still valid considering this auxiliary python function.","category":"section"},{"location":"python/#Benchmarking-vs.-Scipy","page":"Calling from Python","title":"Benchmarking vs. Scipy","text":"To properly benchmark the neighborlist function from CellListMap, let us first define a simple wrapper that will include the transposition of the coordinates in the time:\n\nIn [14]: def neighborlist_simple(x,cutoff):\n    ...:     y = x.transpose()\n    ...:     nn = jl.CellListMap.neighborlist(y,cutoff)\n    ...:     return nn\n    ...:\n\nIn [15]: %timeit neighborlist_simple(coords,0.05)\n61.7 ms ± 707 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n\nLet us compare this with the performance of a inrange neighborlist algorithm from scipy:\n\nIn [29]: from scipy.spatial import cKDTree\n\nIn [30]: def neighborlist_scipy(x,cutoff) : \n    ...:     kd_tree = cKDTree(x)  \n    ...:     pairs = kd_tree.query_pairs(r=0.05)  \n    ...:     return pairs \n    ...:\n\nIn [31]: %timeit neighborlist_scipy(coords,0.05)\n312 ms ± 2.85 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n\nJust to confirm, this is the number of pairs that is being output in this test\n\nIn [32]: len(neighborlist_scipy(coords,0.05)) # using Scipy\nOut[32]: 618475\n\nIn [20]: len(neighborlist_smple(coords,0.05)) # using CellListMap\nOut[20]: 618475\n\nIf we use the neighborlist function from Converting the list to numpy arrays, the result is similar, thus copying the output to numpy arrays does not create a large overhead:\n\nIn [30]: %timeit neighborlist(coords, 0.05)\n67.4 ms ± 4.04 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)","category":"section"},{"location":"python/#Overhead","page":"Calling from Python","title":"Overhead","text":"The overhead of calling the function through juliacall  is small. From within Julia, the timings of a similar execution would be:\n\njulia> using BenchmarkTools\n\njulia> using CellListMap\n\njulia> x = rand(3,50_000);\n\njulia> @btime CellListMap.neighborlist($x,0.05,parallel=false);\n  51.299 ms (17687 allocations: 37.43 MiB)","category":"section"},{"location":"python/#Multi-threading","page":"Calling from Python","title":"Multi-threading","text":"These examples were run single-threaded. To run multi-threaded, an environment variable for Julia needs to be set. For example, in bash, do:\n\n% export JULIA_NUM_THREADS=12\n\nwarning: Warning\nThere is a conflict between garbage collectors that may cause segmentation faults in multi-threaded runs  (see this issue). The workaround appears to be to  disable the Julia garbage collector during the execution of multi-threaded code. Here we provide the necessary syntax as an auxiliary Python function.\n\nConsider the following python file, let us call it neighborlist.py, that provides the neighborlist python function with the conversion of the output to numpy arrays:\n\nfrom juliacall import Main as jl\njl.seval(\"using CellListMap\")\nimport numpy as np\njl.seval(\"\"\"\nfunction copy_to_numpy_arrays(nb_list, i_inds, j_inds, d)\n    for i in eachindex(nb_list)\n        i_inds[i], j_inds[i], d[i] = nb_list[i]\n    end\n    return nothing\nend\n\"\"\")\ndef neighborlist(x, cutoff) :\n    x_t = x.transpose()\n    jl.GC.enable(False)\n    nb_list = jl.neighborlist(x_t, cutoff)\n    jl.GC.enable(True)\n    i_inds = np.full((len(nb_list),), 0, dtype=np.int64)\n    j_inds = np.full((len(nb_list),), 0, dtype=np.int64)\n    d = np.full((len(nb_list),), 0.0, dtype=np.float64)\n    jl.copy_to_numpy_arrays(nb_list, i_inds, j_inds, d)\n    return i_inds, j_inds, d\n\nThen, in Python, do:\n\nIn [1]: import neighborlist as nb\n\nIn [2]: import numpy as np\n\nIn [3]: coords = np.random.random((50_000,3))\n\nIn [4]: i_inds, j_inds, d = nb.neighborlist(coords, 0.05)\n\nIn a notebook with 6 cores (12 threads) this led to the following performance:\n\nIn [5]: %timeit i_inds, j_inds, d = nb.neighborlist(coords, 0.05)\n23.7 ms ± 910 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n\nWhich, is about 3x faster than the serial execution:\n\nIn [4]: %timeit i_inds, j_inds, d = nb.neighborlist(coords, 0.05)\n59.2 ms ± 959 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n\nand thus about 10x faster than scipy.spatial:\n\nIn [7]: %timeit neighborlist_scipy(coords,0.05)\n204 ms ± 2.86 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)","category":"section"},{"location":"python/#General-mappings","page":"Calling from Python","title":"General mappings","text":"A greater flexibility on the use of CellListMap from python can be obtained by defining custom Julia functions. This feature must be used with the low level interface of CellListMap, and is somewhat limited in scope.\n\nIn [36]: jl.seval(\"using CellListMap\")\n\nIn [37]: x = np.random.random((50_000,3));\n\nIn [38]: x_t = x.transpose()\n\nIn [39]: box = jl.Box(np.array([1,1,1]), 0.05)\n\nIn [40]: box\nOut[41]: \nBox{OrthorhombicCell, 3}\n  unit cell matrix = [ 1.0, 0.0, 0.0; 0.0, 1.0, 0.0; 0.0, 0.0, 1.0 ]\n  cutoff = 0.05\n  number of computing cells on each dimension = [22, 22, 22]\n  computing cell sizes = [0.05, 0.05, 0.05] (lcell: 1)\n  Total number of cells = 10648\n\nIn [41]: cl = jl.CellList(x_t,box)\n\nIn [42]: cl\nOut[42]: \nCellList{3, Float64}\n  50000 real particles.\n  7985 cells with real particles.\n  66594 particles in computing box, including images.\n\nThe function to be mapped, however, has to be defined in Julia, using seval. For example, here we define a function that computes the histogram of the distances within the cutoff. \n\nIn [43]: jl.seval(\"\"\"  \n    ...: function histogram(pair, hist) \n    ...:     cutoff = 0.05 \n    ...:     dc = pair.d/cutoff # in [0,1] \n    ...:     ibin = floor(Int,dc*10) + 1 # in [0,10] \n    ...:     hist[ibin] += 1 \n    ...:     return hist \n    ...: end \n    ...: \"\"\")\nOut[44]: histogram (generic function with 1 method)\n\nWe can initialize the output variable (the histogram) using a regular numpy array: \n\nIn [45]: hist = np.zeros(10)\n\nand call the pairwise function to obtain the histogram of the distances within the cutoff:\n\nIn [46]: jl.pairwise!(jl.histogram, hist, box, cl)\nOut[46]: \n10-element PythonCall.PyArray{Float64, 1, true, true, Float64}:\n 153344.0\n      1.151744e6\n      3.066624e6\n      5.787392e6\n      9.220608e6\n      1.3175552e7\n      1.7414912e7\n      2.1817088e7\n      2.6189312e7\n      3.0583808e7\n\nNote that the function receives a NeighborPair object (pair) with fields pair.i, pair.j, pair.x, pair.y, pair.d2, and a lazily-computed pair.d for the distance.\n\nWith this interface, however, it is not possible to pass additional parameters to the mapped function, and thus the additional parameters have to defined inside the called function (as the cutoff in the current example). This is not ideal, for example, for computing accelerations, which depend on the masses of the particles. In this case, currently, either just use Julia from start and closures, or use the neighborlist  function to obtain the list of neighbors to then compute whatever property is desired from the list of pairs, although this is suboptimal in terms of performance.  ","category":"section"},{"location":"migrating/#Migrating-from-0.9","page":"Migrating from 0.9","title":"Migrating from 0.9","text":"This guide helps users migrate from CellListMap version 0.9.x to version 0.10.0.","category":"section"},{"location":"migrating/#Neighbor-lists-updates","page":"Migrating from 0.9","title":"Neighbor lists updates","text":"The neighborlist and neighborlist! functions remain mostly unchanged in their interface, except for the removal of the autoswap option.","category":"section"},{"location":"migrating/#Removal-of-autoswap","page":"Migrating from 0.9","title":"Removal of autoswap","text":"The autoswap option, which was deprecated in version 0.9.16, has been completely removed in 0.10.0. This option was previously used to automatically swap the sets of particles to optimize performance when computing neighbor lists between two sets of particles with different sizes.\n\nMigration: If you were using autoswap=true (which was the default), you may experience some performance regression for smaller systems. For most use cases, simply remove the autoswap keyword argument:\n\n# Before (0.9.x)\nneighborlist(x, y, cutoff; autoswap=true)\n\n# After (0.10.0)\nneighborlist(x, y, cutoff)","category":"section"},{"location":"migrating/#ParticleSystem-interface-updates","page":"Migrating from 0.9","title":"ParticleSystem interface updates","text":"","category":"section"},{"location":"migrating/#Renaming-of-map_pairwise!-to-pairwise!","page":"Migrating from 0.9","title":"Renaming of map_pairwise! to pairwise!","text":"The function map_pairwise! has been renamed to pairwise!:\n\n# Before (0.9.x)\nu = map_pairwise!(f, system)\n\n# After (0.10.0)\nu = pairwise!(f, system)","category":"section"},{"location":"migrating/#Removal-of-pairwise-(without-!)","page":"Migrating from 0.9","title":"Removal of pairwise (without !)","text":"The non-mutating pairwise function has been removed. This change emphasizes that the function always mutates the output field of the ParticleSystem object:\n\n# Before (0.9.x)\nu = pairwise(f, system)\n\n# After (0.10.0)\nu = pairwise!(f, system)  # always use the mutating version","category":"section"},{"location":"migrating/#Simplified-mapped-function-signature","page":"Migrating from 0.9","title":"Simplified mapped function signature","text":"The signature of the mapped function has been simplified. Instead of receiving individual arguments, the function now receives a NeighborPair object containing all pair information:\n\n# Before (0.9.x)\nfunction f(x, y, i, j, d2, output)\n    d = sqrt(d2)\n    # ... compute something\n    return output\nend\n\n# After (0.10.0)\nfunction f(pair, output)\n    (; x, y, i, j, d2, d) = pair  # destructuring\n    # ... compute something\n    return output\nend\n\nThe NeighborPair object contains the fields:\n\nx, y: positions of the two particles (minimum-image convention applied)\ni, j: indices of the particles in the original arrays\nd2: squared distance between the particles\nd: distance between the particles (lazily computed - only calculated when accessed)\n\nThe lazy computation of d is particularly useful when your function only needs the squared distance d2, avoiding unnecessary sqrt calls.","category":"section"},{"location":"migrating/#Output-resetting-behavior","page":"Migrating from 0.9","title":"Output resetting behavior","text":"The handling of the initial output value has changed:\n\nBefore (0.9.x): The output was reset to zero always, and the initial value given to ParticleSystem was ignored. \nAfter (0.10.0): The output is reset to zero(typeof(output)) by default at each pairwise! call, but the reset=false option can be used to accumulate with the initial value.\n\nTo skip the automatic resetting (useful for accumulating results), use the reset=false keyword:\n\n# Reset output to zero before computation (default)\npairwise!(f, system)\n\n# Keep current output value and accumulate\npairwise!(f, system; reset=false)","category":"section"},{"location":"migrating/#Low-level-interface","page":"Migrating from 0.9","title":"Low-level interface","text":"The previous \"low-level interface\" using Box, CellList, and pairwise!(f, output, box, cl) directly is now internal and no longer exported or part of the public API.\n\nMigration: Use the ParticleSystem interface instead. The ParticleSystem interface provides all the functionality of the low-level interface with a simpler and more user-friendly API.\n\n# Before (0.9.x) - Low-level interface\nbox = Box(sides, cutoff)\ncl = CellList(x, box)\nu = map_pairwise!((pair, u) -> f(pair, u), 0.0, box, cl)\n\n# After (0.10.0) - ParticleSystem interface\nsys = ParticleSystem(positions=x, cutoff=cutoff, unitcell=sides, output=0.0)\nu = pairwise!(f, sys)\n\nFor iterative computations where the particle positions change:\n\n# Before (0.9.x)\nbox = Box(sides, cutoff)\ncl = CellList(x, box)\nfor step in 1:nsteps\n    x = new_positions()\n    UpdateCellList!(x, box, cl)\n    u = map_pairwise!(f, 0.0, box, cl)\nend\n\n# After (0.10.0)\nsys = ParticleSystem(positions=x, cutoff=cutoff, unitcell=sides, output=0.0)\nfor step in 1:nsteps\n    sys.xpositions .= new_positions()  # update coordinates directly\n    u = pairwise!(f, sys)\nend\n\nSee the ParticleSystem and Updating the system sections for more details on using the ParticleSystem interface.","category":"section"},{"location":"migrating/#Python-interface","page":"Migrating from 0.9","title":"Python interface","text":"The Python interface has been discontinued in version 0.10.0.","category":"section"},{"location":"migrating/#Summary-of-breaking-changes","page":"Migrating from 0.9","title":"Summary of breaking changes","text":"Change 0.9.x 0.10.0\nPairwise mapping function map_pairwise! pairwise!\nAlias for \"non-mutating\" pairwise pairwise Removed\nOutput reset behavior Manual Automatic (use reset=false to skip)\nLow-level interface Exported Internal (use ParticleSystem)\nautoswap option Deprecated Removed\nPython interface Available Discontinued","category":"section"},{"location":"#CellListMap.jl","page":"Overview","title":"CellListMap.jl","text":"CellListMap.jl implements an efficient cell list scheme for the computation of interactions, neighbor lists, or any other property dependent on the distances between pairs of two- or three-dimensional particles, within a cutoff. \n\nThe package provides an interface to compute a generic function for each pair of particles closer  than a cutoff, using general periodic boundary conditions. Parallel and serial implementations can be used. ","category":"section"},{"location":"#The-naive-double-loop","page":"Overview","title":"The naive double loop","text":"CellListMap is a package that implements a fast scheme for computing properties of systems of particles in 2 or 3 dimensions, within a cutoff. In brief, it is designed to replace double loops running over the pairs of particles of a system. Naively, a loop over all pair of particles is written as:\n\nfor i in 1:N\n    for j in i+1:N\n        # compute distance, possibly considering periodic boundary conditions\n        d = distance(particle[i],particle[j]) \n        if d <= cutoff \n            # compute property dependent on d\n        end\n    end\nend\n\nwhere N is the number of particles. \n\nAlternatively, if the interaction is between two disjoint sets of particles, the naive loop is\n\nfor i in 1:N \n    for j in 1:M\n        # compute distance, possibly considering periodic boundary conditions\n        d = distance(first_set[i], second_set[j])\n        if d <= cutoff\n            # compute property dependent on d\n        end\n    end\nend\n\nwhere N and M are the numbers of particles of each set. If the cutoff is significantly smaller than the dimension of the system, these loops are very expensive, and it is possible to avoid looping over particles that are farther from each other than the cutoff.\n\nCellListMap implements an efficient and parallel cell-list method, with optimizations, to substitute such double-loops while taking into account periodic boundary conditions. Cell lists are an alternative to distance trees and are particularly effective when the distribution of the particles is roughly homogeneous. For highly heterogeneous systems distance trees like those implemented in NearestNeighbors.jl might be more performant.","category":"section"},{"location":"#Quick-start:-computing-neighbor-lists","page":"Overview","title":"Quick start: computing neighbor lists","text":"The simplest use case of CellListMap is to compute the list of neighboring particles within a cutoff distance. This can be implemented as a particular usage case of CellListMap, but given its generality it is provided as an independent interface: the neighborlist function:\n\nAn example of the application of the neighborlist function follows:\n\njulia> using CellListMap\n\njulia> x = rand(3, 10_000); # 10,000 particles in 3D\n\njulia> neighborlist(x, 0.05) # cutoff of 0.05\n209452-element Vector{Tuple{Int64, Int64, Float64}}:\n (1, 1055, 0.04770602450750023)\n (1, 1261, 0.048087995599677004)\n ⋮\n (9989, 8269, 0.0442616226498007)\n (9989, 6452, 0.042189574206507035)\n\nEach element of the list is a tuple (i, j, d) containing the indices of the particles and their distance.\n\nCellListMap supports general periodic boundary conditions, by providing the unitcell as vector (for orthorhombic systems) or a unitcell matrix (for general triclinic systems):\n\njulia> neighborlist(x, 0.05; unitcell=[1,1,1]) # periodic box of side 1\n305006-element Vector{Tuple{Int64, Int64, Float64}}:\n (1, 1055, 0.04770602450750023)\n ⋮\n\nSee the Neighbor lists section for more details, including in-place computations for iterative workflows.\n\nnote: Note\nThe downside of explicitly computing neighbor lists is that it implies storing the list of neighbors. This can be memory consuming and slow in situations where a property can be computed by iterating over the neighbors without materializing the neighbor lists. CellListMap is designed to provide this alternative.","category":"section"},{"location":"#General-pairwise-computations","page":"Overview","title":"General pairwise computations","text":"For more general pairwise computations (energies, forces, etc.) without the materialization of the neighbor lists, the ParticleSystem interface provides a flexible way to define custom functions that are applied to all pairs of particles within the cutoff, and reducing an output value. See the ParticleSystem interface section for details.\n\nA concise example is the computation of the sum of the inverse of the distance between particles:\n\njulia> using CellListMap\n\njulia> x = rand(3, 10_000); # 10,000 particles in 3D\n\njulia> sys = ParticleSystem(positions=x, cutoff=0.05, unitcell=[1,1,1], output=0.0)\n\njulia> pairwise!((pair, u) -> u += 1/pair.d, sys)\n792925.6234732079\n\nNote that in the above example the pairwise method is actually performing a pairwise operation, where the output value u is summed up over all neighboring pairs of particles. \n\nIf you are familiar with Julia, the do syntax also provides a readable format for the pairwise! application:\n\njulia> pairwise!(sys) do pair, u \n    u += 1/pair.d\nend\n792925.6234732079\n\nThe pairwise! method mutates the sys.output field, which stores the result of the computation:\n\njulia> sys.output\n777632.9459487279\n\nUsing initial values, customizing the field name, computing general compound properties, and mapping functions to disjoint sets of particles is possible. ","category":"section"},{"location":"#Installation","page":"Overview","title":"Installation","text":"This is a Julia package. Install Julia first following the instructions in the download page.\n\nOnce Julia is installed, install the CellListMap package from the Julia REPL with:\n\njulia> import Pkg\n\njulia> Pkg.add(\"CellListMap\")","category":"section"},{"location":"#Help!","page":"Overview","title":"Help!","text":"Please ask for help if having any difficulty using the package. Reach us by:\n\nAsking a question on the Julia Discourse forum. Please mark @lmiq on your post, otherwise we may miss it! This may be very effective to get help from  many Julia users on questions that might not be directly related this package.\nOpening an issue if you think you found a problem in the package. Even documentation problems can be reported.\nJoining us at Zulip-chat in the m3g stream of the Julia Zulip forum.\nSending an e-mail to: lmartine@unicamp.br.","category":"section"}]
}
